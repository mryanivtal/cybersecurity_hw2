{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72810151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspellchecker\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086e0e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## General - imports paths etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683f43e6-ff1c-4c28-af4c-3452553fc476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import xml.etree.ElementTree as ET \n",
    "import csv\n",
    "\n",
    "from typing import Dict, Callable, List, Dict, Set, Any\n",
    "import logging\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf9de114-ddde-43d7-9d6a-69d1b0a913d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders\n",
    "PJ_DATA_FOLDER = Path('./customer_data')\n",
    "PAN12_DATA_FILE = Path('./ref_data/pan12_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml')\n",
    "PAN12_LINE_LABELS_FILE = Path('./ref_data/pan12_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-groundtruth-problem2.txt')\n",
    "PAN12_USER_LABELS_FILE = Path('./ref_data/pan12_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-groundtruth-problem1.txt')\n",
    "OUTPUT_FOLDER = Path('./')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ad22d",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf51658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define datasets with texts and labels\n",
    "\n",
    "def list_files_in_dir(folder: Path, extension='*') -> List:\n",
    "    \n",
    "    file_list = [f for f in folder.glob(f'**/*.{extension}') if f.is_file()]\n",
    "    return file_list\n",
    "\n",
    "## Test funcion\n",
    "# list_files_in_dir(DATA_FOLDER, 'dtd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d0df3",
   "metadata": {},
   "source": [
    "### Word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70954f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word lists\n",
    "SEX_WL_PATH = Path(r'.\\sex_words.txt')\n",
    "with open(SEX_WL_PATH, 'rt') as handle:\n",
    "    sex_word_list = handle.read().split('\\n')\n",
    "\n",
    "MEETING_WL_PATH = Path(r'.\\meeting_words.txt')\n",
    "with open(MEETING_WL_PATH, 'rt') as handle:\n",
    "    meeting_word_list = handle.read().split('\\n')\n",
    "\n",
    "FAMILY_WL_PATH = Path(r'.\\family_words.txt')\n",
    "with open(FAMILY_WL_PATH, 'rt') as handle:\n",
    "    family_word_list = handle.read().split('\\n')\n",
    "\n",
    "CHAT_SLANG_PATH = Path(r'.\\chat_slang.txt')\n",
    "with open(CHAT_SLANG_PATH, mode='rt') as handle:\n",
    "    csv_reader = csv.reader(handle, delimiter='\\t')\n",
    "    chat_slang = {rows[0]:rows[1] for rows in csv_reader}\n",
    "\n",
    "EMOTICONS_PATH = Path(r'.\\emoticons.txt')\n",
    "with open(EMOTICONS_PATH, mode='rt', encoding=\"utf8\") as handle:\n",
    "    csv_reader = csv.reader(handle, delimiter='\\t')\n",
    "    emoticons = {rows[0]:rows[1] for rows in csv_reader}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0844b40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e182ed0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chat text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d2873c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going porn site walking laughing loud the alright coming flight right right back fuck'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def remove_stopwords(text: str, words_to_remove: List[str])-> str:\n",
    "    '''\n",
    "    Gets string, returns it without stopwords\n",
    "    '''\n",
    "    return \" \".join([word for word in str(text).split() if word not in words_to_remove])\n",
    "\n",
    "\n",
    "def stem_text(text: str, stemmer: Any)-> str:\n",
    "    '''\n",
    "    stem text string\n",
    "    '''\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "\n",
    "def remove_emoji(text: str) -> str:\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_emoticons(text: str, emoticons: Dict) -> str:\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in emoticons) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def replace_pornsites_with_string(text:str)->str:\n",
    "    pornsite_pattern = re.compile(r'\\S+xnxx\\.co\\S+' + r'|\\S+pornhub\\.co\\S+' + r'|\\S+nude\\.co\\S+' + r'|\\S+sex\\.co\\S+')\n",
    "    return pornsite_pattern.sub(r'porn site', text)\n",
    "\n",
    "def remove_urls(text:str)-> str:\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_special_characters(text:str)-> str:\n",
    "    special_chars_pattern = re.compile(r'[^A-Za-z0-9 ]+')\n",
    "    return special_chars_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def replace_chat_slang(text: str, chat_slang: Dict[str, str])-> str:\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_slang.keys():\n",
    "            new_text.append(chat_slang[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "\n",
    "def correct_spellings(text: str, speller: Callable) -> str:\n",
    "    corrected_text = []\n",
    "    misspelled_words = speller.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(speller.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "\n",
    "def preprocess_string_for_bow(text: str, stemmer: Callable=None, speller: Callable=None, words_to_remove:List[str]=None, emoticons: Dict[str, str]=None)-> str:\n",
    "    # text = remove_emoji(text)\n",
    "    # text = remove_emoticons(text, emoticons)\n",
    "    text = replace_chat_slang(text, chat_slang)\n",
    "    text = text.lower()\n",
    "    text = replace_pornsites_with_string(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_stopwords(text, words_to_remove)\n",
    "    text = correct_spellings(text, speller)\n",
    "    # text = stem_text(text, stemmer)\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_df_for_bow(df: pd.DataFrame, text_col: str, output_col_name='preprocessed_bow', stemmer=None, speller=None, words_to_remove=None, emoticons=None)-> pd.DataFrame:\n",
    "    '''\n",
    "    Gets a PD dataframe and a text column name\n",
    "    returns the same dataframe with additional column called 'posts_preprocessed_bow'\n",
    "    '''\n",
    "    speller = SpellChecker()\n",
    "    words_to_remove = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    df[output_col_name] = df[text_col]\n",
    "    df[output_col_name] = df[output_col_name].apply(lambda text: preprocess_string_for_bow(text, stemmer=stemmer, speller=speller, words_to_remove=words_to_remove, emoticons=emoticons))\n",
    "    return df\n",
    "\n",
    "\n",
    "# test\n",
    "speller = SpellChecker()\n",
    "words_to_remove = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "text = 'r u going to www.google.com http://xnxx.com im walking LOL ths is not &amp;right im caming flight now u r right brb and fu :-)'\n",
    "\n",
    "preprocess_string_for_bow(text, stemmer=stemmer, speller=speller, words_to_remove=words_to_remove, emoticons=emoticons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d31dd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119f4fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convesation level datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fc852-a907-4706-a742-14207e2eccf2",
   "metadata": {},
   "source": [
    "#### PJ Convesation level dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ea3ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>BODY</th>\n",
       "      <th>COMMENT</th>\n",
       "      <th>CODING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:02:01 pm)</td>\n",
       "      <td>im dennis us army soldier from cincinnati</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:02:30 pm)</td>\n",
       "      <td>hi im becky from ky</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:02:35 pm)</td>\n",
       "      <td>how old ru</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:02:42 pm)</td>\n",
       "      <td>13 how old ru</td>\n",
       "      <td>(age stated and he didn't bat an eye)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:02:44 pm)</td>\n",
       "      <td>u single</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:02:51 pm)</td>\n",
       "      <td>yeah</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:03:03 pm)</td>\n",
       "      <td>i had a bf but we broke up when i moved here</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:03:11 pm)</td>\n",
       "      <td>ok u have sex at 13</td>\n",
       "      <td>(he obviously knows my age)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:03:28 pm)</td>\n",
       "      <td>u mean did i ever</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:03:32 pm)</td>\n",
       "      <td>yeah</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       USERNAME      DATETIME                                          BODY  \\\n",
       "0   armysgt1961  (7:02:01 pm)     im dennis us army soldier from cincinnati   \n",
       "1  peekaboo1293  (7:02:30 pm)                           hi im becky from ky   \n",
       "2   armysgt1961  (7:02:35 pm)                                    how old ru   \n",
       "3  peekaboo1293  (7:02:42 pm)                                 13 how old ru   \n",
       "4   armysgt1961  (7:02:44 pm)                                      u single   \n",
       "5  peekaboo1293  (7:02:51 pm)                                          yeah   \n",
       "6  peekaboo1293  (7:03:03 pm)  i had a bf but we broke up when i moved here   \n",
       "7   armysgt1961  (7:03:11 pm)                           ok u have sex at 13   \n",
       "8  peekaboo1293  (7:03:28 pm)                             u mean did i ever   \n",
       "9   armysgt1961  (7:03:32 pm)                                          yeah   \n",
       "\n",
       "                                 COMMENT CODING  \n",
       "0                                   <NA>      \n",
       "  \n",
       "1                                   <NA>   <NA>  \n",
       "2                                   <NA>      \n",
       "  \n",
       "3  (age stated and he didn't bat an eye)   <NA>  \n",
       "4                                   <NA>      \n",
       "  \n",
       "5                                   <NA>   <NA>  \n",
       "6                                   <NA>   <NA>  \n",
       "7            (he obviously knows my age)      \n",
       "  \n",
       "8                                   <NA>   <NA>  \n",
       "9                                   <NA>   <NA>  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_one_chat_pj(file_path: Path) -> Dict[str, pd.DataFrame]:\n",
    "    '''\n",
    "    Gets an XML doctree (ET parser)\n",
    "    returns three dataframes:\n",
    "        - victim\n",
    "        - predator\n",
    "        - chat posts\n",
    "    '''\n",
    "    doc_tree = ET.parse(file_path)\n",
    "    doc_root = doc_tree.getroot()\n",
    "    \n",
    "    posts_df = pd.DataFrame(columns = ['USERNAME', 'DATETIME', 'BODY', 'COMMENT', 'CODING'], dtype=str)\n",
    "    predator_df = pd.DataFrame(columns = ['FIRSTNAME', 'LASTNAME', 'STATEDNAME', 'STATEDAGE', 'GENDER', 'RACE', 'CITY', 'STATE', 'REPEATOFFENDER', 'ADMITGUILT', 'TRUTHFULNAME', 'SCREENNAME'], dtype=str)\n",
    "    victim_df = pd.DataFrame(columns = ['FIRSTNAME', 'LASTNAME', 'STATEDNAME', 'STATEDAGE', 'GENDER', 'RACE', 'CITY', 'STATE', 'PREVIOUSVICTIMIZATION', 'ADMITGUILT', 'SCREENNAME'], dtype=str)\n",
    "\n",
    "    for post in doc_root.findall('POST'):\n",
    "        post_dict = {}\n",
    "        for field in post:\n",
    "            post_dict[field.tag] = field.text\n",
    "\n",
    "        posts_df = posts_df.append(post_dict, ignore_index=True)\n",
    "    posts_df = posts_df.astype('string')\n",
    "\n",
    "\n",
    "    for predator in doc_root.findall('PREDATOR'):\n",
    "        predator_dict = {}\n",
    "        for field in predator:\n",
    "            predator_dict[field.tag] = field.text\n",
    "\n",
    "        predator_df = predator_df.append(predator_dict, ignore_index=True)   \n",
    "    predator_df = predator_df.astype('string')\n",
    "\n",
    "\n",
    "    for victim in doc_root.findall('VICTIM'):\n",
    "        victim_dict = {}\n",
    "        for field in victim:\n",
    "            victim_dict[field.tag] = field.text\n",
    "\n",
    "        victim_df = victim_df.append(victim_dict, ignore_index=True)  \n",
    "    victim_df = victim_df.astype('string')\n",
    "\n",
    "    return {'predator': predator_df, 'victim': victim_df, 'conversation': posts_df}\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Test XML parse functions:\n",
    "file_path = PJ_DATA_FOLDER / Path('ArmySgt1961.xml')\n",
    "chat_dict = load_one_chat_pj(file_path)\n",
    "chat_dict['victim'].head()\n",
    "chat_dict['predator'].head()\n",
    "chat_dict['conversation'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3818aedd-70b1-4802-b66b-6f8116cb4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PjDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrapper around Torch Dataset to perform text classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_folder: Path, preprocess_fn=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            texts (List[str]): a list with texts to classify or to train the\n",
    "                classifier on\n",
    "            labels List[str]: a list with classification labels (optional)\n",
    "        \"\"\"\n",
    "       \n",
    "        self.file_list = list_files_in_dir(data_folder, extension='xml')\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        self.TEXT_COLUMN_NAME = 'BODY'\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            int: length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Gets element of the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int): index of the element in the dataset\n",
    "        Returns:\n",
    "            Single element by index\n",
    "        \"\"\"        \n",
    "        sample = load_one_chat_pj(self.file_list[idx])['conversation']\n",
    "        if self.preprocess_fn is not None:\n",
    "            sample = self.preprocess_fn(sample, self.TEXT_COLUMN_NAME)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7562daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_data\\ArmySgt1961.xml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>BODY</th>\n",
       "      <th>COMMENT</th>\n",
       "      <th>CODING</th>\n",
       "      <th>preprocessed_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:02:01 pm)</td>\n",
       "      <td>im dennis us army soldier from cincinnati</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "      <td>dennis us army soldier cincinnati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:02:30 pm)</td>\n",
       "      <td>hi im becky from ky</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>hi becky ky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:02:35 pm)</td>\n",
       "      <td>how old ru</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:02:42 pm)</td>\n",
       "      <td>13 how old ru</td>\n",
       "      <td>(age stated and he didn't bat an eye)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>13 old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:02:44 pm)</td>\n",
       "      <td>u single</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>7:27:10 PM</td>\n",
       "      <td>(incoming phone number given)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>incoming phone number given</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>7:27:37 PM</td>\n",
       "      <td>name</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>7:27:58 PM</td>\n",
       "      <td>boo real name is becky</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>boo real name becky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>8:38:52 PM</td>\n",
       "      <td>where r u</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>(8:39:00 pm)</td>\n",
       "      <td>armysgt1961 disconnected</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>armysgt1961 disconnected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        USERNAME      DATETIME                                       BODY  \\\n",
       "0    armysgt1961  (7:02:01 pm)  im dennis us army soldier from cincinnati   \n",
       "1   peekaboo1293  (7:02:30 pm)                        hi im becky from ky   \n",
       "2    armysgt1961  (7:02:35 pm)                                 how old ru   \n",
       "3   peekaboo1293  (7:02:42 pm)                              13 how old ru   \n",
       "4    armysgt1961  (7:02:44 pm)                                   u single   \n",
       "..           ...           ...                                        ...   \n",
       "91  peekaboo1293    7:27:10 PM              (incoming phone number given)   \n",
       "92   armysgt1961    7:27:37 PM                                       name   \n",
       "93  peekaboo1293    7:27:58 PM                     boo real name is becky   \n",
       "94  peekaboo1293    8:38:52 PM                                  where r u   \n",
       "95          <NA>  (8:39:00 pm)                   armysgt1961 disconnected   \n",
       "\n",
       "                                  COMMENT CODING  \\\n",
       "0                                    <NA>      \n",
       "   \n",
       "1                                    <NA>   <NA>   \n",
       "2                                    <NA>      \n",
       "   \n",
       "3   (age stated and he didn't bat an eye)   <NA>   \n",
       "4                                    <NA>      \n",
       "   \n",
       "..                                    ...    ...   \n",
       "91                                   <NA>   <NA>   \n",
       "92                                   <NA>      \n",
       "   \n",
       "93                                   <NA>   <NA>   \n",
       "94                                   <NA>   <NA>   \n",
       "95                                   <NA>   <NA>   \n",
       "\n",
       "                     preprocessed_bow  \n",
       "0   dennis us army soldier cincinnati  \n",
       "1                         hi becky ky  \n",
       "2                                 old  \n",
       "3                              13 old  \n",
       "4                              single  \n",
       "..                                ...  \n",
       "91        incoming phone number given  \n",
       "92                               name  \n",
       "93                boo real name becky  \n",
       "94                                     \n",
       "95           armysgt1961 disconnected  \n",
       "\n",
       "[96 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test the dataset\n",
    "pj_ds = PjDataset(PJ_DATA_FOLDER, preprocess_fn=preprocess_df_for_bow)\n",
    "print(pj_ds.file_list[0])\n",
    "pj_ds[0].head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a4589",
   "metadata": {},
   "source": [
    "#### pan12 convesation level dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e001f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pan12Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrapper around Torch Dataset to perform text classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chat_data_file: Path, conversation_labels: Path=None, line_labels: Path=None, preprocess_fn=None, preprocess_args=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            chat_data_file: path to chat xml file\n",
    "            conversation_labels:\n",
    "            line_labels:  \n",
    "        \"\"\"\n",
    "       \n",
    "        self.chat_data_file = chat_data_file\n",
    "        self.conversations = self._get_conversation_roots(chat_data_file)\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        self.preprocess_args = preprocess_args\n",
    "\n",
    "        self.conversation_labels = conversation_labels\n",
    "        self.line_labels = line_labels\n",
    "\n",
    "        self.TEXT_COLUMN_NAME = 'text'\n",
    "\n",
    "                \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            int: length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.conversations)\n",
    "\n",
    "    def __getitem__(self, idx) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Gets element of the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int): index of the element in the dataset\n",
    "        Returns:\n",
    "            Single element by index\n",
    "        \"\"\"        \n",
    "\n",
    "        conversation = self.conversations[idx]\n",
    "        conversation_id = conversation.attrib['id']\n",
    "        conversation_df = pd.DataFrame(columns = ['author', 'line', 'time', 'text'], dtype=str)\n",
    "\n",
    "        for message in conversation.findall('message'):\n",
    "            message_dict = {}\n",
    "            message_dict['line'] = message.attrib['line']\n",
    "            for field in message:\n",
    "                message_dict[field.tag] = field.text\n",
    "\n",
    "            conversation_df = conversation_df.append(message_dict, ignore_index=True)\n",
    "                \n",
    "        if self.preprocess_fn is not None:\n",
    "            conversation_df = self.preprocess_fn(conversation_df, self.TEXT_COLUMN_NAME, *self.preprocess_args)\n",
    "\n",
    "        return {'conversation_id': conversation_id, 'conversation': conversation_df}\n",
    "    \n",
    "    def _get_conversation_roots(self, file_path):\n",
    "        doc_tree = ET.parse(file_path)\n",
    "        conversation_roots = doc_tree.getroot().findall('conversation')\n",
    "        return conversation_roots\n",
    "\n",
    "    \n",
    "PAN12_DATA_FILE = Path('./ref_data/pan12_corpus/pan12-sexual-predator-identification-training-corpus-2012-05-01/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml')\n",
    "PAN12_LINE_LABELS_FILE = Path('./ref_data/pan12_corpus/pan12-sexual-predator-identification-training-corpus-2012-05-01/pan12-sexual-predator-identification-diff.txt')\n",
    "\n",
    "# preprocess_string_for_bow(text, stemmer=stemmer, speller=speller, words_to_remove=words_to_remove, emoticons=emoticons)\n",
    "preprocess_args = {'stemmer':stemmer, 'speller':speller, 'words_to_remove':words_to_remove, 'emoticons':emoticons}\n",
    "pan12_ds = Pan12Dataset(PAN12_DATA_FILE, preprocess_fn=preprocess_df_for_bow, preprocess_args=preprocess_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaa6bbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>line</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0c8dce20967cf80665e60051b8ab2d3c</td>\n",
       "      <td>1</td>\n",
       "      <td>17:40</td>\n",
       "      <td>jrossi: how do I make my peft tests working on...</td>\n",
       "      <td>rossi make left tests working ie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0c8dce20967cf80665e60051b8ab2d3c</td>\n",
       "      <td>2</td>\n",
       "      <td>17:40</td>\n",
       "      <td>it doesn't give any error messages or anything...</td>\n",
       "      <td>doesnt give error messages anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c8dce20967cf80665e60051b8ab2d3c</td>\n",
       "      <td>3</td>\n",
       "      <td>17:40</td>\n",
       "      <td>most of my perf tests don't work on IE9</td>\n",
       "      <td>perf tests dont work ie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0c8dce20967cf80665e60051b8ab2d3c</td>\n",
       "      <td>4</td>\n",
       "      <td>17:41</td>\n",
       "      <td>one reason seems to be that textContent isn't ...</td>\n",
       "      <td>one reason seems textcontent isnt implemented</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             author line   time  \\\n",
       "0  0c8dce20967cf80665e60051b8ab2d3c    1  17:40   \n",
       "1  0c8dce20967cf80665e60051b8ab2d3c    2  17:40   \n",
       "2  0c8dce20967cf80665e60051b8ab2d3c    3  17:40   \n",
       "3  0c8dce20967cf80665e60051b8ab2d3c    4  17:41   \n",
       "\n",
       "                                                text  \\\n",
       "0  jrossi: how do I make my peft tests working on...   \n",
       "1  it doesn't give any error messages or anything...   \n",
       "2            most of my perf tests don't work on IE9   \n",
       "3  one reason seems to be that textContent isn't ...   \n",
       "\n",
       "                                         stemmer  \n",
       "0               rossi make left tests working ie  \n",
       "1            doesnt give error messages anything  \n",
       "2                        perf tests dont work ie  \n",
       "3  one reason seems textcontent isnt implemented  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pan12_ds[45]['conversation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684810d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Line level dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab1a7b2",
   "metadata": {},
   "source": [
    "#### pan12 line level dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e64c6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pan12LineLevelDataloader():\n",
    "\n",
    "    # TODO: add labels!\n",
    "    \n",
    "    \"\"\"\n",
    "    Wrapper around Torch Dataset to perform text classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chat_data_file: Path, user_labels_file: Path=None, line_labels_file: Path=None, preprocess_fn=None, preprocess_args:Dict=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            chat_data_file: path to chat xml file\n",
    "            conversation_labels:\n",
    "            line_labels:  \n",
    "        \"\"\"\n",
    "       \n",
    "        self.chat_data_file = chat_data_file\n",
    "        self.conversations = self._get_conversation_roots(chat_data_file)\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        self.preprocess_args = preprocess_args\n",
    "\n",
    "        self.user_labels_file = user_labels_file\n",
    "        self.line_labels_file = line_labels_file\n",
    "        self.TEXT_COLUMN_NAME = 'text'\n",
    "\n",
    "        self.length = self._get_ds_length()\n",
    "        self.num_conversations = len(self.conversations)\n",
    "\n",
    "        # Initiate queue\n",
    "        self.message_list = None\n",
    "        self.current_conversation_id = None\n",
    "        self.next_conversation_idx = 0\n",
    "        self.next_message_idx = 0\n",
    "\n",
    "        # Create sets of problematic lines and authors for labels\n",
    "        user_labels = pd.read_csv(user_labels_file, delimiter='\\t', header=None)\n",
    "        self.perverted_authors = set(user_labels[0])\n",
    "\n",
    "        line_labels = pd.read_csv(line_labels_file, delimiter='\\t', header=None)\n",
    "        line_labels['concat'] = line_labels[0] + '_' + line_labels[1].astype(str)\n",
    "        self.pervert_lines = set(line_labels['concat'])\n",
    "\n",
    "        self.load_next_conversation_to_list()\n",
    "                       \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            int: length of the dataset\n",
    "        \"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __next__(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Gets element of the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int): index of the element in the dataset\n",
    "        Returns:\n",
    "            Single element by index\n",
    "        \"\"\"        \n",
    "        message_dict = {}\n",
    "        try:\n",
    "            message = self.message_list[self.next_message_idx]\n",
    "        except(IndexError):\n",
    "            self.load_next_conversation_to_list()\n",
    "            message = self.message_list[self.next_message_idx]\n",
    "\n",
    "        message_dict['conversation_id'] = self.current_conversation_id\n",
    "        self.next_message_idx += 1\n",
    "        \n",
    "        message_dict['line'] = message.attrib['line']  \n",
    "\n",
    "        for field in message:\n",
    "            message_dict[field.tag] = field.text\n",
    "        \n",
    "        if self.preprocess_fn is not None:\n",
    "            message_dict['text'] = self.preprocess_fn(message_dict['text'], **self.preprocess_args)\n",
    "        \n",
    "        message_dict['author_label'] = 1 if message_dict['author'] in self.perverted_authors else 0\n",
    "        message_dict['line_label'] = 1 if message_dict['conversation_id'] + '_' + message_dict['line'] in self.pervert_lines else 0\n",
    "\n",
    "        return message_dict\n",
    "    \n",
    "    def _get_conversation_roots(self, file_path):\n",
    "        doc_tree = ET.parse(file_path)\n",
    "        conversation_roots = doc_tree.getroot().findall('conversation')\n",
    "        return conversation_roots\n",
    "\n",
    "    def _get_ds_length(self):\n",
    "        number_messages = 0\n",
    "        for conversation in self.conversations:\n",
    "            number_messages += len(conversation.findall('message'))\n",
    "        \n",
    "        return number_messages\n",
    "\n",
    "    def load_next_conversation_to_list(self):\n",
    "        try:\n",
    "            conversation = self.conversations[self.next_conversation_idx] \n",
    "            self.current_conversation_id = conversation.attrib['id']  \n",
    "        except(IndexError):\n",
    "            raise StopIteration()\n",
    "\n",
    "        self.next_conversation_idx += 1\n",
    "        self.message_list = [m for m in conversation.findall('message')]\n",
    "        self.next_message_idx = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dfc77a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2058781\n",
      "0 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '1', 'author': '0a39f78bcb297ab0ebe8a29c28bfed89', 'time': '15:24', 'text': 'gmail bug 6978 new mark exterminated script elements malformed it', 'author_label': 0, 'line_label': 0}\n",
      "1 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '2', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:32', 'text': 'henri ask firebox build question windows', 'author_label': 0, 'line_label': 0}\n",
      "2 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '3', 'author': 'b8810fee2f4a71f849f3f7409546d1d9', 'time': '15:34', 'text': '60659cfda992013e610f285c46692d28 sure probably dont know answer', 'author_label': 0, 'line_label': 0}\n",
      "3 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '4', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:35', 'text': 'appears build runs creates firefoxexe dustbin', 'author_label': 0, 'line_label': 0}\n",
      "4 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '5', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:35', 'text': 'start get standard install of 3010 instead', 'author_label': 0, 'line_label': 0}\n",
      "5 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '6', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:35', 'text': 'make package unzip start', 'author_label': 0, 'line_label': 0}\n",
      "6 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '7', 'author': 'b8810fee2f4a71f849f3f7409546d1d9', 'time': '15:35', 'text': '60659cfda992013e610f285c46692d28 already usual firebox open', 'author_label': 0, 'line_label': 0}\n",
      "7 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '8', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:35', 'text': 'likely', 'author_label': 0, 'line_label': 0}\n",
      "8 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '9', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:36', 'text': 'need close instances', 'author_label': 0, 'line_label': 0}\n",
      "9 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '10', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:36', 'text': '', 'author_label': 0, 'line_label': 0}\n",
      "10 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '11', 'author': 'b8810fee2f4a71f849f3f7409546d1d9', 'time': '15:36', 'text': '60659cfda992013e610f285c46692d28 least linux version need', 'author_label': 0, 'line_label': 0}\n",
      "11 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '12', 'author': 'b8810fee2f4a71f849f3f7409546d1d9', 'time': '15:36', 'text': 'unless run different profile may advisable anyway', 'author_label': 0, 'line_label': 0}\n",
      "12 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '13', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:36', 'text': 'good point', 'author_label': 0, 'line_label': 0}\n",
      "13 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '14', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:37', 'text': 'gone moment due chatzilla', 'author_label': 0, 'line_label': 0}\n",
      "14 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '15', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:38', 'text': 'henri problem', 'author_label': 0, 'line_label': 0}\n",
      "15 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '16', 'author': 'b8810fee2f4a71f849f3f7409546d1d9', 'time': '15:40', 'text': 'ok good guess windows things linux behavior', 'author_label': 0, 'line_label': 0}\n",
      "16 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '17', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:43', 'text': 'ah yeah firebox annoying', 'author_label': 0, 'line_label': 0}\n",
      "17 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '18', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:44', 'text': '60659cfda992013e610f285c46692d28 merely citing message made seem thought we agreement', 'author_label': 0, 'line_label': 0}\n",
      "18 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '19', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:45', 'text': 'thought threshold criteria tracker maybe things changed', 'author_label': 0, 'line_label': 0}\n",
      "19 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '20', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:48', 'text': 'dont need we agreement add something tracker', 'author_label': 0, 'line_label': 0}\n",
      "20 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '21', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:49', 'text': 'thats im saying', 'author_label': 0, 'line_label': 0}\n",
      "21 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '22', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:49', 'text': 'particular author outstanding action action123 reply due 8 days ago', 'author_label': 0, 'line_label': 0}\n",
      "22 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '23', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:49', 'text': 'ian', 'author_label': 0, 'line_label': 0}\n",
      "23 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '24', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:50', 'text': 'yes', 'author_label': 0, 'line_label': 0}\n",
      "24 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '25', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:50', 'text': 'since nontelcon participants assigned action items', 'author_label': 0, 'line_label': 0}\n",
      "25 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '26', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:50', 'text': 'telco', 'author_label': 0, 'line_label': 0}\n",
      "26 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '27', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:50', 'text': '', 'author_label': 0, 'line_label': 0}\n",
      "27 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '28', 'author': '0a39f78bcb297ab0ebe8a29c28bfed89', 'time': '15:50', 'text': 'title action123 himl weekly tracker', 'author_label': 0, 'line_label': 0}\n",
      "28 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '29', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:50', 'text': 'let state differently agree taking action item', 'author_label': 0, 'line_label': 0}\n",
      "29 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '30', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:50', 'text': 'we protocol assign action items people agree taking', 'author_label': 0, 'line_label': 0}\n",
      "30 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '31', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:51', 'text': 'dont know think needs', 'author_label': 0, 'line_label': 0}\n",
      "31 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '32', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:51', 'text': 'based experience we id say agree', 'author_label': 0, 'line_label': 0}\n",
      "32 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '33', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:52', 'text': 'ok add unchartered stuff spec reply asked the reasons', 'author_label': 0, 'line_label': 0}\n",
      "33 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '34', 'author': 'b8810fee2f4a71f849f3f7409546d1d9', 'time': '15:54', 'text': 'agreement tracker item assigned thought protocol refuse zaki picked quotvictimquot', 'author_label': 0, 'line_label': 0}\n",
      "34 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '35', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:55', 'text': 'ignoring process moment wasnt added action we asks editor something think deserves answer', 'author_label': 0, 'line_label': 0}\n",
      "35 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '36', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:56', 'text': 'raised issue two weeks ago things take bit time', 'author_label': 0, 'line_label': 0}\n",
      "36 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '37', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:57', 'text': 'ian time add four chapters card calendar subtext atom probably also time explain', 'author_label': 0, 'line_label': 0}\n",
      "37 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '38', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:57', 'text': 'catch arc probably ask prioritize somewhat timely response important', 'author_label': 0, 'line_label': 0}\n",
      "38 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '39', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:58', 'text': 'think fact theres overdue action sufficient information we wants feedback', 'author_label': 0, 'line_label': 0}\n",
      "39 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '40', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:58', 'text': 'seems followed microdot use cases requirements discussion', 'author_label': 0, 'line_label': 0}\n",
      "40 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '41', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '15:58', 'text': '60659cfda992013e610f285c46692d28 doubt even knows action item assigned', 'author_label': 0, 'line_label': 0}\n",
      "41 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '42', 'author': '60659cfda992013e610f285c46692d28', 'time': '15:59', 'text': 'hes attending telco reading minutes', 'author_label': 0, 'line_label': 0}\n",
      "42 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '43', 'author': 'b25b6b77a0087ff8385941e5545d32ea', 'time': '15:59', 'text': '60659cfda992013e610f285c46692d28 worth think answer question justbecause allows use cases rich drag drop clipboard itemsquot fulfilled', 'author_label': 0, 'line_label': 0}\n",
      "43 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '44', 'author': 'b25b6b77a0087ff8385941e5545d32ea', 'time': '16:00', 'text': 'although obviously offical answer', 'author_label': 0, 'line_label': 0}\n",
      "44 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '45', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '16:00', 'text': '60659cfda992013e610f285c46692d28 seems like quite leap knowing action item', 'author_label': 0, 'line_label': 0}\n",
      "45 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '46', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '16:01', 'text': 'experience ian always action items time', 'author_label': 0, 'line_label': 0}\n",
      "46 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '47', 'author': 'b25b6b77a0087ff8385941e5545d32ea', 'time': '16:02', 'text': '60659cfda992013e610f285c46692d28 whilst think makes sense consider taking specific mocrodata bits himl 5 keeping damp stuff would make specs codependent im sure youd gain much', 'author_label': 0, 'line_label': 0}\n",
      "47 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '48', 'author': 'b25b6b77a0087ff8385941e5545d32ea', 'time': '16:02', 'text': 'microdot', 'author_label': 0, 'line_label': 0}\n",
      "48 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '49', 'author': 'b25b6b77a0087ff8385941e5545d32ea', 'time': '16:02', 'text': 'amongst errors', 'author_label': 0, 'line_label': 0}\n",
      "49 {'conversation_id': 'affc2df0951b733d14ba92d19d9b7695', 'line': '50', 'author': 'edb259c0e0038f38bb200bc20c8cbf7e', 'time': '16:06', 'text': 'gives finding rules action items', 'author_label': 0, 'line_label': 0}\n",
      "50 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '1', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:28', 'text': 'back', 'author_label': 0, 'line_label': 0}\n",
      "51 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '2', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '19:28', 'text': 'ok babe', 'author_label': 1, 'line_label': 0}\n",
      "52 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '3', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '19:28', 'text': 'happend babe', 'author_label': 1, 'line_label': 0}\n",
      "53 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '4', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:28', 'text': 'dog wanted i took runnin street', 'author_label': 0, 'line_label': 0}\n",
      "54 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '5', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '19:29', 'text': 'oh man hate kinda god', 'author_label': 1, 'line_label': 0}\n",
      "55 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '6', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:29', 'text': 'dashing', 'author_label': 0, 'line_label': 0}\n",
      "56 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '7', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '19:30', 'text': 'see pitbull hes sweet heart', 'author_label': 1, 'line_label': 0}\n",
      "57 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '8', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:30', 'text': 'cool', 'author_label': 0, 'line_label': 0}\n",
      "58 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '9', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '19:30', 'text': 'thinks small dog', 'author_label': 1, 'line_label': 0}\n",
      "59 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '10', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:30', 'text': 'laughing loud', 'author_label': 0, 'line_label': 0}\n",
      "60 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '11', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:30', 'text': 'like 2 sit i lap', 'author_label': 0, 'line_label': 0}\n",
      "61 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '12', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '19:32', 'text': 'way would stretch take couch', 'author_label': 1, 'line_label': 0}\n",
      "62 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '13', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:32', 'text': 'laughing loud', 'author_label': 0, 'line_label': 0}\n",
      "63 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '14', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '19:35', 'text': 'want see baby pics', 'author_label': 1, 'line_label': 0}\n",
      "64 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '15', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:37', 'text': 'awwwww', 'author_label': 0, 'line_label': 0}\n",
      "65 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '16', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:37', 'text': 'hes sooooo cute', 'author_label': 0, 'line_label': 0}\n",
      "66 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '17', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:38', 'text': 'one opened', 'author_label': 0, 'line_label': 0}\n",
      "67 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '18', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:38', 'text': '2 didnt', 'author_label': 0, 'line_label': 0}\n",
      "68 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '19', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '19:39', 'text': 'ok', 'author_label': 1, 'line_label': 0}\n",
      "69 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '20', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '19:41', 'text': 'hes tiny', 'author_label': 0, 'line_label': 0}\n",
      "70 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '21', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '19:41', 'text': 'yeah', 'author_label': 1, 'line_label': 0}\n",
      "71 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '22', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:03', 'text': 'ya doin', 'author_label': 0, 'line_label': 0}\n",
      "72 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '23', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:03', 'text': 'wondering baby', 'author_label': 1, 'line_label': 0}\n",
      "73 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '24', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:04', 'text': '', 'author_label': 0, 'line_label': 0}\n",
      "74 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '25', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:04', 'text': 'ok', 'author_label': 1, 'line_label': 0}\n",
      "75 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '26', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:14', 'text': '', 'author_label': 0, 'line_label': 0}\n",
      "76 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '27', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:14', 'text': '', 'author_label': 1, 'line_label': 0}\n",
      "77 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '28', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:15', 'text': 'know baby soooo awesome', 'author_label': 1, 'line_label': 0}\n",
      "78 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '29', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:16', 'text': 'thanks', 'author_label': 0, 'line_label': 0}\n",
      "79 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '30', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:16', 'text': 'yw', 'author_label': 1, 'line_label': 0}\n",
      "80 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '31', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:37', 'text': 'eat supper yet', 'author_label': 0, 'line_label': 0}\n",
      "81 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '32', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:37', 'text': \"yeah ordered papajohn's pizza baby\", 'author_label': 1, 'line_label': 0}\n",
      "82 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '33', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:38', 'text': 'gonna go eat', 'author_label': 0, 'line_label': 0}\n",
      "83 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '34', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:38', 'text': 'i later', 'author_label': 0, 'line_label': 0}\n",
      "84 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '35', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:38', 'text': 'ok babby eating', 'author_label': 1, 'line_label': 0}\n",
      "85 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '36', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:38', 'text': 'chicken', 'author_label': 0, 'line_label': 0}\n",
      "86 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '37', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:38', 'text': 'mom', 'author_label': 1, 'line_label': 0}\n",
      "87 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '38', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:38', 'text': 'back later', 'author_label': 0, 'line_label': 0}\n",
      "88 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '39', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:39', 'text': '', 'author_label': 0, 'line_label': 0}\n",
      "89 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '40', 'author': 'b6fe182274453b707870b16e5d2ad562', 'time': '20:39', 'text': 'po', 'author_label': 0, 'line_label': 0}\n",
      "90 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '41', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:39', 'text': 'ok', 'author_label': 1, 'line_label': 0}\n",
      "91 {'conversation_id': 'de15188e9fd515ed817a0b34546be902', 'line': '42', 'author': '4a9332d7466b98d11c23e4447b26460a', 'time': '20:39', 'text': '', 'author_label': 1, 'line_label': 0}\n",
      "92 {'conversation_id': '17784c5a093477c1706b1a68cea7c802', 'line': '1', 'author': '713349f3afa2dbe352d2abe4d3f01a12', 'time': '03:10', 'text': 'hello', 'author_label': 0, 'line_label': 0}\n",
      "93 {'conversation_id': '17784c5a093477c1706b1a68cea7c802', 'line': '2', 'author': 'fcfda042c76436b97eca32b6c0490d1d', 'time': '03:10', 'text': 'boys shit', 'author_label': 0, 'line_label': 0}\n",
      "94 {'conversation_id': '17784c5a093477c1706b1a68cea7c802', 'line': '3', 'author': '713349f3afa2dbe352d2abe4d3f01a12', 'time': '03:10', 'text': '', 'author_label': 0, 'line_label': 0}\n",
      "95 {'conversation_id': '17784c5a093477c1706b1a68cea7c802', 'line': '4', 'author': 'fcfda042c76436b97eca32b6c0490d1d', 'time': '03:10', 'text': 'hi', 'author_label': 0, 'line_label': 0}\n",
      "96 {'conversation_id': '17784c5a093477c1706b1a68cea7c802', 'line': '5', 'author': 'fcfda042c76436b97eca32b6c0490d1d', 'time': '03:10', 'text': 'sorry', 'author_label': 0, 'line_label': 0}\n",
      "97 {'conversation_id': '17784c5a093477c1706b1a68cea7c802', 'line': '6', 'author': 'fcfda042c76436b97eca32b6c0490d1d', 'time': '03:10', 'text': 'angry', 'author_label': 0, 'line_label': 0}\n",
      "98 {'conversation_id': '17784c5a093477c1706b1a68cea7c802', 'line': '7', 'author': 'fcfda042c76436b97eca32b6c0490d1d', 'time': '03:10', 'text': '', 'author_label': 0, 'line_label': 0}\n",
      "99 {'conversation_id': '17784c5a093477c1706b1a68cea7c802', 'line': '8', 'author': 'fcfda042c76436b97eca32b6c0490d1d', 'time': '03:10', 'text': '', 'author_label': 0, 'line_label': 0}\n",
      "100 {'conversation_id': '17784c5a093477c1706b1a68cea7c802', 'line': '9', 'author': '713349f3afa2dbe352d2abe4d3f01a12', 'time': '03:11', 'text': 'quite alright get way occasion', 'author_label': 0, 'line_label': 0}\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "preprocess_args = {'stemmer':stemmer, 'speller':speller, 'words_to_remove':words_to_remove, 'emoticons':emoticons}\n",
    "pan12_ds = Pan12LineLevelDataloader(PAN12_DATA_FILE, user_labels_file=PAN12_USER_LABELS_FILE, line_labels_file=PAN12_LINE_LABELS_FILE, preprocess_fn=preprocess_string_for_bow, preprocess_args=preprocess_args)\n",
    "print(len(pan12_ds))\n",
    "\n",
    "for i, m in enumerate(pan12_ds):\n",
    "    print(i, m) \n",
    "    if i==100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa278e",
   "metadata": {},
   "source": [
    "### Convert Pan12 to labeled datafreame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d0e52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pan12converterToDF():\n",
    "\n",
    "    # TODO: add labels!\n",
    "    \n",
    "    \"\"\"\n",
    "    Wrapper around Torch Dataset to perform text classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chat_data_file: Path, user_labels_file: Path=None, line_labels_file: Path=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            chat_data_file: path to chat xml file\n",
    "            conversation_labels:\n",
    "            line_labels:  \n",
    "        \"\"\"\n",
    "       \n",
    "        self.chat_data_file = chat_data_file\n",
    "        self.conversations = self._get_conversation_roots(chat_data_file)\n",
    "\n",
    "        self.user_labels_file = user_labels_file\n",
    "        self.line_labels_file = line_labels_file\n",
    "        self.TEXT_COLUMN_NAME = 'text'\n",
    "\n",
    "        self.length = self._get_ds_length()\n",
    "        self.num_conversations = len(self.conversations)\n",
    "\n",
    "        # Initiate queue\n",
    "        self.message_list = None\n",
    "        self.current_conversation_id = None\n",
    "        self.next_conversation_idx = 0\n",
    "        self.next_message_idx = 0\n",
    "\n",
    "        # Create sets of problematic lines and authors for labels\n",
    "        user_labels = pd.read_csv(user_labels_file, delimiter='\\t', header=None)\n",
    "        self.perverted_authors = set(user_labels[0])\n",
    "\n",
    "        line_labels = pd.read_csv(line_labels_file, delimiter='\\t', header=None)\n",
    "        line_labels['concat'] = line_labels[0] + '_' + line_labels[1].astype(str)\n",
    "        self.pervert_lines = set(line_labels['concat'])\n",
    "\n",
    "        self.load_next_conversation_to_list() \n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            int: length of the dataset\n",
    "        \"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def convert(self, filename:Path) -> pd.DataFrame:\n",
    "        \"\"\"Gets element of the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int): index of the element in the dataset\n",
    "        Returns:\n",
    "            Single element by index\n",
    "        \"\"\"        \n",
    "        \n",
    "        pan12_df = pd.DataFrame(columns=['conversation_id', 'line', 'author', 'time', 'text', 'line_label', 'author_label'])\n",
    "        for i in tqdm(range(self.length)):\n",
    "            message_dict = {}\n",
    "            try:\n",
    "                message = self.message_list[self.next_message_idx]\n",
    "            except(IndexError):\n",
    "                self.load_next_conversation_to_list()\n",
    "                message = self.message_list[self.next_message_idx]\n",
    "            \n",
    "            message_dict['conversation_id'] = self.current_conversation_id\n",
    "            self.next_message_idx += 1\n",
    "            \n",
    "            message_dict['line'] = message.attrib['line']  \n",
    "            for field in message:\n",
    "                message_dict[field.tag] = field.text\n",
    "            \n",
    "            message_dict['author_label'] = 1 if message_dict['author'] in self.perverted_authors else 0\n",
    "            message_dict['line_label'] = 1 if message_dict['conversation_id'] + '_' + message_dict['line'] in self.pervert_lines else 0\n",
    "            \n",
    "            pan12_df = pan12_df.append(message_dict, ignore_index=True)\n",
    "            if i % 1000 == 0:\n",
    "                pan12_df.to_csv(filename)\n",
    "                print('.', end='')\n",
    "\n",
    "            # #######\n",
    "            # if i == 2001:\n",
    "            #     print(pan12_df.head(100))\n",
    "            #     break\n",
    "            # ######\n",
    "        pan12_df.to_csv(filename)\n",
    "        return pan12_df\n",
    "    \n",
    "    def _get_conversation_roots(self, file_path):\n",
    "        doc_tree = ET.parse(file_path)\n",
    "        conversation_roots = doc_tree.getroot().findall('conversation')\n",
    "        return conversation_roots\n",
    "\n",
    "    def _get_ds_length(self):\n",
    "        number_messages = 0\n",
    "        for conversation in self.conversations:\n",
    "            number_messages += len(conversation.findall('message'))\n",
    "        \n",
    "        return number_messages\n",
    "\n",
    "    def load_next_conversation_to_list(self):\n",
    "        try:\n",
    "            conversation = self.conversations[self.next_conversation_idx] \n",
    "            self.current_conversation_id = conversation.attrib['id']  \n",
    "        except(IndexError):\n",
    "            raise StopIteration()\n",
    "\n",
    "        self.next_conversation_idx += 1\n",
    "        self.message_list = [m for m in conversation.findall('message')]\n",
    "        self.next_message_idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92dd4938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2058781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fb3bdf227840e8b7877fea6368714a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2058781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...                     conversation_id line                            author  \\\n",
      "0   affc2df0951b733d14ba92d19d9b7695    1  0a39f78bcb297ab0ebe8a29c28bfed89   \n",
      "1   affc2df0951b733d14ba92d19d9b7695    2  60659cfda992013e610f285c46692d28   \n",
      "2   affc2df0951b733d14ba92d19d9b7695    3  b8810fee2f4a71f849f3f7409546d1d9   \n",
      "3   affc2df0951b733d14ba92d19d9b7695    4  60659cfda992013e610f285c46692d28   \n",
      "4   affc2df0951b733d14ba92d19d9b7695    5  60659cfda992013e610f285c46692d28   \n",
      "..                               ...  ...                               ...   \n",
      "95  17784c5a093477c1706b1a68cea7c802    4  fcfda042c76436b97eca32b6c0490d1d   \n",
      "96  17784c5a093477c1706b1a68cea7c802    5  fcfda042c76436b97eca32b6c0490d1d   \n",
      "97  17784c5a093477c1706b1a68cea7c802    6  fcfda042c76436b97eca32b6c0490d1d   \n",
      "98  17784c5a093477c1706b1a68cea7c802    7  fcfda042c76436b97eca32b6c0490d1d   \n",
      "99  17784c5a093477c1706b1a68cea7c802    8  fcfda042c76436b97eca32b6c0490d1d   \n",
      "\n",
      "     time                                               text line_label  \\\n",
      "0   15:24  bugmail: [Bug 6978] New: Mark eof-terminated s...          0   \n",
      "1   15:32  Henri, can I ask you a Firefox build question ...          0   \n",
      "2   15:34  60659cfda992013e610f285c46692d28: sure, but I ...          0   \n",
      "3   15:35  It appears the build runs through, it creates ...          0   \n",
      "4   15:35  when I start it, I get my standard install of ...          0   \n",
      "..    ...                                                ...        ...   \n",
      "95  03:10                                                 hi          0   \n",
      "96  03:10                                              sorry          0   \n",
      "97  03:10                                   i was just angry          0   \n",
      "98  03:10                                               what          0   \n",
      "99  03:10                                                  ?          0   \n",
      "\n",
      "   author_label  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "..          ...  \n",
      "95            0  \n",
      "96            0  \n",
      "97            0  \n",
      "98            0  \n",
      "99            0  \n",
      "\n",
      "[100 rows x 7 columns]\n",
      "2002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>line</th>\n",
       "      <th>author</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>line_label</th>\n",
       "      <th>author_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>affc2df0951b733d14ba92d19d9b7695</td>\n",
       "      <td>1</td>\n",
       "      <td>0a39f78bcb297ab0ebe8a29c28bfed89</td>\n",
       "      <td>15:24</td>\n",
       "      <td>bugmail: [Bug 6978] New: Mark eof-terminated s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>affc2df0951b733d14ba92d19d9b7695</td>\n",
       "      <td>2</td>\n",
       "      <td>60659cfda992013e610f285c46692d28</td>\n",
       "      <td>15:32</td>\n",
       "      <td>Henri, can I ask you a Firefox build question ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>affc2df0951b733d14ba92d19d9b7695</td>\n",
       "      <td>3</td>\n",
       "      <td>b8810fee2f4a71f849f3f7409546d1d9</td>\n",
       "      <td>15:34</td>\n",
       "      <td>60659cfda992013e610f285c46692d28: sure, but I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>affc2df0951b733d14ba92d19d9b7695</td>\n",
       "      <td>4</td>\n",
       "      <td>60659cfda992013e610f285c46692d28</td>\n",
       "      <td>15:35</td>\n",
       "      <td>It appears the build runs through, it creates ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affc2df0951b733d14ba92d19d9b7695</td>\n",
       "      <td>5</td>\n",
       "      <td>60659cfda992013e610f285c46692d28</td>\n",
       "      <td>15:35</td>\n",
       "      <td>when I start it, I get my standard install of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>17784c5a093477c1706b1a68cea7c802</td>\n",
       "      <td>4</td>\n",
       "      <td>fcfda042c76436b97eca32b6c0490d1d</td>\n",
       "      <td>03:10</td>\n",
       "      <td>hi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>17784c5a093477c1706b1a68cea7c802</td>\n",
       "      <td>5</td>\n",
       "      <td>fcfda042c76436b97eca32b6c0490d1d</td>\n",
       "      <td>03:10</td>\n",
       "      <td>sorry</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17784c5a093477c1706b1a68cea7c802</td>\n",
       "      <td>6</td>\n",
       "      <td>fcfda042c76436b97eca32b6c0490d1d</td>\n",
       "      <td>03:10</td>\n",
       "      <td>i was just angry</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>17784c5a093477c1706b1a68cea7c802</td>\n",
       "      <td>7</td>\n",
       "      <td>fcfda042c76436b97eca32b6c0490d1d</td>\n",
       "      <td>03:10</td>\n",
       "      <td>what</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>17784c5a093477c1706b1a68cea7c802</td>\n",
       "      <td>8</td>\n",
       "      <td>fcfda042c76436b97eca32b6c0490d1d</td>\n",
       "      <td>03:10</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     conversation_id line                            author  \\\n",
       "0   affc2df0951b733d14ba92d19d9b7695    1  0a39f78bcb297ab0ebe8a29c28bfed89   \n",
       "1   affc2df0951b733d14ba92d19d9b7695    2  60659cfda992013e610f285c46692d28   \n",
       "2   affc2df0951b733d14ba92d19d9b7695    3  b8810fee2f4a71f849f3f7409546d1d9   \n",
       "3   affc2df0951b733d14ba92d19d9b7695    4  60659cfda992013e610f285c46692d28   \n",
       "4   affc2df0951b733d14ba92d19d9b7695    5  60659cfda992013e610f285c46692d28   \n",
       "..                               ...  ...                               ...   \n",
       "95  17784c5a093477c1706b1a68cea7c802    4  fcfda042c76436b97eca32b6c0490d1d   \n",
       "96  17784c5a093477c1706b1a68cea7c802    5  fcfda042c76436b97eca32b6c0490d1d   \n",
       "97  17784c5a093477c1706b1a68cea7c802    6  fcfda042c76436b97eca32b6c0490d1d   \n",
       "98  17784c5a093477c1706b1a68cea7c802    7  fcfda042c76436b97eca32b6c0490d1d   \n",
       "99  17784c5a093477c1706b1a68cea7c802    8  fcfda042c76436b97eca32b6c0490d1d   \n",
       "\n",
       "     time                                               text line_label  \\\n",
       "0   15:24  bugmail: [Bug 6978] New: Mark eof-terminated s...          0   \n",
       "1   15:32  Henri, can I ask you a Firefox build question ...          0   \n",
       "2   15:34  60659cfda992013e610f285c46692d28: sure, but I ...          0   \n",
       "3   15:35  It appears the build runs through, it creates ...          0   \n",
       "4   15:35  when I start it, I get my standard install of ...          0   \n",
       "..    ...                                                ...        ...   \n",
       "95  03:10                                                 hi          0   \n",
       "96  03:10                                              sorry          0   \n",
       "97  03:10                                   i was just angry          0   \n",
       "98  03:10                                               what          0   \n",
       "99  03:10                                                  ?          0   \n",
       "\n",
       "   author_label  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "..          ...  \n",
       "95            0  \n",
       "96            0  \n",
       "97            0  \n",
       "98            0  \n",
       "99            0  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Test converter\n",
    "\n",
    "# pan12_converter = Pan12converterToDF(PAN12_DATA_FILE, user_labels_file=PAN12_USER_LABELS_FILE, line_labels_file=PAN12_LINE_LABELS_FILE)\n",
    "# print(len(pan12_converter))\n",
    "# pan12_df = pan12_converter.convert(OUTPUT_FOLDER / Path('pan12_csv.zip'))\n",
    "# print(len(pan12_df))\n",
    "# pan12_df.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f319750",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TF/IDF - Not started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(dataset)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d684c5",
   "metadata": {},
   "source": [
    "## some thoughts\n",
    "Bag of words - sexual words, fear, trust, family, approach (Location, transport) , other categories - DrouinBoydHancockJames2017\n",
    "Good article: file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/Early%20Text%20Classification%20using%20Multi-Resolution%20Concept%20Representations.pdf\n",
    "Ensamble and preprocessing: file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/PredatoryConversationDetection.pdf\n",
    "file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/Analyzing_Chat_Conversations_of_Pedophil.pdf\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a8e22f9a50968eda7c2b2da6b1cd647c6294c71990fbcb0be47dbd614eb6ed8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
