{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e0cd8b4e",
      "metadata": {
        "id": "e0cd8b4e"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "* Detect predetorial patterns in other side chat messages, alert parents / block chat\n",
        "    - Per message\n",
        "    - Sequence\n",
        "    - Media\n",
        "* Detect and warn / block personal information giveaway by own side of chat (Child)\n",
        "    - text\n",
        "    - media\n",
        "* Support 2 party / multiple party chats\n",
        "* Block known predators from past chats\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4754d185",
      "metadata": {
        "id": "4754d185"
      },
      "source": [
        "\n",
        "## Flow control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9313de52",
      "metadata": {
        "id": "9313de52"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Options:\n",
        "Each element can be either 'Process' or 'Load'\n",
        "'''\n",
        "\n",
        "# Dataframe creation from raw XMLs\n",
        "CREATE_FULL_PJ_CONVERSATIONS_DATAFRAME = 'Load'\n",
        "CREATE_FULL_PAN12_DATAFRAME = 'Load'\n",
        "\n",
        "# Dataframe preprocessing\n",
        "PREPROCESS_FULL_PAN12_DATAFRAME = 'Load'\n",
        "PREPROCESS_FULL_PJ_DATAFRAME = 'Load'\n",
        "\n",
        "# LDA topic model classifier on Pan12 - single manual steps\n",
        "PAN12_TOPIC_MODEL_CORPUS = 'Process'\n",
        "\n",
        "# LDA topic model classifier on Pan12 - Automatic grid search\n",
        "GRID_SEARCH_LDA_RFC = 'Process'\n",
        "GRID_SEARCH_LDA_GB = 'Process'\n",
        "\n",
        "\n",
        "##########################################################\n",
        "# Obsolete - code under backup section\n",
        "PAN12_TOPIC_MODEL = 'Process'\n",
        "PAN12_TOPIC_MODEL_RF = 'Process'\n",
        "CREATE_FULL_PJ_DATAFRAME_SENTENCE_LEVEL = 'Load'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f086e0e1",
      "metadata": {
        "id": "f086e0e1",
        "tags": []
      },
      "source": [
        "## General - imports paths etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "X7ncp3Hf4hJX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ncp3Hf4hJX",
        "outputId": "d3b65350-f0b8-4afb-bcde-a85566b96cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.7/dist-packages (0.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 590 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2022.5.18.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair) (0.11.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair) (0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from altair) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from altair) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair) (2.11.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair) (4.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->altair) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->altair) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->altair) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspellchecker\n",
        "!python -m spacy download en_core_web_sm\n",
        "%pip install pyLDAvis\n",
        "%pip install altair\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98514e4d",
      "metadata": {
        "id": "98514e4d"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "683f43e6-ff1c-4c28-af4c-3452553fc476",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "683f43e6-ff1c-4c28-af4c-3452553fc476",
        "outputId": "cac5ff83-9e38-4b94-bbd6-edbda15179f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "tqdm.pandas()\n",
        "from ipywidgets import IntProgress\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import altair\n",
        "\n",
        "# from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.corpora as corpora\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "import spacy\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "import xml.etree.ElementTree as ET \n",
        "from xml.etree.ElementTree import ParseError\n",
        "\n",
        "import csv\n",
        "\n",
        "from typing import Dict, Callable, List, Dict, Set, Any\n",
        "import logging\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m3FuuqiQ2Sk3",
      "metadata": {
        "id": "m3FuuqiQ2Sk3"
      },
      "source": [
        "### Env control and folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "LAmVCG5d2Y-M",
      "metadata": {
        "id": "LAmVCG5d2Y-M"
      },
      "outputs": [],
      "source": [
        "ENV = 'Colab'\n",
        "# ENV = 'Local'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bf9de114-ddde-43d7-9d6a-69d1b0a913d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf9de114-ddde-43d7-9d6a-69d1b0a913d0",
        "outputId": "79f7ed1a-c924-4027-c7f1-f3586653c0f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Folders\n",
        "if ENV=='Local':\n",
        "  PROJECT_ROOT = Path('./')\n",
        "\n",
        "elif ENV=='Colab':\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  PROJECT_ROOT = Path('/content/drive/MyDrive/colab_data/cyber2/')\n",
        "  \n",
        "\n",
        "PJ_DATA_FOLDER = PROJECT_ROOT / Path('customer_data')\n",
        "PAN12_TEST_DATA_FILE = PROJECT_ROOT / Path('ref_data/pan12_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml')\n",
        "PAN12_LINE_LABELS_FILE = PROJECT_ROOT / Path('ref_data/pan12_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-groundtruth-problem2.txt')\n",
        "PAN12_USER_LABELS_FILE = PROJECT_ROOT / Path('ref_data/pan12_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-groundtruth-problem1.txt')\n",
        "\n",
        "PAN12_TRAIN_DATA_FILE = PROJECT_ROOT / Path('ref_data/pan12_corpus/pan12-sexual-predator-identification-training-corpus-2012-05-01/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml')\n",
        "PAN12_TRAIN_USER_LABELS_FILE = PROJECT_ROOT / Path('ref_data/pan12_corpus/pan12-sexual-predator-identification-training-corpus-2012-05-01/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt')\n",
        "\n",
        "\n",
        "OUTPUT_FOLDER = PROJECT_ROOT / Path('output')\n",
        "\n",
        "if not PAN12_TEST_DATA_FILE.exists():\n",
        "    raise FileNotFoundError('File not found!')\n",
        "\n",
        "if not PAN12_LINE_LABELS_FILE.exists():\n",
        "    raise FileNotFoundError('File not found!')  \n",
        "\n",
        "if not PAN12_USER_LABELS_FILE.exists():\n",
        "    raise FileNotFoundError('File not found!') \n",
        "\n",
        "if not PJ_DATA_FOLDER.is_dir():\n",
        "    raise FileNotFoundError('Directry not found!') \n",
        "\n",
        "if not OUTPUT_FOLDER.is_dir():\n",
        "    print(f'creating output folder: {OUTPUT_FOLDER}')\n",
        "    OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "037ad22d",
      "metadata": {
        "id": "037ad22d"
      },
      "source": [
        "### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eaf51658",
      "metadata": {
        "id": "eaf51658"
      },
      "outputs": [],
      "source": [
        "# Define datasets with texts and labels\n",
        "\n",
        "def list_files_in_dir(folder: Path, extension='*') -> List:\n",
        "    \n",
        "    file_list = [f for f in folder.glob(f'**/*.{extension}') if f.is_file()]\n",
        "    return file_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8f4bc9ce",
      "metadata": {
        "id": "8f4bc9ce"
      },
      "outputs": [],
      "source": [
        "def unify_csv_dataframes_to_one_sorted(csv_parts_folder: Path, target_csv_path=None)-> pd.DataFrame:\n",
        "    '''\n",
        "    Gets:\n",
        "        csv_parts_folder - Path of folder with partial df CSV files\n",
        "        target_csv_path - (optional) - path to save unified CSV\n",
        "\n",
        "    Returns:\n",
        "        Unified PD dataframe with all csvs concatenated on axis 0\n",
        "    '''\n",
        "\n",
        "    file_list = list_files_in_dir(csv_parts_folder, extension='csv')\n",
        "    ordered_filenames = sorted([str(filename) for filename in file_list])\n",
        "    ordered_file_list = [Path(filename) for filename in ordered_filenames]\n",
        "    print(f'Found {len(ordered_file_list)} files to unify')\n",
        "\n",
        "    unified_df = None\n",
        "    for file in ordered_file_list:\n",
        "        part_df = pd.read_csv(file, header=0, index_col=0)\n",
        "\n",
        "        if unified_df is not None:\n",
        "            unified_df = pd.concat([unified_df, part_df], axis=0)\n",
        "        else:\n",
        "            unified_df = part_df\n",
        "\n",
        "    if target_csv_path is not None:\n",
        "        unified_df.to_csv(target_csv_path)\n",
        "    \n",
        "    return unified_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "065d0df3",
      "metadata": {
        "id": "065d0df3"
      },
      "source": [
        "### Load word lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "70954f6b",
      "metadata": {
        "id": "70954f6b"
      },
      "outputs": [],
      "source": [
        "# Load word lists\n",
        "SEX_WL_PATH = PROJECT_ROOT / Path(r'sex_words.txt')\n",
        "with open(SEX_WL_PATH, 'rt') as handle:\n",
        "    sex_word_list = handle.read().split('\\n')\n",
        "\n",
        "MEETING_WL_PATH = SEX_WL_PATH = PROJECT_ROOT / Path(r'meeting_words.txt')\n",
        "with open(MEETING_WL_PATH, 'rt') as handle:\n",
        "    meeting_word_list = handle.read().split('\\n')\n",
        "\n",
        "FAMILY_WL_PATH = SEX_WL_PATH = PROJECT_ROOT / Path(r'family_words.txt')\n",
        "with open(FAMILY_WL_PATH, 'rt') as handle:\n",
        "    family_word_list = handle.read().split('\\n')\n",
        "\n",
        "CHAT_SLANG_PATH = SEX_WL_PATH = PROJECT_ROOT / Path(r'chat_slang.txt')\n",
        "with open(CHAT_SLANG_PATH, mode='rt') as handle:\n",
        "    csv_reader = csv.reader(handle, delimiter='\\t')\n",
        "    chat_slang = {rows[0]:rows[1] for rows in csv_reader}\n",
        "\n",
        "EMOTICONS_PATH = SEX_WL_PATH = PROJECT_ROOT / Path(r'emoticons.txt')\n",
        "with open(EMOTICONS_PATH, mode='rt', encoding=\"utf8\") as handle:\n",
        "    csv_reader = csv.reader(handle, delimiter='\\t')\n",
        "    emoticons = {rows[0]:rows[1] for rows in csv_reader}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0844b40",
      "metadata": {
        "id": "b0844b40",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e182ed0",
      "metadata": {
        "id": "3e182ed0",
        "tags": []
      },
      "source": [
        "### Chat text preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "34d2873c",
      "metadata": {
        "id": "34d2873c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a451ebb-8aca-43e8-e0b4-0bc2cc9894a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "<ipython-input-9-b7f45eb76567>:76: DeprecationWarning: invalid escape sequence \\w\n",
            "  text_words = re.sub(\"[^\\w]\", \" \",  text).split()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def remove_stopwords(text: str, words_to_remove: List[str])-> str:\n",
        "    '''\n",
        "    Gets string, returns it without stopwords\n",
        "    '''\n",
        "    return \" \".join([word for word in str(text).split() if word not in words_to_remove])\n",
        "\n",
        "\n",
        "def stem_text(text: str, stemmer: Any)-> str:\n",
        "    '''\n",
        "    stem text string\n",
        "    '''\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "\n",
        "def remove_emoji(text: str) -> str:\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "def remove_emoticons(text: str, emoticons: Dict) -> str:\n",
        "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in emoticons) + u')')\n",
        "    return emoticon_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "def replace_pornsites_with_string(text:str, replacement_string:str='porn')->str:\n",
        "    pornsite_pattern = re.compile(r'\\S+xnxx\\.co\\S+' + r'|\\S+pornhub\\.co\\S+' + r'|\\S+nude\\.co\\S+' + r'|\\S+sex\\.co\\S+')\n",
        "    return pornsite_pattern.sub(replacement_string, text)\n",
        "\n",
        "def remove_urls(text:str)-> str:\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "def remove_special_characters(text:str)-> str:\n",
        "    special_chars_pattern = re.compile(r'[^A-Za-z0-9 ]+')\n",
        "    return special_chars_pattern.sub(r' ', text)\n",
        "\n",
        "\n",
        "def replace_chat_slang(text: str, chat_slang: Dict[str, str])-> str:\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_slang.keys():\n",
        "            new_text.append(chat_slang[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)\n",
        "\n",
        "\n",
        "def correct_spellings(text: str, speller: Callable) -> str:\n",
        "    corrected_text = []\n",
        "    misspelled_words = speller.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(speller.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "    return \" \".join(corrected_text)\n",
        "\n",
        "\n",
        "def lemmation(text:str, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    nlp_lem = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "    result = nlp_lem(text)\n",
        "    result = [token.lemma_ for token in result if token.pos_ in allowed_postags]\n",
        "    return  \" \".join(result)\n",
        "\n",
        "\n",
        "def contains_words_from_list(text: str, word_list: List[str])-> bool:\n",
        "    text_words = re.sub(\"[^\\w]\", \" \",  text).split()\n",
        "    if any(word in word_list for word in text_words):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def preprocess_string_for_bow(text: str, stemmer: Callable=None, speller: Callable=None, words_to_remove:List[str]=None, emoticons: Dict[str, str]=None, chat_slang: Dict[str, str]=None)-> str:\n",
        "    try:\n",
        "        # text = remove_emoji(text)\n",
        "        # text = remove_emoticons(text, emoticons)\n",
        "        text = text.lower()\n",
        "        text = replace_chat_slang(text, chat_slang)\n",
        "        text = replace_pornsites_with_string(text)\n",
        "        # text = remove_urls(text)\n",
        "        text = remove_special_characters(text)\n",
        "        text = correct_spellings(text, speller)\n",
        "        text = lemmation(text)\n",
        "        # text = remove_stopwords(text, words_to_remove)\n",
        "        # text = stem_text(text, stemmer)\n",
        "    except(TypeError):\n",
        "        print(f'Problematic string: {text}')\n",
        "        text = ''\n",
        "    return text\n",
        "\n",
        "\n",
        "def preprocess_df_for_bow(df: pd.DataFrame, text_col: str, output_col_name='preprocessed_bow', stemmer=None, speller=None, words_to_remove=None, emoticons=None, chat_slang=None)-> pd.DataFrame:\n",
        "    '''\n",
        "    Gets a PD dataframe and a text column name\n",
        "    returns the same dataframe with additional column called 'posts_preprocessed_bow'\n",
        "    '''\n",
        "    df[output_col_name] = df[text_col].progress_apply(lambda text: preprocess_string_for_bow(text, stemmer=stemmer, speller=speller, words_to_remove=words_to_remove, emoticons=emoticons, chat_slang=chat_slang))\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fb38ab5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fb38ab5c",
        "outputId": "fd422209-e6c4-4942-8ea2-65686ba78180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:126: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go com porn walk laugh loud amp right come flight now right right back'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# test\n",
        "preprocess_args = {'stemmer': PorterStemmer(),\n",
        "                    'speller': SpellChecker(),\n",
        "                    'words_to_remove': set(stopwords.words('english')),\n",
        "                    'emoticons': emoticons,\n",
        "                    'chat_slang': chat_slang,\n",
        "                    }\n",
        "\n",
        "text = 'r u going to www.google.com http://xnxx.com im walking LOL ths is not &amp;right im caming flight now u r right brb and fu :-)'\n",
        "# text = 'yeah--well I just want to see you before I go in the apt--cause one of my friends :) lol :X) got arrested for doing the same thing with a 16 year old--it was a set-up type thing'\n",
        "\n",
        "preprocess_string_for_bow(text, **preprocess_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d31dd2",
      "metadata": {
        "id": "f4d31dd2",
        "tags": []
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8db35ba",
      "metadata": {
        "id": "b8db35ba"
      },
      "source": [
        "### PJ dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f8fc852-a907-4706-a742-14207e2eccf2",
      "metadata": {
        "id": "0f8fc852-a907-4706-a742-14207e2eccf2"
      },
      "source": [
        "#### PJ Convesation level dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "00ea3ef6",
      "metadata": {
        "id": "00ea3ef6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_one_chat_as_df_pj(file_path: Path) -> Dict[str, pd.DataFrame]:\n",
        "    '''\n",
        "    Gets an path to a PJ XML file\n",
        "    returns a dict with three dataframes:\n",
        "        - victim data\n",
        "        - predator data\n",
        "        - conversation posts\n",
        "    '''\n",
        "    parser = ET.XMLParser(encoding=\"utf-8\")\n",
        "    try:\n",
        "        doc_tree = ET.parse(file_path, parser=parser)\n",
        "    except(ParseError):\n",
        "        print(f'failed to parse {str(file_path)}')\n",
        "        return None\n",
        "        \n",
        "    doc_root = doc_tree.getroot()\n",
        "    \n",
        "    posts_df = pd.DataFrame(columns = ['USERNAME', 'DATETIME', 'BODY', 'COMMENT', 'CODING'], dtype=str)\n",
        "    predator_df = pd.DataFrame(columns = ['FIRSTNAME', 'LASTNAME', 'STATEDNAME', 'STATEDAGE', 'GENDER', 'RACE', 'CITY', 'STATE', 'REPEATOFFENDER', 'ADMITGUILT', 'TRUTHFULNAME', 'SCREENNAME'], dtype=str)\n",
        "    victim_df = pd.DataFrame(columns = ['FIRSTNAME', 'LASTNAME', 'STATEDNAME', 'STATEDAGE', 'GENDER', 'RACE', 'CITY', 'STATE', 'PREVIOUSVICTIMIZATION', 'ADMITGUILT', 'SCREENNAME'], dtype=str)\n",
        "\n",
        "    for post in doc_root.findall('POST'):\n",
        "        post_dict = {}\n",
        "        for field in post:\n",
        "            post_dict[field.tag] = field.text\n",
        "\n",
        "        posts_df = posts_df.append(post_dict, ignore_index=True)\n",
        "    posts_df = posts_df.astype('string')\n",
        "\n",
        "\n",
        "    for predator in doc_root.findall('PREDATOR'):\n",
        "        predator_dict = {}\n",
        "        for field in predator:\n",
        "            if field.tag == 'SCREENNAME':\n",
        "                for field2 in field:\n",
        "                    predator_dict[field2.tag] = field2.text\n",
        "            predator_dict[field.tag] = field.text\n",
        "\n",
        "        predator_df = predator_df.append(predator_dict, ignore_index=True)   \n",
        "    predator_df = predator_df.astype('string')\n",
        "\n",
        "    for victim in doc_root.findall('VICTIM'):\n",
        "        victim_dict = {}\n",
        "        for field in victim:\n",
        "            victim_dict[field.tag] = field.text\n",
        "\n",
        "        victim_df = victim_df.append(victim_dict, ignore_index=True)  \n",
        "    victim_df = victim_df.astype('string')\n",
        "\n",
        "    return {'predator': predator_df, 'victim': victim_df, 'conversation': posts_df, 'conversation_id': str(file_path.parts[-1])}\n",
        "\n",
        "\n",
        "#----------------------------------------------------------\n",
        "# Test XML parse functions:\n",
        "# file_path = PJ_DATA_FOLDER / Path('ArmySgt1961.xml')\n",
        "# chat_dict = load_one_chat_as_df_pj(file_path)\n",
        "# chat_dict['victim'].head()\n",
        "# chat_dict['predator'].head()\n",
        "# chat_dict['conversation'].head(10)\n",
        "# chat_dict['conversation_id']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load entire PJ dataframe as list of one-sided conversations"
      ],
      "metadata": {
        "id": "was5bvfMwGeZ"
      },
      "id": "was5bvfMwGeZ"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PjConversationsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Wrapper around Torch Dataset.\n",
        "    Prepares an indexed list of PJ conversation in a folder, returns conversations per index (like an array)\n",
        "    Load is lazy - loads conversation from disk on request.\n",
        "    Uses load_one_chat_as_df_pj() for conversation loading\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_folder: Path):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          data_folder - folder with PJ XML files\n",
        "          df_preprocess_fn - function that gets a dataframe and adds preprocesed text column based on given text column\n",
        "\n",
        "        \"\"\"\n",
        "        self.file_list = list_files_in_dir(data_folder, extension='xml')\n",
        "        self.TEXT_COLUMN_NAME = 'BODY'\n",
        "\n",
        "        \n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: length of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Gets element of the dataset\n",
        "\n",
        "        Args:\n",
        "            index (int): index of the element in the dataset\n",
        "        Returns:\n",
        "            Single element by index\n",
        "        \"\"\"        \n",
        "        sample = load_one_chat_as_df_pj(self.file_list[idx])\n",
        "        return sample\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "Mi2dtwgUwLno"
      },
      "id": "Mi2dtwgUwLno",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PJ_CONVERSATIONS_RAW_CSV = OUTPUT_FOLDER / Path('pj_conversations_raw_full.csv')\n",
        "\n",
        "if CREATE_FULL_PJ_CONVERSATIONS_DATAFRAME == 'Process':\n",
        "    print('Running process...')\n",
        "\n",
        "    pj_ds = PjConversationsDataset(PJ_DATA_FOLDER)\n",
        "    predator_texts = []\n",
        "    innocent_texts = []\n",
        "\n",
        "    for conversation_dict in tqdm(pj_ds):\n",
        "      # try:\n",
        "        conversation_df = conversation_dict['conversation'][~conversation_dict['conversation'].USERNAME.isnull() & ~conversation_dict['conversation'].BODY.isnull()]\n",
        "        authors = conversation_df['USERNAME'].unique()\n",
        "        for author in authors:\n",
        "          author_side_text = ' '.join(conversation_df[conversation_df.USERNAME == author]['BODY'])\n",
        "          if author in conversation_dict['predator'].iloc[0].USERNAME:\n",
        "              predator_texts.append(author_side_text)\n",
        "          else:\n",
        "              innocent_texts.append(author_side_text)\n",
        "      # except:\n",
        "      #   print(f'failed to parse conversation: {conversation_dict[\"conversation_id\"]}')\n",
        "      #   print(f'author: {author}, predator: {conversation_dict[\"predator\"].iloc[0].USERNAME}')\n",
        "\n",
        "    predator_texts_df = pd.DataFrame(predator_texts, columns=['text'])\n",
        "    predator_texts_df['predator'] = np.ones(len(predator_texts_df))\n",
        "    innocent_texts_df = pd.DataFrame(innocent_texts, columns=['text'])\n",
        "    innocent_texts_df['predator'] = np.zeros(len(innocent_texts_df))\n",
        "\n",
        "    pj_conversations_df = pd.concat([predator_texts_df, innocent_texts_df]).reset_index(drop=True)\n",
        "    pj_conversations_df.to_csv(PJ_CONVERSATIONS_RAW_CSV, header=True)\n",
        "\n",
        "elif CREATE_FULL_PJ_CONVERSATIONS_DATAFRAME == 'Load':\n",
        "    print('Loading dataset...')\n",
        "    pj_conversations_df = pd.read_csv(PJ_CONVERSATIONS_RAW_CSV)\n",
        "\n",
        "\n",
        "# Remove conversations with leq than 10 words\n",
        "pj_conversations_df['text_len'] = pj_conversations_df['text'].progress_apply(lambda text: len(text.split()))\n",
        "pj_conversations_df = pj_conversations_df[pj_conversations_df.text_len > 15]\n",
        "\n",
        "print(f'Number of predator texts: {len(pj_conversations_df[pj_conversations_df.predator == True])}')\n",
        "print(f'Number of innocent texts: {len(pj_conversations_df[pj_conversations_df.predator == False])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "d40ac9d8d4f047e39de2073aea9081a3",
            "2db3eacea41d49dd9ca7ee6b171529f1",
            "b300b572616448d78c69cde93a9de496",
            "4066155448ca4327b75b1eeb11ee9803",
            "5a37284ad13e4bf0bab398c40b7c6de6",
            "c7625ab67ebe4845919296c0ea13d2bd",
            "3135c6f5d49640cd89d17d3ef7a32f87",
            "8fe0ee99c0d643479b584f450cce2b07",
            "7e0db75ac6bd4cbf93acffe5209c0dfb",
            "1afb056c343a4d249d09e03901e24566",
            "766f2da80aa54630af7b2886e770b60f"
          ]
        },
        "id": "VIEFYq_lyUfR",
        "outputId": "ad7f9313-c620-4d5f-ea75-e6bba8afd50f"
      },
      "id": "VIEFYq_lyUfR",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/123 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d40ac9d8d4f047e39de2073aea9081a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of predator texts: 57\n",
            "Number of innocent texts: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pj_conversations_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cnmzlSapGJOp",
        "outputId": "74ea957a-cdd3-45e9-d15b-012020c72359"
      },
      "id": "cnmzlSapGJOp",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                               text  predator  \\\n",
              "0             0  hi very pretty pic im david hope i didnt bothe...       1.0   \n",
              "1             1  hi jason here 8-) nice to meet you tony hows i...       1.0   \n",
              "2             2  hi me too how are you whrerr are you exactly r...       1.0   \n",
              "3             3  :-) hi 19 m fox valley do u want me to cum? ca...       1.0   \n",
              "4             4  yim? yes? i am in instant messenger cool...you...       1.0   \n",
              "..          ...                                                ...       ...   \n",
              "118         118  ohmy that's funny ok ok lol that's funny i've ...       0.0   \n",
              "119         119  hi hi renee,are you there >:d< yes your beauti...       0.0   \n",
              "120         120  hi are you there hi, luv bug watching tv and u...       0.0   \n",
              "121         121  hi hi hi lol good i was just messin with u wha...       0.0   \n",
              "122         122  hi i'm good a/s/l 15/f/fl nothing much bored o...       0.0   \n",
              "\n",
              "     text_len  \n",
              "0        5738  \n",
              "1         166  \n",
              "2         150  \n",
              "3         307  \n",
              "4         411  \n",
              "..        ...  \n",
              "118      9551  \n",
              "119       239  \n",
              "120       181  \n",
              "121     13135  \n",
              "122      7517  \n",
              "\n",
              "[122 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e34bba53-ae80-49f8-a748-283293526882\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>predator</th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>hi very pretty pic im david hope i didnt bothe...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hi jason here 8-) nice to meet you tony hows i...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>hi me too how are you whrerr are you exactly r...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>:-) hi 19 m fox valley do u want me to cum? ca...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>yim? yes? i am in instant messenger cool...you...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>118</td>\n",
              "      <td>ohmy that's funny ok ok lol that's funny i've ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>119</td>\n",
              "      <td>hi hi renee,are you there &gt;:d&lt; yes your beauti...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>120</td>\n",
              "      <td>hi are you there hi, luv bug watching tv and u...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>121</td>\n",
              "      <td>hi hi hi lol good i was just messin with u wha...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>122</td>\n",
              "      <td>hi i'm good a/s/l 15/f/fl nothing much bored o...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>122 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e34bba53-ae80-49f8-a748-283293526882')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e34bba53-ae80-49f8-a748-283293526882 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e34bba53-ae80-49f8-a748-283293526882');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess PJ dataframe"
      ],
      "metadata": {
        "id": "khNzXWimJUCq"
      },
      "id": "khNzXWimJUCq"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "PJ_PREPROCESSED_CSV = OUTPUT_FOLDER / Path('pj_preprocessed_full.csv')\n",
        "\n",
        "if PREPROCESS_FULL_PJ_DATAFRAME == 'Process':\n",
        "    print('Running preprocess...')\n",
        "\n",
        "    preprocess_args = {'stemmer': PorterStemmer(),\n",
        "                        'speller': SpellChecker(),\n",
        "                        'words_to_remove': set(stopwords.words('english')),\n",
        "                        'emoticons': emoticons,\n",
        "                        'chat_slang': chat_slang,\n",
        "                        }\n",
        "\n",
        "    pj_preprocessed_df = preprocess_df_for_bow(pj_conversations_df, 'text', output_col_name='preprocessed_bow', **preprocess_args)\n",
        "    pj_preprocessed_df.to_csv(PJ_PREPROCESSED_CSV)        \n",
        "\n",
        "elif PREPROCESS_FULL_PJ_DATAFRAME == 'Load':\n",
        "    print('Loading preprocessed data...')\n",
        "    pj_preprocessed_df = pd.read_csv(PJ_PREPROCESSED_CSV, index_col=0)\n",
        "\n",
        "\n",
        "pj_preprocessed_df = pj_preprocessed_df[pj_preprocessed_df.preprocessed_bow.notna()].reset_index(drop=True)\n",
        "pj_preprocessed_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-Fu09w90JagY",
        "outputId": "888c948c-4c55-4ba0-c7cf-8c05190c0909"
      },
      "id": "-Fu09w90JagY",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading preprocessed data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  predator  text_len  \\\n",
              "0    hi very pretty pic im david hope i didnt bothe...       1.0      5738   \n",
              "1    hi jason here 8-) nice to meet you tony hows i...       1.0       166   \n",
              "2    hi me too how are you whrerr are you exactly r...       1.0       150   \n",
              "3    :-) hi 19 m fox valley do u want me to cum? ca...       1.0       307   \n",
              "4    yim? yes? i am in instant messenger cool...you...       1.0       411   \n",
              "..                                                 ...       ...       ...   \n",
              "116  ohmy that's funny ok ok lol that's funny i've ...       0.0      9551   \n",
              "117  hi hi renee,are you there >:d< yes your beauti...       0.0       239   \n",
              "118  hi are you there hi, luv bug watching tv and u...       0.0       181   \n",
              "119  hi hi hi lol good i was just messin with u wha...       0.0     13135   \n",
              "120  hi i'm good a/s/l 15/f/fl nothing much bored o...       0.0      7517   \n",
              "\n",
              "                                      preprocessed_bow  \n",
              "0    very pretty pic bother how old again sure read...  \n",
              "1    here nice meet how s go bro lookin fun long te...  \n",
              "2    too how where exactly right so do eve day here...  \n",
              "3    want cum cause watchin cam so where fall about...  \n",
              "4    instant messenger cool look damn sexy male chi...  \n",
              "..                                                 ...  \n",
              "116  ofmy funny laugh loud funny ve see on here lik...  \n",
              "117  renee there beautiful want sex want first woul...  \n",
              "118  there bug watch really watch too now watch hap...  \n",
              "119  laugh loud good just messin s way look lot ode...  \n",
              "120  good fly much bore head really name name reall...  \n",
              "\n",
              "[121 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae68091b-468c-4a1c-9046-a500a8e7ed8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>predator</th>\n",
              "      <th>text_len</th>\n",
              "      <th>preprocessed_bow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi very pretty pic im david hope i didnt bothe...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5738</td>\n",
              "      <td>very pretty pic bother how old again sure read...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi jason here 8-) nice to meet you tony hows i...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>166</td>\n",
              "      <td>here nice meet how s go bro lookin fun long te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hi me too how are you whrerr are you exactly r...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150</td>\n",
              "      <td>too how where exactly right so do eve day here...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:-) hi 19 m fox valley do u want me to cum? ca...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>307</td>\n",
              "      <td>want cum cause watchin cam so where fall about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yim? yes? i am in instant messenger cool...you...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>411</td>\n",
              "      <td>instant messenger cool look damn sexy male chi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>ohmy that's funny ok ok lol that's funny i've ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9551</td>\n",
              "      <td>ofmy funny laugh loud funny ve see on here lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>hi hi renee,are you there &gt;:d&lt; yes your beauti...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>239</td>\n",
              "      <td>renee there beautiful want sex want first woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>hi are you there hi, luv bug watching tv and u...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181</td>\n",
              "      <td>there bug watch really watch too now watch hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>hi hi hi lol good i was just messin with u wha...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13135</td>\n",
              "      <td>laugh loud good just messin s way look lot ode...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>hi i'm good a/s/l 15/f/fl nothing much bored o...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7517</td>\n",
              "      <td>good fly much bore head really name name reall...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae68091b-468c-4a1c-9046-a500a8e7ed8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae68091b-468c-4a1c-9046-a500a8e7ed8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae68091b-468c-4a1c-9046-a500a8e7ed8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09720ea7",
      "metadata": {
        "id": "09720ea7"
      },
      "source": [
        "### Pan12 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66cde0de",
      "metadata": {
        "id": "66cde0de"
      },
      "source": [
        "#### Pan12 Conversation  level dataset for train data (No line labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4792225b",
      "metadata": {
        "id": "4792225b"
      },
      "outputs": [],
      "source": [
        "class Pan12Dataset(Dataset):\n",
        "    '''\n",
        "    Wrapper around Torch Dataset.\n",
        "    Prepares an indexed list of Pan12 conversation in a folder, returns conversations per index (like an array)\n",
        "    Load is lazy - loads conversation from disk on request.\n",
        "    Uses load_one_chat_as_df_pj() for conversation loading\n",
        "    '''\n",
        "\n",
        "    def __init__(self, chat_data_file: Path, user_labels_file: Path=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            chat_data_file: path to chat xml file\n",
        "            conversation_labels:\n",
        "            line_labels:  \n",
        "        \"\"\"\n",
        "        self.chat_data_file = chat_data_file\n",
        "        self.conversations = self._get_conversation_roots(chat_data_file)\n",
        "        self.preprocess_args = preprocess_args\n",
        "        self.user_labels_file = user_labels_file\n",
        "        self.TEXT_COLUMN_NAME = 'text'\n",
        "\n",
        "        # Create sets of problematic lines and authors for labels\n",
        "        user_labels = pd.read_csv(user_labels_file, header=None)\n",
        "        self.perverted_authors = set(user_labels[0])\n",
        "\n",
        "                \n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: length of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.conversations)\n",
        "\n",
        "    def __getitem__(self, idx) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Gets element of the dataset\n",
        "\n",
        "        Args:\n",
        "            index (int): index of the element in the dataset\n",
        "        Returns:\n",
        "            Single element by index\n",
        "        \"\"\"        \n",
        "\n",
        "        conversation = self.conversations[idx]\n",
        "        conversation_id = conversation.attrib['id']\n",
        "        conversation_list = []\n",
        "\n",
        "        for message in conversation.findall('message'):\n",
        "            message_list = [message.attrib['line']]\n",
        "            for field in message:\n",
        "                message_list.append(field.text)\n",
        "            \n",
        "            conversation_list.append(message_list)\n",
        "\n",
        "        conversation_df = pd.DataFrame(conversation_list, columns = ['line', 'author', 'time', 'text'])\n",
        "        conversation_df = conversation_df.dropna()\n",
        "        \n",
        "        if self.user_labels_file is not None:\n",
        "            chat_predetors = [author for author in conversation_df.author.unique() if author in self.perverted_authors]\n",
        "            result = {'conversation_id': conversation_id, 'conversation': conversation_df, 'predators': chat_predetors}\n",
        "        else:\n",
        "            result = {'conversation_id': conversation_id, 'conversation': conversation_df}\n",
        "\n",
        "        return result\n",
        "    \n",
        "    def _get_conversation_roots(self, file_path):\n",
        "        doc_tree = ET.parse(file_path)\n",
        "        conversation_roots = doc_tree.getroot().findall('conversation')\n",
        "        return conversation_roots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c0d4bf5",
      "metadata": {
        "id": "5c0d4bf5"
      },
      "source": [
        "#### Pan12 TRAIN converter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b636179",
      "metadata": {
        "id": "7b636179"
      },
      "source": [
        "This section creates a dataset of single sided chat strings and tags them as predator or innocent.\n",
        "I.e. - each 2-party conversation will create two samples - one of each party, and each party will be tagged separately.\n",
        "The samples of predators are not necessary predatory in every sample, sinnce the label is on the person and not on the specific chat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3fc3456f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "a09b813467f84ce2be71c01cfe8ffe0f",
            "764888db91b7493f997b275d3391bd61",
            "08efc49d30b142d28b842c95cb8c9c69",
            "24a9858cdccd4d28a121751277368e7d",
            "91d7aceb8b334d5b9b9d99d2bb6c90c1",
            "cf464a4d2971448abeff4a8b0fced125",
            "20c8adf59fb14febaed6ac1506c6b34e",
            "7f72d2f8c89242a7a3642ad309ac0882",
            "a14bf716be90487abd2dfae080a50968",
            "33fb918038104c638fb541e1ad30b80a",
            "775a0f126ae446639966550dbdf0493c"
          ]
        },
        "id": "3fc3456f",
        "outputId": "76571d17-1028-4328-93c0-5653bdfc0ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/99502 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a09b813467f84ce2be71c01cfe8ffe0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of predator texts: 753\n",
            "Number of innocent texts: 38250\n"
          ]
        }
      ],
      "source": [
        "PAN12_TRAIN_RAW_CSV = OUTPUT_FOLDER / Path('pan12_raw_full.csv')\n",
        "\n",
        "if CREATE_FULL_PAN12_DATAFRAME == 'Process':\n",
        "    print('Running process...')\n",
        "\n",
        "\n",
        "    pan12_train_ds = Pan12Dataset(PAN12_TRAIN_DATA_FILE, PAN12_TRAIN_USER_LABELS_FILE)\n",
        "    predator_texts = []\n",
        "    innocent_texts = []\n",
        "\n",
        "    for conversation_dict in tqdm(pan12_train_ds):\n",
        "        conversation_df = conversation_dict['conversation']\n",
        "        authors = conversation_df['author'].unique()\n",
        "        for author in authors:\n",
        "            author_side_text = ' '.join(conversation_df[conversation_df.author == author]['text'])\n",
        "            if author in conversation_dict['predators']:\n",
        "                predator_texts.append(author_side_text)\n",
        "            else:\n",
        "                innocent_texts.append(author_side_text)\n",
        "\n",
        "    predator_texts_df = pd.DataFrame(predator_texts, columns=['text'])\n",
        "    predator_texts_df['predator'] = np.ones(len(predator_texts_df))\n",
        "    innocent_texts_df = pd.DataFrame(innocent_texts, columns=['text'])\n",
        "    innocent_texts_df['predator'] = np.zeros(len(innocent_texts_df))\n",
        "\n",
        "    pan12_train_df = pd.concat([predator_texts_df, innocent_texts_df]).reset_index(drop=True)\n",
        "    pan12_train_df.to_csv(PAN12_TRAIN_RAW_CSV, header=True)\n",
        "\n",
        "elif CREATE_FULL_PAN12_DATAFRAME == 'Load':\n",
        "    print('Loading dataset...')\n",
        "    pan12_train_df = pd.read_csv(PAN12_TRAIN_RAW_CSV)\n",
        "\n",
        "\n",
        "# Remove conversations with leq than 10 words\n",
        "pan12_train_df['text_len'] = pan12_train_df['text'].progress_apply(lambda text: len(text.split()))\n",
        "pan12_train_df = pan12_train_df[pan12_train_df.text_len > 15]\n",
        "\n",
        "print(f'Number of predator texts: {len(pan12_train_df[pan12_train_df.predator == True])}')\n",
        "print(f'Number of innocent texts: {len(pan12_train_df[pan12_train_df.predator == False])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0b6b863f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0b6b863f",
        "outputId": "a8d41883-75a2-476d-ed13-c706f9ea40b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading preprocessed data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  predator  text_len  \\\n",
              "0      hey!! a little better what are u doing? yea i ...       1.0       320   \n",
              "1      hello hey where r u from in nj?? same here cnj...       1.0       468   \n",
              "2      hi liz nothing much...how have u been doin any...       1.0        84   \n",
              "3      Hello Whatcha doin? Oh yeah hows brad and darl...       1.0        45   \n",
              "4      i came to tonapah and you were't on left at 6 ...       1.0        24   \n",
              "...                                                  ...       ...       ...   \n",
              "35917  65325d50b2e25aca54bc871b89758c9c: For the poll...       0.0        49   \n",
              "35918  Ooh, impressive, 3 out of 3 of the times liste...       0.0        29   \n",
              "35919  hello asl 21m uk u wasuup omg me too lol rape ...       0.0       221   \n",
              "35920  heyy asl? 17 f australia&apos; mehh not much b...       0.0       177   \n",
              "35921  hey what u doing 16 wby m wbu what bout you we...       0.0        24   \n",
              "\n",
              "                                        preprocessed_bow  \n",
              "0      little better do yea think just wake check see...  \n",
              "1      where same here co so bring room work old here...  \n",
              "2      much how do good ok wrong finish homework good...  \n",
              "3      do how s loud laugh loud ink school kinda bori...  \n",
              "4                          come on leave back talk later  \n",
              "...                                                  ...  \n",
              "35917  poll vote member vote represent understanding ...  \n",
              "35918  impressive time list new reminder email correc...  \n",
              "35919  uk omg too laugh loud rape just start jude lau...  \n",
              "35920  much blast nirvana bedroom laugh haha love buz...  \n",
              "35921     do why web cam site porn yea come com guy girl  \n",
              "\n",
              "[35922 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-298f87c8-ebcf-4c12-9d5f-e21318239c87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>predator</th>\n",
              "      <th>text_len</th>\n",
              "      <th>preprocessed_bow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hey!! a little better what are u doing? yea i ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>320</td>\n",
              "      <td>little better do yea think just wake check see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hello hey where r u from in nj?? same here cnj...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>468</td>\n",
              "      <td>where same here co so bring room work old here...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hi liz nothing much...how have u been doin any...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84</td>\n",
              "      <td>much how do good ok wrong finish homework good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hello Whatcha doin? Oh yeah hows brad and darl...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>45</td>\n",
              "      <td>do how s loud laugh loud ink school kinda bori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i came to tonapah and you were't on left at 6 ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24</td>\n",
              "      <td>come on leave back talk later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35917</th>\n",
              "      <td>65325d50b2e25aca54bc871b89758c9c: For the poll...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49</td>\n",
              "      <td>poll vote member vote represent understanding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35918</th>\n",
              "      <td>Ooh, impressive, 3 out of 3 of the times liste...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29</td>\n",
              "      <td>impressive time list new reminder email correc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35919</th>\n",
              "      <td>hello asl 21m uk u wasuup omg me too lol rape ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>221</td>\n",
              "      <td>uk omg too laugh loud rape just start jude lau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35920</th>\n",
              "      <td>heyy asl? 17 f australia&amp;apos; mehh not much b...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>177</td>\n",
              "      <td>much blast nirvana bedroom laugh haha love buz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35921</th>\n",
              "      <td>hey what u doing 16 wby m wbu what bout you we...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24</td>\n",
              "      <td>do why web cam site porn yea come com guy girl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35922 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-298f87c8-ebcf-4c12-9d5f-e21318239c87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-298f87c8-ebcf-4c12-9d5f-e21318239c87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-298f87c8-ebcf-4c12-9d5f-e21318239c87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "PAN12_TRAIN_PREPROCESSED_CSV = OUTPUT_FOLDER / Path('pan12_preprocessed_full.csv')\n",
        "\n",
        "if PREPROCESS_FULL_PAN12_DATAFRAME == 'Process':\n",
        "    print('Running preprocess...')\n",
        "\n",
        "    preprocess_args = {'stemmer': PorterStemmer(),\n",
        "                        'speller': SpellChecker(),\n",
        "                        'words_to_remove': set(stopwords.words('english')),\n",
        "                        'emoticons': emoticons,\n",
        "                        'chat_slang': chat_slang,\n",
        "                        }\n",
        "\n",
        "    for i in range(0, 40):\n",
        "      print(f'current batch: {i * 1000} - {(i+1) * 1000}')\n",
        "      df = preprocess_df_for_bow(pan12_train_df.iloc[i * 1000:((i+1) * 1000), :], 'text', output_col_name='preprocessed_bow', **preprocess_args)\n",
        "      PAN12_TRAIN_PREPROCESSED_CSV = OUTPUT_FOLDER / Path(f'pan12_preprocessed_full_{i}_{i+1}.csv')\n",
        "      df.to_csv(PAN12_TRAIN_PREPROCESSED_CSV, header=True)\n",
        "    \n",
        "    # join and update Pan12 preprocessed csv parts - Required because the preprocessing was ran on several computers in parts\n",
        "    PAN12_TRAIN_PREPROCESSED_CSV = OUTPUT_FOLDER / Path('pan12_preprocessed_full.csv')\n",
        "    PAN12_TRAIN_PREPROCESSED_CSV_PARTS_FOLDER = OUTPUT_FOLDER / Path('pan12_preprocessed_parts')\n",
        "\n",
        "    unified_df = unify_csv_dataframes_to_one_sorted(PAN12_TRAIN_PREPROCESSED_CSV_PARTS_FOLDER)\n",
        "    # unified_df.preprocessed_bow = unified_df.preprocessed_bow.apply(lambda text: ''.join(ch for ch in text if ch not in [\"'\", \"[\", \"]\", \",\"]))\n",
        "\n",
        "    unified_df.to_csv(PAN12_TRAIN_PREPROCESSED_CSV)        \n",
        "\n",
        "elif PREPROCESS_FULL_PAN12_DATAFRAME == 'Load':\n",
        "    print('Loading preprocessed data...')\n",
        "    pan12_train_df = pd.read_csv(PAN12_TRAIN_PREPROCESSED_CSV, index_col=0)\n",
        "\n",
        "\n",
        "pan12_train_df = pan12_train_df[pan12_train_df.preprocessed_bow.notna()].reset_index(drop=True)\n",
        "pan12_train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unify datasets - entire pan + positives from pj"
      ],
      "metadata": {
        "id": "QYSqCQE8Ss_o"
      },
      "id": "QYSqCQE8Ss_o"
    },
    {
      "cell_type": "code",
      "source": [
        "pan_pj_unified_df = pd.concat([pj_preprocessed_df[pj_preprocessed_df.predator == 1], pan12_train_df])"
      ],
      "metadata": {
        "id": "QmJhAfIsSwy0"
      },
      "id": "QmJhAfIsSwy0",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pan_pj_unified_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NTRxcuvLYG74",
        "outputId": "715bea50-d8ab-4b14-f44d-73dbe93a84bf"
      },
      "id": "NTRxcuvLYG74",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  predator  text_len  \\\n",
              "0      hi very pretty pic im david hope i didnt bothe...       1.0      5738   \n",
              "1      hi jason here 8-) nice to meet you tony hows i...       1.0       166   \n",
              "2      hi me too how are you whrerr are you exactly r...       1.0       150   \n",
              "3      :-) hi 19 m fox valley do u want me to cum? ca...       1.0       307   \n",
              "4      yim? yes? i am in instant messenger cool...you...       1.0       411   \n",
              "...                                                  ...       ...       ...   \n",
              "35917  65325d50b2e25aca54bc871b89758c9c: For the poll...       0.0        49   \n",
              "35918  Ooh, impressive, 3 out of 3 of the times liste...       0.0        29   \n",
              "35919  hello asl 21m uk u wasuup omg me too lol rape ...       0.0       221   \n",
              "35920  heyy asl? 17 f australia&apos; mehh not much b...       0.0       177   \n",
              "35921  hey what u doing 16 wby m wbu what bout you we...       0.0        24   \n",
              "\n",
              "                                        preprocessed_bow  \n",
              "0      very pretty pic bother how old again sure read...  \n",
              "1      here nice meet how s go bro lookin fun long te...  \n",
              "2      too how where exactly right so do eve day here...  \n",
              "3      want cum cause watchin cam so where fall about...  \n",
              "4      instant messenger cool look damn sexy male chi...  \n",
              "...                                                  ...  \n",
              "35917  poll vote member vote represent understanding ...  \n",
              "35918  impressive time list new reminder email correc...  \n",
              "35919  uk omg too laugh loud rape just start jude lau...  \n",
              "35920  much blast nirvana bedroom laugh haha love buz...  \n",
              "35921     do why web cam site porn yea come com guy girl  \n",
              "\n",
              "[35979 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a11daa42-4abb-4605-9443-4784878d1acf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>predator</th>\n",
              "      <th>text_len</th>\n",
              "      <th>preprocessed_bow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi very pretty pic im david hope i didnt bothe...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5738</td>\n",
              "      <td>very pretty pic bother how old again sure read...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi jason here 8-) nice to meet you tony hows i...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>166</td>\n",
              "      <td>here nice meet how s go bro lookin fun long te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hi me too how are you whrerr are you exactly r...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150</td>\n",
              "      <td>too how where exactly right so do eve day here...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:-) hi 19 m fox valley do u want me to cum? ca...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>307</td>\n",
              "      <td>want cum cause watchin cam so where fall about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yim? yes? i am in instant messenger cool...you...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>411</td>\n",
              "      <td>instant messenger cool look damn sexy male chi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35917</th>\n",
              "      <td>65325d50b2e25aca54bc871b89758c9c: For the poll...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49</td>\n",
              "      <td>poll vote member vote represent understanding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35918</th>\n",
              "      <td>Ooh, impressive, 3 out of 3 of the times liste...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29</td>\n",
              "      <td>impressive time list new reminder email correc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35919</th>\n",
              "      <td>hello asl 21m uk u wasuup omg me too lol rape ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>221</td>\n",
              "      <td>uk omg too laugh loud rape just start jude lau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35920</th>\n",
              "      <td>heyy asl? 17 f australia&amp;apos; mehh not much b...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>177</td>\n",
              "      <td>much blast nirvana bedroom laugh haha love buz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35921</th>\n",
              "      <td>hey what u doing 16 wby m wbu what bout you we...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24</td>\n",
              "      <td>do why web cam site porn yea come com guy girl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35979 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a11daa42-4abb-4605-9443-4784878d1acf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a11daa42-4abb-4605-9443-4784878d1acf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a11daa42-4abb-4605-9443-4784878d1acf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59bd5e29",
      "metadata": {
        "id": "59bd5e29"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9a594d2",
      "metadata": {
        "id": "a9a594d2"
      },
      "source": [
        "### Word-list based features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8de75393",
      "metadata": {
        "id": "8de75393"
      },
      "outputs": [],
      "source": [
        "def contains_words_from_list(text: str, word_list: List[str])-> bool:\n",
        "    text_words = re.sub(\"[^\\w]\", \" \",  text).split()\n",
        "    if any(word in word_list for word in text_words):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def count_words_from_list(text: str, word_list: List[str])-> int:\n",
        "    text_words = text.split()\n",
        "    word_counts = pd.value_counts(np.array(text_words))\n",
        "    count = word_counts[set(word_counts.index) & set(word_list)].sum()\n",
        "    return count\n",
        "\n",
        "\n",
        "def add_wordlist_features(df: pd.DataFrame, text_column: str, sex_word_list, family_word_list, meeting_word_list):\n",
        "    df['num_sex_words'] = df[text_column].progress_apply(lambda text: count_words_from_list(text, sex_word_list))\n",
        "    df['num_family_words'] = df[text_column].progress_apply(lambda text: count_words_from_list(text, family_word_list))\n",
        "    df['num_meeting_words'] = df[text_column].progress_apply(lambda text: count_words_from_list(text, meeting_word_list))\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pan_pj_unified_df = add_wordlist_features(pan_pj_unified_df, 'preprocessed_bow', sex_word_list, family_word_list, meeting_word_list)\n",
        "pan_pj_unified_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rbfGHZN7uOpN",
        "outputId": "00d8a741-6e7b-45cf-82e6-3241a0115388"
      },
      "id": "rbfGHZN7uOpN",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  predator  text_len  \\\n",
              "0      hi very pretty pic im david hope i didnt bothe...       1.0      5738   \n",
              "1      hi jason here 8-) nice to meet you tony hows i...       1.0       166   \n",
              "2      hi me too how are you whrerr are you exactly r...       1.0       150   \n",
              "3      :-) hi 19 m fox valley do u want me to cum? ca...       1.0       307   \n",
              "4      yim? yes? i am in instant messenger cool...you...       1.0       411   \n",
              "...                                                  ...       ...       ...   \n",
              "35917  65325d50b2e25aca54bc871b89758c9c: For the poll...       0.0        49   \n",
              "35918  Ooh, impressive, 3 out of 3 of the times liste...       0.0        29   \n",
              "35919  hello asl 21m uk u wasuup omg me too lol rape ...       0.0       221   \n",
              "35920  heyy asl? 17 f australia&apos; mehh not much b...       0.0       177   \n",
              "35921  hey what u doing 16 wby m wbu what bout you we...       0.0        24   \n",
              "\n",
              "                                        preprocessed_bow  num_sex_words  \\\n",
              "0      very pretty pic bother how old again sure read...             97   \n",
              "1      here nice meet how s go bro lookin fun long te...              0   \n",
              "2      too how where exactly right so do eve day here...              5   \n",
              "3      want cum cause watchin cam so where fall about...             14   \n",
              "4      instant messenger cool look damn sexy male chi...             11   \n",
              "...                                                  ...            ...   \n",
              "35917  poll vote member vote represent understanding ...              0   \n",
              "35918  impressive time list new reminder email correc...              0   \n",
              "35919  uk omg too laugh loud rape just start jude lau...              3   \n",
              "35920  much blast nirvana bedroom laugh haha love buz...              1   \n",
              "35921     do why web cam site porn yea come com guy girl              1   \n",
              "\n",
              "       num_family_words  num_meeting_words  \n",
              "0                     7                 15  \n",
              "1                     2                  3  \n",
              "2                     0                  1  \n",
              "3                     1                  4  \n",
              "4                     0                  1  \n",
              "...                 ...                ...  \n",
              "35917                 0                  0  \n",
              "35918                 0                  0  \n",
              "35919                 0                  0  \n",
              "35920                 0                  0  \n",
              "35921                 0                  0  \n",
              "\n",
              "[35979 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21892ccb-4d91-4b40-bef5-534e4f8b12b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>predator</th>\n",
              "      <th>text_len</th>\n",
              "      <th>preprocessed_bow</th>\n",
              "      <th>num_sex_words</th>\n",
              "      <th>num_family_words</th>\n",
              "      <th>num_meeting_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi very pretty pic im david hope i didnt bothe...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5738</td>\n",
              "      <td>very pretty pic bother how old again sure read...</td>\n",
              "      <td>97</td>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi jason here 8-) nice to meet you tony hows i...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>166</td>\n",
              "      <td>here nice meet how s go bro lookin fun long te...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hi me too how are you whrerr are you exactly r...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150</td>\n",
              "      <td>too how where exactly right so do eve day here...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:-) hi 19 m fox valley do u want me to cum? ca...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>307</td>\n",
              "      <td>want cum cause watchin cam so where fall about...</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yim? yes? i am in instant messenger cool...you...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>411</td>\n",
              "      <td>instant messenger cool look damn sexy male chi...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35917</th>\n",
              "      <td>65325d50b2e25aca54bc871b89758c9c: For the poll...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49</td>\n",
              "      <td>poll vote member vote represent understanding ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35918</th>\n",
              "      <td>Ooh, impressive, 3 out of 3 of the times liste...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29</td>\n",
              "      <td>impressive time list new reminder email correc...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35919</th>\n",
              "      <td>hello asl 21m uk u wasuup omg me too lol rape ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>221</td>\n",
              "      <td>uk omg too laugh loud rape just start jude lau...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35920</th>\n",
              "      <td>heyy asl? 17 f australia&amp;apos; mehh not much b...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>177</td>\n",
              "      <td>much blast nirvana bedroom laugh haha love buz...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35921</th>\n",
              "      <td>hey what u doing 16 wby m wbu what bout you we...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24</td>\n",
              "      <td>do why web cam site porn yea come com guy girl</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35979 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21892ccb-4d91-4b40-bef5-534e4f8b12b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21892ccb-4d91-4b40-bef5-534e4f8b12b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21892ccb-4d91-4b40-bef5-534e4f8b12b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dQ1tI7GOQjSe",
      "metadata": {
        "id": "dQ1tI7GOQjSe"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "600af7b9",
      "metadata": {
        "id": "600af7b9"
      },
      "source": [
        "### LDA topic model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BOW and corpush preparation\n",
        "\n",
        "ID2WORD_MODEL_PATH = OUTPUT_FOLDER / Path('lda_id2word.bin')\n",
        "CORPUS_PATH = OUTPUT_FOLDER / Path('lda_corpus.bin')\n",
        "\n",
        "# Create bag of words list from chat sentences\n",
        "def create_bow_from_text(text):\n",
        "    bow_words = []\n",
        "    text_word_list = gensim.utils.simple_preprocess(text, deacc=True)\n",
        "    bow_words.append(text_word_list)\n",
        "    return bow_words[0]\n",
        "\n",
        "\n",
        "def create_bow_from_text_list(text_list):\n",
        "    bow_words = []\n",
        "    for i, text in enumerate(text_list):\n",
        "        # text_word_list = gensim.utils.simple_preprocess(text, deacc=True)\n",
        "        # bow_words.append(text_word_list)\n",
        "        bow_words.append(create_bow_from_text(text))\n",
        "        \n",
        "    return bow_words\n",
        "\n",
        "\n",
        "# Process the Pan12 dataset\n",
        "if PAN12_TOPIC_MODEL_CORPUS == 'Process':\n",
        "  print('Calculating BOW and corpus...')\n",
        "\n",
        "  bow_words = create_bow_from_text_list(pan_pj_unified_df['preprocessed_bow'])\n",
        "\n",
        "  # create word indexes and frequencies from chat sentences bow\n",
        "  id2word = corpora.Dictionary(bow_words)\n",
        "  corpus = []\n",
        "  for word in bow_words:\n",
        "      corpus.append(id2word.doc2bow(word))\n",
        "    \n",
        "  # Save models to disk\n",
        "  id2word.save(str(ID2WORD_MODEL_PATH))\n",
        "  with open(CORPUS_PATH, 'wb') as handle:\n",
        "    pickle.dump(corpus, handle)\n",
        "\n",
        "elif PAN12_TOPIC_MODEL_CORPUS == 'Load':\n",
        "  print('Loading BOW and corpus from disk...')\n",
        "  id2word = corpora.Dictionary.load(str(ID2WORD_MODEL_PATH))\n",
        "  with open(CORPUS_PATH, 'rb') as handle:\n",
        "    corpus = pickle.load(handle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSHKwuaFl1QH",
        "outputId": "2babb727-9e38-493a-de2c-3aae695c87df"
      },
      "id": "hSHKwuaFl1QH",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating BOW and corpus...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a734e28c",
      "metadata": {
        "id": "a734e28c"
      },
      "outputs": [],
      "source": [
        "# Actual LDA topic model\n",
        "\n",
        "def create_lda_model(corpus, id2word, num_topics, save_to_disk=True, save_model_path=None):\n",
        "  print(f'Calculating LDA model with {num_topics} topics...')\n",
        "  # create LDA topic model\n",
        "  lda_model = gensim.models.LdaMulticore(workers=3, corpus=corpus,\n",
        "  id2word=id2word,\n",
        "  num_topics=num_topics, \n",
        "  chunksize=100,\n",
        "  passes=10)\n",
        "\n",
        "  # lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "  # id2word=id2word,\n",
        "  # num_topics=num_topics, \n",
        "  # update_every=1,\n",
        "  # chunksize=100,\n",
        "  # passes=10,\n",
        "  # alpha='auto')\n",
        "\n",
        "  # Save models to disk\n",
        "  if save_to_disk:\n",
        "    lda_model.save(str(save_model_path))\n",
        "\n",
        "  return lda_model\n",
        "\n",
        "\n",
        "# NUM_LDA_TOPICS = 10\n",
        "# LDA_MODEL_PATH = OUTPUT_FOLDER / Path(f'lda_model_{NUM_LDA_TOPICS}.bin')\n",
        "\n",
        "# if PAN12_TOPIC_MODEL == 'Process':\n",
        "#   lda_model = create_lda_model(corpus, id2word, NUM_LDA_TOPICS, save_to_disk=True)\n",
        "    \n",
        " \n",
        "# elif PAN12_TOPIC_MODEL == 'Load':\n",
        "#   print('Loading LDA model from disk...')\n",
        "#   lda_model = gensim.models.ldamodel.LdaModel.load(str(LDA_MODEL_PATH))\n",
        "\n",
        "#   NUM_LDA_TOPICS = len(lda_model.get_topics())\n",
        "#   print(f'Loaded model has {NUM_LDA_TOPICS} topics')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e6679c62",
      "metadata": {
        "id": "e6679c62"
      },
      "outputs": [],
      "source": [
        "# # visualize\n",
        "# vis = gensimvis.prepare(lda_model, corpus, id2word, mds='mmds', R=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "M14Mq5aNsvhH",
      "metadata": {
        "id": "M14Mq5aNsvhH"
      },
      "outputs": [],
      "source": [
        "# Topics inference function\n",
        "def get_text_topics(text, id2word, lda_model):\n",
        "  text_vector = id2word.doc2bow(text.split())\n",
        "  text_topics = lda_model.get_document_topics(text_vector)\n",
        "  return text_topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "UbTnkrZZS7TQ",
      "metadata": {
        "id": "UbTnkrZZS7TQ"
      },
      "outputs": [],
      "source": [
        "# for test only: show topics for some sample sentences:\n",
        "preprocess_args = {'stemmer': PorterStemmer(),\n",
        "                    'speller': SpellChecker(),\n",
        "                    'words_to_remove': set(stopwords.words('english')),\n",
        "                    'emoticons': emoticons,\n",
        "                    'chat_slang': chat_slang,\n",
        "                    }\n",
        "\n",
        "\n",
        "def display_text_topics(text: str, preprocess_args):\n",
        "  text_preprocessed  = preprocess_string_for_bow(text, **preprocess_args)\n",
        "  text_topics = get_text_topics(text_preprocessed, id2word, lda_model)\n",
        "  print(text)\n",
        "  print(text_topics)\n",
        "  print()\n",
        "\n",
        "\n",
        "# sample = 'Tell your mom she is a cunt with a nice ass fuck her and suck you too'\n",
        "# display_text_topics(sample, preprocess_args)\n",
        "\n",
        "# sample = 'I would like to go to the cinema and have popcorn'\n",
        "# display_text_topics(sample, preprocess_args)\n",
        "\n",
        "# sample = pan_pj_unified_df['preprocessed_bow'][100]\n",
        "# display_text_topics(sample, preprocess_args)\n",
        "\n",
        "# sample = pan_pj_unified_df['preprocessed_bow'][1000]\n",
        "# display_text_topics(sample, preprocess_args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80NQ45KMZb15",
      "metadata": {
        "id": "80NQ45KMZb15"
      },
      "source": [
        "### Data prep for classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bgPzOPYuoGe",
      "metadata": {
        "id": "4bgPzOPYuoGe"
      },
      "source": [
        "#### Add topics to data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "XblXL-iTuwp0",
      "metadata": {
        "id": "XblXL-iTuwp0"
      },
      "outputs": [],
      "source": [
        "def add_topics_to_df(df, id2word, lda_model):\n",
        "  num_lda_topics = len(lda_model.get_topics())\n",
        "  topic_scores = np.zeros([len(df), num_lda_topics])\n",
        "\n",
        "  for row_idx, row in tqdm(df.iterrows()):\n",
        "    row_topics = get_text_topics(row.preprocessed_bow, id2word, lda_model)\n",
        "    for topic in row_topics:\n",
        "      topic_scores[row_idx, topic[0]] = topic[1]\n",
        "  \n",
        "  for topic_idx in range(num_lda_topics):\n",
        "    df[f'topic_{topic_idx}'] = topic_scores[:, topic_idx]\n",
        "  \n",
        "  return df\n",
        "\n",
        "\n",
        "# pan_pj_unified_df = add_topics_to_df(df, id2word, lda_model)\n",
        "# pan_pj_unified_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ARjaSNHQpqcn",
      "metadata": {
        "id": "ARjaSNHQpqcn"
      },
      "source": [
        "#### Train / Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "s_101HvtZyPN",
      "metadata": {
        "id": "s_101HvtZyPN"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "def dataprep_for_classifier(df, precent_train, num_lda_topics, reandom_seed=17):\n",
        "\n",
        "  random.seed(reandom_seed)\n",
        "  x_columns = [f'topic_{i}' for i in range(num_lda_topics)] + ['num_sex_words', 'num_family_words', 'num_meeting_words']\n",
        "  y_column = ['predator']\n",
        "  data_columns = x_columns + y_column\n",
        "\n",
        "  # Split Train / Test\n",
        "  num_samples_positive = len(df[df.predator == 1])\n",
        "  num_samples_negative = len(df) - num_samples_positive\n",
        "\n",
        "  num_train_positive_samples = int(precent_train * num_samples_positive)\n",
        "  num_train_negative_samples = int(precent_train * num_samples_negative)\n",
        "\n",
        "  train_pos_index = random.sample(range(num_samples_positive),  num_train_positive_samples)\n",
        "  test_pos_index = list(set(range(num_samples_positive)).difference(train_pos_index))\n",
        "  print(f'testing: {num_samples_positive} = {len(train_pos_index) + len(test_pos_index)}')\n",
        "\n",
        "  train_neg_index = random.sample(range(num_samples_negative),  num_train_negative_samples)\n",
        "  test_neg_index = list(set(range(num_samples_negative)).difference(train_neg_index))\n",
        "  print(f'testing: {num_samples_negative} = {len(train_neg_index) + len(test_neg_index)}')\n",
        "\n",
        "  data_train_pos = df[df.predator == 1].iloc[train_pos_index][data_columns]\n",
        "  data_train_neg = df[df.predator == 0].iloc[train_neg_index][data_columns]\n",
        "  data_train = pd.concat([data_train_pos, data_train_neg], axis=0).sample(frac=1)\n",
        "  data_train.predator = data_train.predator.astype('int')\n",
        "\n",
        "  data_test_pos = df[df.predator == 1].iloc[test_pos_index][data_columns]\n",
        "  data_test_neg = df[df.predator == 0].iloc[test_neg_index][data_columns]\n",
        "  data_test = pd.concat([data_test_pos, data_test_neg], axis=0).sample(frac=1)\n",
        "  data_test.predator = data_test.predator.astype('int')\n",
        "\n",
        "  x_train = data_train[x_columns]\n",
        "  y_train = data_train[y_column]\n",
        "  x_test = data_test[x_columns]\n",
        "  y_test = data_test[y_column]\n",
        "\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "\n",
        "# PERCENT_TRAIN = 0.8\n",
        "# x_train, y_train, x_test, y_test = dataprep_for_classifier(pan_pj_unified_df, PERCENT_TRAIN, NUM_LDA_TOPICS)\n",
        "# print(x_train.head(), '\\n', y_train.head())\n",
        "# print(x_test.head(), '\\n', y_test.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest classifier on topic model"
      ],
      "metadata": {
        "id": "LfoJnsSSjbEZ"
      },
      "id": "LfoJnsSSjbEZ"
    },
    {
      "cell_type": "markdown",
      "id": "kAxJasN3puIO",
      "metadata": {
        "id": "kAxJasN3puIO"
      },
      "source": [
        "#### RF model calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "M5muXYQlZTUM",
      "metadata": {
        "id": "M5muXYQlZTUM"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def calc_random_forest(x_train, y_train, n_estimators, max_depth, class_weight=None, save_to_file=True, output_path=None, random_state=17):\n",
        "  # Random Forest train\n",
        "  # print('Processing random forest model...')\n",
        "\n",
        "  # Setting random state to get reproducible results\n",
        "  rfc = RandomForestClassifier(n_jobs=4, n_estimators=n_estimators, max_depth=max_depth, class_weight=class_weight, random_state=random_state)\n",
        "  rfc.fit(x_train, y_train)\n",
        "\n",
        "  if save_to_file:\n",
        "    # Save model to disk\n",
        "    with open(output_path, 'wb') as file_handler:\n",
        "        pickle.dump(rfc, file_handler)\n",
        "  \n",
        "  return rfc\n",
        "\n",
        "\n",
        "\n",
        "# N_ESTIMATORS = 50\n",
        "# MAX_DEPTH = 4\n",
        "# CLASS_WEIGHT='balanced'\n",
        "\n",
        "# LDA_MODEL_RF_PATH = OUTPUT_FOLDER / Path(f'lda_rf_model_{NUM_LDA_TOPICS}_{N_ESTIMATORS}_{MAX_DEPTH}_{CLASS_WEIGHT}.bin')\n",
        "\n",
        "# # Random Forest train\n",
        "# if PAN12_TOPIC_MODEL_RF == 'Process':\n",
        "#   print('Processing random forest model...')\n",
        "#   rfc = calc_random_forest(x_train, y_train, N_ESTIMATORS, MAX_DEPTH, class_weight=CLASS_WEIGHT, save_to_file=True, output_path=LDA_MODEL_RF_PATH, random_state=17)\n",
        "\n",
        "\n",
        "# elif PAN12_TOPIC_MODEL_RF == 'Load':\n",
        "#   print('Loading random forest model from disk...')\n",
        "#   with open(LDA_MODEL_RF_PATH, 'rb') as file_handler:\n",
        "#     rfc = pickle.load(file_handler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "gJAZAeCn7c6g",
      "metadata": {
        "id": "gJAZAeCn7c6g"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "def display_roc_curve_and_get_perfs(y_test, y_test_pred, plot=True):\n",
        "  # Compute fpr, tpr, thresholds and roc auc\n",
        "  REQUIRED_FPR = 0.05\n",
        "\n",
        "  test_fpr, test_tpr, thresholds = roc_curve(y_test, y_test_pred, drop_intermediate=False)\n",
        "  test_roc_auc = auc(test_fpr, test_tpr)\n",
        "\n",
        "  fpr_idx = np.argmax(test_fpr >= REQUIRED_FPR)\n",
        "  required_tpr = test_tpr[fpr_idx]\n",
        "\n",
        "  if plot:\n",
        "    # Plot ROC curve\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.plot(test_fpr, test_tpr, label='Test ROC curve (area = %0.3f)' % test_roc_auc)\n",
        "    ax.vlines(REQUIRED_FPR, 0, required_tpr, color=\"r\", lw=2)\n",
        "    ax.hlines(required_tpr, REQUIRED_FPR, 0, color=\"r\", lw=2, label=f'FPR {REQUIRED_FPR}, TPR {required_tpr}')\n",
        "\n",
        "    ax.set_xlim([0, 1.0])\n",
        "    ax.set_ylim([0.0, 1.0])\n",
        "    ax.set_yticks(np.arange(22) / 20.0)\n",
        "    ax.set_xlim([4e-5, 1.0])\n",
        "\n",
        "    ax.set_xlabel(\"False positive rate\")\n",
        "    ax.set_ylabel(\"True positive rate\")\n",
        "    ax.set_title('Receiver Operating Characteristic')\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    ax.set_xscale(\"log\")\n",
        "    plt.gca().grid(True)\n",
        "    plt.show()\n",
        "\n",
        "  return test_roc_auc, required_tpr\n",
        "\n",
        "\n",
        "# y_test_pred = rfc.predict_proba(x_test)[:, 1]\n",
        "# test_roc_auc, tpr = display_roc_curve_and_get_perfs(y_test, y_test_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Grid search best hyperparams"
      ],
      "metadata": {
        "id": "rFPpqwYyMFSI"
      },
      "id": "rFPpqwYyMFSI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train or load the random forest model\n",
        "\n",
        "RFC_TRAIN_RESULTS_CSV_PATH = OUTPUT_FOLDER / 'rfc_train_results.csv'\n",
        "CLASS_WEIGHT='balanced'\n",
        "\n",
        "if GRID_SEARCH_LDA_RFC == 'Process':\n",
        "  PERCENT_TRAIN = 0.8\n",
        "\n",
        "  # Grid search parmaeters\n",
        "  train_results = pd.DataFrame(columns=['topics', 'trees', 'depth', 'auc', 'tpr'])\n",
        "\n",
        "  topics = [9, 10, 20, 35, 50]\n",
        "  for num_topics in tqdm(topics):\n",
        "    # Build LDA model\n",
        "    LDA_MODEL_PATH = OUTPUT_FOLDER / Path(f'lda_model_{int(num_topics)}.bin')\n",
        "    if LDA_MODEL_PATH.is_file():\n",
        "      lda_model = gensim.models.ldamodel.LdaModel.load(str(LDA_MODEL_PATH))\n",
        "    else:\n",
        "      lda_model = create_lda_model(corpus, id2word, num_topics, save_to_disk=True, save_model_path=LDA_MODEL_PATH)\n",
        "    \n",
        "    # update dataframe with topics\n",
        "    df = add_topics_to_df(pan_pj_unified_df, id2word, lda_model).copy()\n",
        "\n",
        "    # dataprep\n",
        "    x_train, y_train, x_test, y_test = dataprep_for_classifier(df, PERCENT_TRAIN, num_topics)\n",
        "\n",
        "    min_depth = 3\n",
        "    max_depth = int(num_topics * 2/3)\n",
        "    num_depths = min(max_depth - min_depth, 5)\n",
        "    depths_for_num_topics = np.linspace(min_depth, max_depth, num_depths, dtype=int)\n",
        "\n",
        "    for depth in tqdm(depths_for_num_topics):\n",
        "      min_trees=50\n",
        "      max_trees = 300\n",
        "      trees = [num for num in np.linspace(min_trees, max_trees, 5, dtype=int)]\n",
        "\n",
        "      for num_trees in tqdm(trees):\n",
        "        # build RFC\n",
        "        LDA_MODEL_RF_PATH = OUTPUT_FOLDER / Path(f'lda_rf_model_{int(num_topics)}_{int(num_trees)}_{int(depth)}_{CLASS_WEIGHT}.bin')\n",
        "        if LDA_MODEL_RF_PATH.is_file():\n",
        "          with open(LDA_MODEL_RF_PATH, 'rb') as file_handler:\n",
        "            rfc = pickle.load(file_handler)\n",
        "        else:\n",
        "          rfc = calc_random_forest(x_train, y_train, num_trees, depth, class_weight=CLASS_WEIGHT, save_to_file=True, output_path=LDA_MODEL_RF_PATH, random_state=17)\n",
        "        # Test\n",
        "        y_test_pred = rfc.predict_proba(x_test)[:, 1]\n",
        "        test_roc_auc, tpr = display_roc_curve_and_get_perfs(y_test, y_test_pred, plot=False)\n",
        "\n",
        "        train_results = train_results.append({'topics': num_topics, 'trees': num_trees, 'depth': depth, 'auc': test_roc_auc, 'tpr': tpr}, ignore_index=True)\n",
        "    train_results.to_csv(RFC_TRAIN_RESULTS_CSV_PATH)\n",
        "\n",
        "elif GRID_SEARCH_LDA_RFC == 'Load':\n",
        "  print('Loading train results from disk...')\n",
        "  train_results = pd.read_csv(RFC_TRAIN_RESULTS_CSV_PATH, index_col=0)\n",
        "\n",
        "print('10 best results based on TPR:')\n",
        "print(train_results.sort_values('tpr', ascending=False).head(10))\n",
        "print()\n",
        "\n",
        "# Load best configuration back to memory\n",
        "print('Loading best model set from disk...')\n",
        "best_config = train_results.sort_values('tpr', ascending=False).iloc[0, :].to_dict()\n",
        "\n",
        "LDA_MODEL_PATH = OUTPUT_FOLDER / Path(f'lda_model_{int(best_config[\"topics\"])}.bin')\n",
        "LDA_MODEL_RF_PATH = OUTPUT_FOLDER / Path(f'lda_rf_model_{int(best_config[\"topics\"])}_{int(best_config[\"trees\"])}_{int(best_config[\"depth\"])}_{CLASS_WEIGHT}.bin')\n",
        "\n",
        "print(f'Loading model {str(LDA_MODEL_PATH)}...', end='')\n",
        "if LDA_MODEL_PATH.is_file():\n",
        "  lda_model = gensim.models.LdaMulticore.load(str(LDA_MODEL_PATH))\n",
        "  print('Done!')\n",
        "\n",
        "\n",
        "print(f'Loading model {str(LDA_MODEL_RF_PATH)}...', end='')\n",
        "if LDA_MODEL_RF_PATH.is_file():\n",
        "  with open(LDA_MODEL_RF_PATH, 'rb') as file_handler:\n",
        "    rfc = pickle.load(file_handler)\n",
        "  print('Done!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "218f0581d26440e1a0927314b976400e",
            "9858d77455834e42bc47179f5d6bd3a1",
            "b665f6f3b7744fbb9c748c21104a5c56",
            "6580fcfafe5f4d23b97b41e4935bbdb9",
            "2dcf20615e9041348a49894ec7679bce",
            "22c8be85f9af4a40838fd3e5c5817e27",
            "b5e8146bd7324e428740e51b04dd5eca",
            "6525b4c7fded4f07825c782237dbcc4d",
            "97ca2dce8e91459a980a1709e08bc68d",
            "c24272063414439bad1fd7a92e569116",
            "a2a9277c5b7e4307bd5e934e57a30134"
          ]
        },
        "id": "5Z6QSmguYStV",
        "outputId": "e4f1f4fe-27df-411f-ad61-a9573d6d0b53"
      },
      "id": "5Z6QSmguYStV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "218f0581d26440e1a0927314b976400e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating LDA model with 9 topics...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient boost on topic model"
      ],
      "metadata": {
        "id": "cLUIvgCyjob-"
      },
      "id": "cLUIvgCyjob-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGB model calculation"
      ],
      "metadata": {
        "id": "Jr7F2Ou8njOZ"
      },
      "id": "Jr7F2Ou8njOZ"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "def calc_grad_boost(x_train, y_train, n_estimators, max_depth, save_to_file=True, output_path=None, random_state=17):\n",
        "  # Gradient boost train\n",
        "\n",
        "  xgb = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "  xgb.fit(x_train, y_train)\n",
        "\n",
        "  if save_to_file:\n",
        "    # Save model to disk\n",
        "    with open(output_path, 'wb') as file_handler:\n",
        "        pickle.dump(xgb, file_handler)\n",
        "  \n",
        "  return xgb"
      ],
      "metadata": {
        "id": "xA7G4i78jrpk"
      },
      "id": "xA7G4i78jrpk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Grid search best hyperparameters"
      ],
      "metadata": {
        "id": "2NPBRow3nmMd"
      },
      "id": "2NPBRow3nmMd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train or load the Gradient boost model\n",
        "\n",
        "GB_TRAIN_RESULTS_CSV_PATH = OUTPUT_FOLDER / 'gb_train_results.csv'\n",
        "\n",
        "if GRID_SEARCH_LDA_GB == 'Process':\n",
        "  PERCENT_TRAIN = 0.8\n",
        "\n",
        "  # Grid search parmaeters\n",
        "  train_results = pd.DataFrame(columns=['topics', 'trees', 'depth', 'auc', 'tpr'])\n",
        "\n",
        "  topics = [9, 10, 20, 35, 50]\n",
        "  for num_topics in tqdm(topics):\n",
        "    # Build LDA model\n",
        "    LDA_MODEL_PATH = OUTPUT_FOLDER / Path(f'lda_model_{int(num_topics)}.bin')\n",
        "    if LDA_MODEL_PATH.is_file():\n",
        "      lda_model = gensim.models.ldamodel.LdaModel.load(str(LDA_MODEL_PATH))\n",
        "    else:\n",
        "      lda_model = create_lda_model(corpus, id2word, num_topics, save_to_disk=True, save_model_path=LDA_MODEL_PATH)\n",
        "    \n",
        "    # update dataframe with topics\n",
        "    df = add_topics_to_df(pan_pj_unified_df, id2word, lda_model).copy()\n",
        "    # dataprep\n",
        "    x_train, y_train, x_test, y_test = dataprep_for_classifier(df, PERCENT_TRAIN, num_topics)\n",
        "\n",
        "    min_depth = 3\n",
        "    max_depth = int(num_topics * 2/3)\n",
        "    num_depths = min(max_depth - min_depth, 5)\n",
        "    depths_for_num_topics = np.linspace(min_depth, max_depth, num_depths, dtype=int)\n",
        "\n",
        "    for depth in tqdm(depths_for_num_topics):\n",
        "      min_trees=50\n",
        "      max_trees = 300\n",
        "      trees = [num for num in np.linspace(min_trees, max_trees, 5, dtype=int)]\n",
        "\n",
        "      for num_trees in tqdm(trees):\n",
        "        # build GB\n",
        "        LDA_MODEL_GB_PATH = OUTPUT_FOLDER / Path(f'lda_gb_model_{int(num_topics)}_{int(num_trees)}_{int(depth)}.bin')\n",
        "        if LDA_MODEL_GB_PATH.is_file():\n",
        "          with open(LDA_MODEL_GB_PATH, 'rb') as file_handler:\n",
        "            gb = pickle.load(file_handler)\n",
        "        else:\n",
        "          gb = calc_grad_boost(x_train, y_train, num_trees, depth, save_to_file=True, output_path=LDA_MODEL_GB_PATH, random_state=17)\n",
        "        # Test\n",
        "        y_test_pred = gb.predict_proba(x_test)[:, 1]\n",
        "        test_roc_auc, tpr = display_roc_curve_and_get_perfs(y_test, y_test_pred, plot=False)\n",
        "\n",
        "        train_results = train_results.append({'topics': num_topics, 'trees': num_trees, 'depth': depth, 'auc': test_roc_auc, 'tpr': tpr}, ignore_index=True)\n",
        "    train_results.to_csv(GB_TRAIN_RESULTS_CSV_PATH)\n",
        "\n",
        "elif GRID_SEARCH_LDA_GB == 'Load':\n",
        "  print('Loading train results from disk...')\n",
        "  train_results = pd.read_csv(GB_TRAIN_RESULTS_CSV_PATH, index_col=0)\n",
        "\n",
        "print('10 best results based on TPR:')\n",
        "print(train_results.sort_values('tpr', ascending=False).head(10))\n",
        "print()\n",
        "\n",
        "# Load best configuration back to memory\n",
        "print('Loading best model set from disk...')\n",
        "best_config = train_results.sort_values('tpr', ascending=False).iloc[0, :].to_dict()\n",
        "\n",
        "LDA_MODEL_PATH = OUTPUT_FOLDER / Path(f'lda_model_{int(best_config[\"topics\"])}.bin')\n",
        "LDA_MODEL_GB_PATH = OUTPUT_FOLDER / Path(f'lda_gb_model_{int(best_config[\"topics\"])}_{int(best_config[\"trees\"])}_{int(best_config[\"depth\"])}.bin')\n",
        "\n",
        "print(f'Loading model {str(LDA_MODEL_PATH)}...', end='')\n",
        "if LDA_MODEL_PATH.is_file():\n",
        "  lda_model = gensim.models.LdaMulticore.load(str(LDA_MODEL_PATH))\n",
        "  print('Done!')\n",
        "\n",
        "\n",
        "print(f'Loading model {str(LDA_MODEL_GB_PATH)}...', end='')\n",
        "if LDA_MODEL_GB_PATH.is_file():\n",
        "  with open(LDA_MODEL_GB_PATH, 'rb') as file_handler:\n",
        "    gb = pickle.load(file_handler)\n",
        "  print('Done!')\n"
      ],
      "metadata": {
        "id": "EqFwDVyhkQTb"
      },
      "id": "EqFwDVyhkQTb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test final model"
      ],
      "metadata": {
        "id": "r0GpQjxQOxQl"
      },
      "id": "r0GpQjxQOxQl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualize toppic model on train data"
      ],
      "metadata": {
        "id": "GZ_ZvsSyO6Up"
      },
      "id": "GZ_ZvsSyO6Up"
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize topic model\n",
        "vis = gensimvis.prepare(lda_model, corpus, id2word, mds='mmds', R=30)\n",
        "vis"
      ],
      "metadata": {
        "id": "8JNflpbRO2Uk"
      },
      "id": "8JNflpbRO2Uk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_vector = id2word.doc2bow(['fuck'])\n",
        "# # print(lda_model.get_document_topics(text_vector))\n",
        "\n",
        "# f = plt.figure()\n",
        "# f.set_figwidth(20)\n",
        "# f.set_figheight(20)\n",
        "\n",
        "# # plt.imshow(WordCloud().fit_words(dict(lda_model.show_topic(24, 300))), )\n",
        "# lda_model.show_topic(23, 300)"
      ],
      "metadata": {
        "id": "gapm-ab-ed7R"
      },
      "id": "gapm-ab-ed7R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test model on entire dataset"
      ],
      "metadata": {
        "id": "vMH44QnNYXMQ"
      },
      "id": "vMH44QnNYXMQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# dataprep\n",
        "df = add_topics_to_df(pan_pj_unified_df, id2word, lda_model)\n",
        "\n",
        "num_lda_topics = len(lda_model.get_topics())\n",
        "x_columns = [f'topic_{i}' for i in range(num_lda_topics)]\n",
        "y_column = ['predator']\n",
        "\n",
        "x_unified_full = pan_pj_unified_df[x_columns]\n",
        "y_unified_full = pan_pj_unified_df[y_column]\n",
        "\n",
        "y_unified_full_pred = rfc.predict_proba(x_unified_full)[:, 1]\n",
        "\n",
        "display_roc_curve_and_get_perfs(y_unified_full, y_unified_full_pred, plot=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "FKmYSDBdXYEf"
      },
      "id": "FKmYSDBdXYEf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test podel on Customer data only"
      ],
      "metadata": {
        "id": "iTXQEQssYmdJ"
      },
      "id": "iTXQEQssYmdJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# update dataframe with topics\n",
        "pj_preprocessed_df = add_topics_to_df(pj_preprocessed_df, id2word, lda_model)\n",
        "\n",
        "# dataprep\n",
        "num_lda_topics = len(lda_model.get_topics())\n",
        "x_columns = [f'topic_{i}' for i in range(num_lda_topics)]\n",
        "y_column = ['predator']\n",
        "\n",
        "x_customer = pj_preprocessed_df[x_columns]\n",
        "y_customer = pj_preprocessed_df[y_column]\n",
        "\n",
        "y_customer_pred = rfc.predict_proba(x_customer)[:, 1]\n",
        "\n",
        "display_roc_curve_and_get_perfs(y_customer, y_customer_pred, plot=True)"
      ],
      "metadata": {
        "id": "0blI5jXkRsf6"
      },
      "id": "0blI5jXkRsf6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9bac1a26",
      "metadata": {
        "id": "9bac1a26"
      },
      "source": [
        "## Backup - not useful currently"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a3c8a5",
      "metadata": {
        "id": "90a3c8a5"
      },
      "source": [
        "#### TF/IDF - **Not used**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f21fe2b",
      "metadata": {
        "id": "9f21fe2b"
      },
      "outputs": [],
      "source": [
        "# Train TF/IDF model\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df = 5, max_df = 0.95)\n",
        "tfidf_vectorizer.fit(pan12_train_df['preprocessed_bow'])\n",
        "\n",
        "# Transform chat messages to vocabulary vectors\n",
        "vectorized_data = tfidf_vectorizer.transform(pan12_train_df['preprocessed_bow'])\n",
        "print(f'Vectorized data shape: {vectorized_data.shape}')\n",
        "\n",
        "print(pan12_train_df['preprocessed_bow'][6])\n",
        "print(vectorized_data[6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc2379a",
      "metadata": {
        "id": "7bc2379a"
      },
      "outputs": [],
      "source": [
        "# create dataframe of vectors\n",
        "tfidf_df = pd.DataFrame(vectorized_data.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
        "# tfidf_df[['sex', 'babe', 'young', 'age', 'dick']].sort_values('dick', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62539499",
      "metadata": {
        "id": "62539499"
      },
      "outputs": [],
      "source": [
        "# https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html\n",
        "#Visualize TF/IDF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bab1a7b2",
      "metadata": {
        "id": "bab1a7b2"
      },
      "source": [
        "#### pan12 line level dataloader **Not used**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64c6027",
      "metadata": {
        "id": "e64c6027"
      },
      "outputs": [],
      "source": [
        "class Pan12LineLevelDataloader():  \n",
        "    \"\"\"\n",
        "    Wrapper around Torch Dataset to perform text classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chat_data_file: Path, user_labels_file: Path=None, line_labels_file: Path=None, preprocess_fn=None, preprocess_args:Dict=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            chat_data_file: path to chat xml file\n",
        "            conversation_labels:\n",
        "            line_labels:  \n",
        "        \"\"\"\n",
        "       \n",
        "        self.chat_data_file = chat_data_file\n",
        "        self.conversations = self._get_conversation_roots(chat_data_file)\n",
        "        self.preprocess_fn = preprocess_fn\n",
        "        self.preprocess_args = preprocess_args\n",
        "\n",
        "        self.user_labels_file = user_labels_file\n",
        "        self.line_labels_file = line_labels_file\n",
        "        self.TEXT_COLUMN_NAME = 'text'\n",
        "\n",
        "        self.length = self._get_ds_length()\n",
        "        self.num_conversations = len(self.conversations)\n",
        "\n",
        "        # Initiate queue\n",
        "        self.message_list = None\n",
        "        self.current_conversation_id = None\n",
        "        self.next_conversation_idx = 0\n",
        "        self.next_message_idx = 0\n",
        "\n",
        "        # Create sets of problematic lines and authors for labels\n",
        "        user_labels = pd.read_csv(user_labels_file, delimiter='\\t', header=None)\n",
        "        self.perverted_authors = set(user_labels[0])\n",
        "\n",
        "        line_labels = pd.read_csv(line_labels_file, delimiter='\\t', header=None)\n",
        "        line_labels['concat'] = line_labels[0] + '_' + line_labels[1].astype(str)\n",
        "        self.pervert_lines = set(line_labels['concat'])\n",
        "\n",
        "        self.load_next_conversation_to_list()\n",
        "                       \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: length of the dataset\n",
        "        \"\"\"\n",
        "        return self.length\n",
        "\n",
        "    def __next__(self) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Gets element of the dataset\n",
        "\n",
        "        Args:\n",
        "            index (int): index of the element in the dataset\n",
        "        Returns:\n",
        "            Single element by index\n",
        "        \"\"\"        \n",
        "        message_dict = {}\n",
        "        try:\n",
        "            message = self.message_list[self.next_message_idx]\n",
        "        except(IndexError):\n",
        "            self.load_next_conversation_to_list()\n",
        "            message = self.message_list[self.next_message_idx]\n",
        "\n",
        "        message_dict['conversation_id'] = self.current_conversation_id\n",
        "        self.next_message_idx += 1\n",
        "        \n",
        "        message_dict['line'] = message.attrib['line']  \n",
        "\n",
        "        for field in message:\n",
        "            message_dict[field.tag] = field.text\n",
        "        \n",
        "        if self.preprocess_fn is not None:\n",
        "            message_dict['text'] = self.preprocess_fn(message_dict['text'], **self.preprocess_args)\n",
        "        \n",
        "        message_dict['author_label'] = 1 if message_dict['author'] in self.perverted_authors else 0\n",
        "        message_dict['line_label'] = 1 if message_dict['conversation_id'] + '_' + message_dict['line'] in self.pervert_lines else 0\n",
        "\n",
        "        return message_dict\n",
        "    \n",
        "    def _get_conversation_roots(self, file_path):\n",
        "        doc_tree = ET.parse(file_path)\n",
        "        conversation_roots = doc_tree.getroot().findall('conversation')\n",
        "        return conversation_roots\n",
        "\n",
        "    def _get_ds_length(self):\n",
        "        number_messages = 0\n",
        "        for conversation in self.conversations:\n",
        "            number_messages += len(conversation.findall('message'))\n",
        "        \n",
        "        return number_messages\n",
        "\n",
        "    def load_next_conversation_to_list(self):\n",
        "        try:\n",
        "            conversation = self.conversations[self.next_conversation_idx] \n",
        "            self.current_conversation_id = conversation.attrib['id']  \n",
        "        except(IndexError):\n",
        "            raise StopIteration()\n",
        "\n",
        "        self.next_conversation_idx += 1\n",
        "        self.message_list = [m for m in conversation.findall('message')]\n",
        "        self.next_message_idx = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dfc77a4",
      "metadata": {
        "id": "7dfc77a4"
      },
      "outputs": [],
      "source": [
        "# # Test dataset\n",
        "# preprocess_args = {'stemmer': PorterStemmer(),\n",
        "#                     'speller': SpellChecker(),\n",
        "#                     'words_to_remove': set(stopwords.words('english')),\n",
        "#                     'emoticons': emoticons,\n",
        "#                     'chat_slang': chat_slang\n",
        "#                     }\n",
        "\n",
        "# pan12_ds = Pan12LineLevelDataloader(PAN12_TEST_DATA_FILE, user_labels_file=PAN12_USER_LABELS_FILE, line_labels_file=PAN12_LINE_LABELS_FILE, preprocess_fn=preprocess_string_for_bow, preprocess_args=preprocess_args)\n",
        "# print(len(pan12_ds))\n",
        "\n",
        "# for i, m in enumerate(pan12_ds):\n",
        "#     print(i, m) \n",
        "#     if i==50:\n",
        "#         break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3aa278e",
      "metadata": {
        "id": "d3aa278e"
      },
      "source": [
        "#### Convert Pan12 to labeled datafreame for use later as Train data - **Not used**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0e52c1",
      "metadata": {
        "id": "2d0e52c1"
      },
      "outputs": [],
      "source": [
        "# class Pan12converterToDF():\n",
        "\n",
        "#     # Pan12 converter for TEST dataset - with line labels!\n",
        "    \n",
        "#     \"\"\"\n",
        "#     Wrapper around Torch Dataset to perform text classification\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, chat_data_file: Path, user_labels_file: Path=None, line_labels_file: Path=None):\n",
        "#         \"\"\"\n",
        "#         Args:\n",
        "#             chat_data_file: path to chat xml file\n",
        "#             conversation_labels:\n",
        "#             line_labels:\n",
        "#             mode:   full - all data \n",
        "#                     positive_lines - Only lines labeled as problematic\n",
        "#         \"\"\"\n",
        "       \n",
        "#         self.chat_data_file = chat_data_file\n",
        "#         self.conversations = self._get_conversation_roots(chat_data_file)\n",
        "\n",
        "#         self.user_labels_file = user_labels_file\n",
        "#         self.line_labels_file = line_labels_file\n",
        "#         self.TEXT_COLUMN_NAME = 'text'\n",
        "\n",
        "#         self.length = self._get_ds_length()\n",
        "#         self.num_conversations = len(self.conversations)\n",
        "\n",
        "#         # Initiate queue\n",
        "#         self.message_list = None\n",
        "#         self.current_conversation_id = None\n",
        "#         self.next_conversation_idx = 0\n",
        "#         self.next_message_idx = 0\n",
        "\n",
        "#         # Create sets of problematic lines and authors for labels\n",
        "#         user_labels = pd.read_csv(user_labels_file, delimiter='\\t', header=None)\n",
        "#         self.perverted_authors = set(user_labels[0])\n",
        "\n",
        "#         line_labels = pd.read_csv(line_labels_file, delimiter='\\t', header=None)\n",
        "#         line_labels['concat'] = line_labels[0] + '_' + line_labels[1].astype(str)\n",
        "#         self.perverted_conversations = set(line_labels[0].unique())\n",
        "#         self.pervert_lines = set(line_labels['concat'])\n",
        "\n",
        "\n",
        "#     def __iter__(self):\n",
        "#         return self\n",
        "\n",
        "#     def __len__(self) -> int:\n",
        "#         \"\"\"\n",
        "#         Returns:\n",
        "#             int: length of the dataset\n",
        "#         \"\"\"\n",
        "#         return self.length\n",
        "\n",
        "#     def convert(self, filename:Path, save_every=2000, mode: str='full') -> pd.DataFrame:\n",
        "#         \"\"\"Gets element of the dataset\n",
        "\n",
        "#         Args:\n",
        "#             index (int): index of the element in the dataset\n",
        "#         Returns:\n",
        "#             Single element by index\n",
        "#         \"\"\"        \n",
        "#         pan12_df = pd.DataFrame(columns=['conversation_id', 'line', 'author', 'time', 'text', 'line_label', 'author_label'])\n",
        "\n",
        "#         self._load_next_conversation_to_list(mode) \n",
        "\n",
        "#         if(mode == 'full'):\n",
        "#             iter_len = self.length\n",
        "#         elif(mode == 'positive_lines'):\n",
        "#             iter_len = len(self.pervert_lines)\n",
        "        \n",
        "#         for i in tqdm(range(iter_len)):\n",
        "#             message_dict = {}\n",
        "#             try:\n",
        "#                 message = self.message_list[self.next_message_idx]\n",
        "#             except(IndexError):\n",
        "#                 self._load_next_conversation_to_list(mode)\n",
        "#                 message = self.message_list[self.next_message_idx]\n",
        "            \n",
        "#             message_dict['conversation_id'] = self.current_conversation_id\n",
        "#             self.next_message_idx += 1\n",
        "            \n",
        "#             message_dict['line'] = message.attrib['line']  \n",
        "#             for field in message:\n",
        "#                 message_dict[field.tag] = field.text\n",
        "            \n",
        "#             message_dict['author_label'] = 1 if message_dict['author'] in self.perverted_authors else 0\n",
        "#             message_dict['line_label'] = 1 if message_dict['conversation_id'] + '_' + message_dict['line'] in self.pervert_lines else 0\n",
        "            \n",
        "#             pan12_df = pan12_df.append(message_dict, ignore_index=True)\n",
        "#             if i % save_every == 0:\n",
        "#                 pan12_df.to_csv(filename)\n",
        "#                 print('.', end='')\n",
        "\n",
        "#             # #######\n",
        "#             # if i == 1001:\n",
        "#             #     print(pan12_df.head(2001))\n",
        "#             #     break\n",
        "#             # ######\n",
        "#         pan12_df.to_csv(filename)\n",
        "#         return pan12_df\n",
        "    \n",
        "#     def _get_conversation_roots(self, file_path):\n",
        "#         doc_tree = ET.parse(file_path)\n",
        "#         conversation_roots = doc_tree.getroot().findall('conversation')\n",
        "#         return conversation_roots\n",
        "\n",
        "#     def _get_ds_length(self):\n",
        "#         number_messages = 0\n",
        "#         for conversation in self.conversations:\n",
        "#             number_messages += len(conversation.findall('message'))\n",
        "        \n",
        "#         return number_messages\n",
        "\n",
        "#     def _load_next_conversation_to_list(self, mode):\n",
        "#         try:\n",
        "#             conversation = self.conversations[self.next_conversation_idx] \n",
        "#             self.next_conversation_idx += 1\n",
        "#             self.current_conversation_id = conversation.attrib['id']  \n",
        "\n",
        "#             if mode == 'positive_lines':\n",
        "#                 while self.current_conversation_id not in self.perverted_conversations:\n",
        "#                     conversation = self.conversations[self.next_conversation_idx] \n",
        "#                     self.next_conversation_idx += 1\n",
        "#                     self.current_conversation_id = conversation.attrib['id']  \n",
        "     \n",
        "#         except(IndexError):\n",
        "#             raise StopIteration()\n",
        "\n",
        "#         if mode == 'positive_lines':\n",
        "#             self.message_list = [m for m in conversation.findall('message') if (self.current_conversation_id + '_' + m.attrib['line'] in self.pervert_lines)]\n",
        "#         else:\n",
        "#             self.message_list = [m for m in conversation.findall('message')]\n",
        "#         self.next_message_idx = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92dd4938",
      "metadata": {
        "id": "92dd4938"
      },
      "outputs": [],
      "source": [
        "# # PAN12_PERVERTED_LINES_CSV = OUTPUT_FOLDER / Path('pan12_perverted_lines_preprocessed.csv')\n",
        "# PAN12_PERVERTED_LINES_CSV = OUTPUT_FOLDER / Path('pan12_full_lines_preprocessed.csv')\n",
        "\n",
        "# PAN12_FULL_RAW_CSV = OUTPUT_FOLDER / Path('pan12_raw_full.csv')\n",
        "\n",
        "# if CREATE_FULL_PAN12_DATAFRAME == 'Process':\n",
        "#     # Create a dataframe of all pan12 test perverted lines\n",
        "#     pan12_converter = Pan12converterToDF(PAN12_TEST_DATA_FILE, user_labels_file=PAN12_USER_LABELS_FILE, line_labels_file=PAN12_LINE_LABELS_FILE)\n",
        "#     print(len(pan12_converter))\n",
        "#     # pan12_df = pan12_converter.convert(PAN12_FULL_RAW_CSV, mode='positive_lines')\n",
        "#     pan12_df = pan12_converter.convert(PAN12_FULL_RAW_CSV, mode='full')\n",
        "#     print(f'lines in pan12_df: {len(pan12_df)}')\n",
        "\n",
        "#     # Preprocess pan12 perverted lines only and save to csv\n",
        "#     preprocess_args = {'stemmer': PorterStemmer(),\n",
        "#                         'speller': SpellChecker(),\n",
        "#                         'words_to_remove': set(stopwords.words('english')),\n",
        "#                         'emoticons': emoticons,\n",
        "#                         'chat_slang': chat_slang\n",
        "#                         }\n",
        "\n",
        "#     pan12_df = preprocess_df_for_bow(pan12_df, 'text', **preprocess_args)\n",
        "#     pan12_df.to_csv(PAN12_PERVERTED_LINES_CSV)\n",
        "\n",
        "#     # add features to pan12 df\n",
        "#     pan12_df = add_wordlist_features(pan12_df, 'preprocessed_bow', sex_word_list, family_word_list, meeting_word_list)\n",
        "#     pan12_df.to_csv(PAN12_PERVERTED_LINES_CSV)\n",
        "\n",
        "# elif CREATE_FULL_PAN12_DATAFRAME == 'Load':\n",
        "#     pan12_df = pd.read_csv(PAN12_PERVERTED_LINES_CSV)\n",
        "\n",
        "# pan12_df = pan12_df.dropna()\n",
        "# pan12_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886275cc",
      "metadata": {
        "id": "886275cc"
      },
      "source": [
        "#### Load entire PJ dataset as single dataframe of chat lines - **Not used**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3818aedd-70b1-4802-b66b-6f8116cb4dbf",
      "metadata": {
        "id": "3818aedd-70b1-4802-b66b-6f8116cb4dbf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# class PjSentencesDataset(Dataset):\n",
        "#     \"\"\"\n",
        "#     Wrapper around Torch Dataset.\n",
        "#     Prepares an indexed list of PJ conversation in a folder, returns conversations per index (like an array)\n",
        "#     Load is lazy - loads conversation from disk on request.\n",
        "#     Uses load_one_chat_as_df_pj() for conversation loading\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, data_folder: Path, df_preprocess_fn=None, df_preprocess_args:Dict=None):\n",
        "#         \"\"\"\n",
        "#         Args:\n",
        "#           data_folder - folder with PJ XML files\n",
        "#           df_preprocess_fn - function that gets a dataframe and adds preprocesed text column based on given text column\n",
        "\n",
        "#         \"\"\"\n",
        "       \n",
        "#         self.file_list = list_files_in_dir(data_folder, extension='xml')\n",
        "#         self.df_preprocess_fn = df_preprocess_fn\n",
        "#         self.df_preprocess_args = df_preprocess_args\n",
        "#         self.TEXT_COLUMN_NAME = 'BODY'\n",
        "\n",
        "        \n",
        "#     def __len__(self) -> int:\n",
        "#         \"\"\"\n",
        "#         Returns:\n",
        "#             int: length of the dataset\n",
        "#         \"\"\"\n",
        "#         return len(self.file_list)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         \"\"\"Gets element of the dataset\n",
        "\n",
        "#         Args:\n",
        "#             index (int): index of the element in the dataset\n",
        "#         Returns:\n",
        "#             Single element by index\n",
        "#         \"\"\"        \n",
        "#         sample = load_one_chat_as_df_pj(self.file_list[idx])\n",
        "#         if (self.df_preprocess_fn is not None) and (sample is not None):\n",
        "#             sample['conversation'] = self.df_preprocess_fn(sample['conversation'], self.TEXT_COLUMN_NAME, **self.df_preprocess_args)\n",
        "\n",
        "#         return sample\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7562daf7",
      "metadata": {
        "id": "7562daf7"
      },
      "outputs": [],
      "source": [
        "# # Test the dataset\n",
        "# preprocess_args = {'stemmer': PorterStemmer(),\n",
        "#                     'speller': SpellChecker(),\n",
        "#                     'words_to_remove': set(stopwords.words('english')),\n",
        "#                     'emoticons': emoticons,\n",
        "#                     'chat_slang': chat_slang,\n",
        "#                     }\n",
        "                    \n",
        "# pj_ds = PjSentencesDataset(PJ_DATA_FOLDER, df_preprocess_fn=preprocess_df_for_bow, df_preprocess_args=preprocess_args)\n",
        "# print(len(pj_ds))\n",
        "# print(pj_ds[1]['conversation_id'])\n",
        "# pj_ds[1]['conversation'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8a5905e",
      "metadata": {
        "id": "c8a5905e"
      },
      "outputs": [],
      "source": [
        "# # Create full dataframe, no preprocessing yet\n",
        "\n",
        "# def load_pj_dataset(data_folder:Path):\n",
        "#     pj_df = None                    \n",
        "#     pj_ds = PjSentencesDataset(data_folder)\n",
        "\n",
        "#     for i in tqdm(range(len(pj_ds))):\n",
        "#         conversation_dict = pj_ds[i]\n",
        "#         if not conversation_dict is None:\n",
        "#             conversation = conversation_dict['conversation']\n",
        "#             conversation['conversation_id'] = conversation_dict['conversation_id']\n",
        "\n",
        "#             if not pj_df is None:\n",
        "#                 pj_df = pj_df.append(conversation)\n",
        "#             else:\n",
        "#                 pj_df = conversation.copy()\n",
        "    \n",
        "#     return pj_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd051e12",
      "metadata": {
        "id": "bd051e12"
      },
      "outputs": [],
      "source": [
        "# PJ_PREPROCESSED_CSV_PATH = OUTPUT_FOLDER / Path('pj_preprocessed_dataframe.csv')\n",
        "# PJ_FULL_RAW_CSV = OUTPUT_FOLDER / Path('pj2_raw_full.csv')\n",
        "\n",
        "# if CREATE_FULL_PJ_DATAFRAME_SENTENCE_LEVEL == 'Process':\n",
        "#     # load original dataset\n",
        "#     pj_sentences_df = load_pj_dataset(PJ_DATA_FOLDER)\n",
        "#     pj_sentences_df.to_csv(PJ_FULL_RAW_CSV)\n",
        "\n",
        "#     # preprocess and add features\n",
        "#     preprocess_args = {'stemmer': PorterStemmer(),\n",
        "#                         'speller': SpellChecker(),\n",
        "#                         'words_to_remove': set(stopwords.words('english')),\n",
        "#                         'emoticons': emoticons,\n",
        "#                         'chat_slang': chat_slang,\n",
        "#                         }\n",
        "\n",
        "#     pj_sentences_df = preprocess_df_for_bow(pj_sentences_df, 'BODY', **preprocess_args)\n",
        "#     pj_sentences_df = add_wordlist_features(pj_sentences_df, 'preprocessed_bow', sex_word_list, family_word_list, meeting_word_list)\n",
        "#     pj_sentences_df.to_csv(PJ_PREPROCESSED_CSV_PATH)\n",
        "\n",
        "# elif CREATE_FULL_PJ_DATAFRAME_SENTENCE_LEVEL == 'Load':\n",
        "#     pj_sentences_df = pd.read_csv(PJ_PREPROCESSED_CSV_PATH, index_col=0)\n",
        "\n",
        "\n",
        "# pj_sentences_df = pj_sentences_df[pj_sentences_df['preprocessed_bow'].notna()]\n",
        "# pj_sentences_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fbbf9a3",
      "metadata": {
        "id": "0fbbf9a3"
      },
      "outputs": [],
      "source": [
        "# pj_sentences_df.groupby(['conversation_id']).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d684c5",
      "metadata": {
        "id": "72d684c5"
      },
      "source": [
        "## some thoughts\n",
        "Bag of words - sexual words, fear, trust, family, approach (Location, transport) , other categories - DrouinBoydHancockJames2017\n",
        "Good article: file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/Early%20Text%20Classification%20using%20Multi-Resolution%20Concept%20Representations.pdf\n",
        "Ensamble and preprocessing: file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/PredatoryConversationDetection.pdf\n",
        "file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/Analyzing_Chat_Conversations_of_Pedophil.pdf\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "98514e4d",
        "m3FuuqiQ2Sk3",
        "037ad22d",
        "065d0df3",
        "b0844b40",
        "b8db35ba",
        "was5bvfMwGeZ",
        "khNzXWimJUCq",
        "09720ea7",
        "66cde0de",
        "5c0d4bf5",
        "600af7b9",
        "80NQ45KMZb15",
        "kAxJasN3puIO",
        "Jr7F2Ou8njOZ",
        "9bac1a26",
        "90a3c8a5",
        "bab1a7b2",
        "d3aa278e",
        "886275cc"
      ],
      "machine_shape": "hm",
      "name": "cyber_hw2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1a8e22f9a50968eda7c2b2da6b1cd647c6294c71990fbcb0be47dbd614eb6ed8"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d40ac9d8d4f047e39de2073aea9081a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2db3eacea41d49dd9ca7ee6b171529f1",
              "IPY_MODEL_b300b572616448d78c69cde93a9de496",
              "IPY_MODEL_4066155448ca4327b75b1eeb11ee9803"
            ],
            "layout": "IPY_MODEL_5a37284ad13e4bf0bab398c40b7c6de6"
          }
        },
        "2db3eacea41d49dd9ca7ee6b171529f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7625ab67ebe4845919296c0ea13d2bd",
            "placeholder": "​",
            "style": "IPY_MODEL_3135c6f5d49640cd89d17d3ef7a32f87",
            "value": "100%"
          }
        },
        "b300b572616448d78c69cde93a9de496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe0ee99c0d643479b584f450cce2b07",
            "max": 123,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e0db75ac6bd4cbf93acffe5209c0dfb",
            "value": 123
          }
        },
        "4066155448ca4327b75b1eeb11ee9803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1afb056c343a4d249d09e03901e24566",
            "placeholder": "​",
            "style": "IPY_MODEL_766f2da80aa54630af7b2886e770b60f",
            "value": " 123/123 [00:00&lt;00:00, 1860.53it/s]"
          }
        },
        "5a37284ad13e4bf0bab398c40b7c6de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7625ab67ebe4845919296c0ea13d2bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3135c6f5d49640cd89d17d3ef7a32f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe0ee99c0d643479b584f450cce2b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e0db75ac6bd4cbf93acffe5209c0dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1afb056c343a4d249d09e03901e24566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "766f2da80aa54630af7b2886e770b60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a09b813467f84ce2be71c01cfe8ffe0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_764888db91b7493f997b275d3391bd61",
              "IPY_MODEL_08efc49d30b142d28b842c95cb8c9c69",
              "IPY_MODEL_24a9858cdccd4d28a121751277368e7d"
            ],
            "layout": "IPY_MODEL_91d7aceb8b334d5b9b9d99d2bb6c90c1"
          }
        },
        "764888db91b7493f997b275d3391bd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf464a4d2971448abeff4a8b0fced125",
            "placeholder": "​",
            "style": "IPY_MODEL_20c8adf59fb14febaed6ac1506c6b34e",
            "value": "100%"
          }
        },
        "08efc49d30b142d28b842c95cb8c9c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f72d2f8c89242a7a3642ad309ac0882",
            "max": 99502,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a14bf716be90487abd2dfae080a50968",
            "value": 99502
          }
        },
        "24a9858cdccd4d28a121751277368e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33fb918038104c638fb541e1ad30b80a",
            "placeholder": "​",
            "style": "IPY_MODEL_775a0f126ae446639966550dbdf0493c",
            "value": " 99502/99502 [00:00&lt;00:00, 236010.33it/s]"
          }
        },
        "91d7aceb8b334d5b9b9d99d2bb6c90c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf464a4d2971448abeff4a8b0fced125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c8adf59fb14febaed6ac1506c6b34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f72d2f8c89242a7a3642ad309ac0882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14bf716be90487abd2dfae080a50968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33fb918038104c638fb541e1ad30b80a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "775a0f126ae446639966550dbdf0493c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "218f0581d26440e1a0927314b976400e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9858d77455834e42bc47179f5d6bd3a1",
              "IPY_MODEL_b665f6f3b7744fbb9c748c21104a5c56",
              "IPY_MODEL_6580fcfafe5f4d23b97b41e4935bbdb9"
            ],
            "layout": "IPY_MODEL_2dcf20615e9041348a49894ec7679bce"
          }
        },
        "9858d77455834e42bc47179f5d6bd3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22c8be85f9af4a40838fd3e5c5817e27",
            "placeholder": "​",
            "style": "IPY_MODEL_b5e8146bd7324e428740e51b04dd5eca",
            "value": "  0%"
          }
        },
        "b665f6f3b7744fbb9c748c21104a5c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6525b4c7fded4f07825c782237dbcc4d",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97ca2dce8e91459a980a1709e08bc68d",
            "value": 0
          }
        },
        "6580fcfafe5f4d23b97b41e4935bbdb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c24272063414439bad1fd7a92e569116",
            "placeholder": "​",
            "style": "IPY_MODEL_a2a9277c5b7e4307bd5e934e57a30134",
            "value": " 0/5 [00:00&lt;?, ?it/s]"
          }
        },
        "2dcf20615e9041348a49894ec7679bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c8be85f9af4a40838fd3e5c5817e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e8146bd7324e428740e51b04dd5eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6525b4c7fded4f07825c782237dbcc4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ca2dce8e91459a980a1709e08bc68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c24272063414439bad1fd7a92e569116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a9277c5b7e4307bd5e934e57a30134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}