{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f086e0e1",
      "metadata": {
        "id": "f086e0e1",
        "tags": []
      },
      "source": [
        "## General - imports paths etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X7ncp3Hf4hJX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ncp3Hf4hJX",
        "outputId": "3286ae7f-0849-41d9-d87f-2bb9342b8ba9"
      },
      "outputs": [],
      "source": [
        "# %pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "683f43e6-ff1c-4c28-af4c-3452553fc476",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "683f43e6-ff1c-4c28-af4c-3452553fc476",
        "outputId": "e026db55-de59-40bd-bc1e-fe33a2fd15ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\mryan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from ipywidgets import IntProgress\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import spacy\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "import xml.etree.ElementTree as ET \n",
        "import csv\n",
        "\n",
        "from typing import Dict, Callable, List, Dict, Set, Any\n",
        "import logging\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m3FuuqiQ2Sk3",
      "metadata": {
        "id": "m3FuuqiQ2Sk3"
      },
      "source": [
        "## Env control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "LAmVCG5d2Y-M",
      "metadata": {
        "id": "LAmVCG5d2Y-M"
      },
      "outputs": [],
      "source": [
        "# ENV = 'Colab'\n",
        "ENV = 'Local'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bf9de114-ddde-43d7-9d6a-69d1b0a913d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf9de114-ddde-43d7-9d6a-69d1b0a913d0",
        "outputId": "8384cef9-9e3c-47a2-ce08-e86f3a761b2c"
      },
      "outputs": [],
      "source": [
        "# Folders\n",
        "if ENV=='Local':\n",
        "  PROJECT_ROOT = Path('./')\n",
        "\n",
        "elif ENV=='Colab':\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  PROJECT_ROOT = Path('/content/drive/MyDrive/colab_data/cyber2/')\n",
        "  \n",
        "\n",
        "PJ_DATA_FOLDER = PROJECT_ROOT / Path('customer_data')\n",
        "PAN12_DATA_FILE = PROJECT_ROOT / Path('ref_data/pan12_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml')\n",
        "PAN12_LINE_LABELS_FILE = PROJECT_ROOT / Path('ref_data/pan12_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-groundtruth-problem2.txt')\n",
        "PAN12_USER_LABELS_FILE = PROJECT_ROOT / Path('ref_data/pan12_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-groundtruth-problem1.txt')\n",
        "OUTPUT_FOLDER = PROJECT_ROOT\n",
        "\n",
        "if not PAN12_DATA_FILE.exists():\n",
        "    raise FileNotFoundError('File not found!')\n",
        "\n",
        "if not PAN12_LINE_LABELS_FILE.exists():\n",
        "    raise FileNotFoundError('File not found!')  \n",
        "\n",
        "if not PAN12_USER_LABELS_FILE.exists():\n",
        "    raise FileNotFoundError('File not found!') \n",
        "\n",
        "if not PJ_DATA_FOLDER.is_dir():\n",
        "    raise FileNotFoundError('Directry not found!') \n",
        "\n",
        "if not OUTPUT_FOLDER.is_dir():\n",
        "    raise FileNotFoundError('Directry not found!') \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "037ad22d",
      "metadata": {
        "id": "037ad22d"
      },
      "source": [
        "#### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eaf51658",
      "metadata": {
        "id": "eaf51658"
      },
      "outputs": [],
      "source": [
        "# Define datasets with texts and labels\n",
        "\n",
        "def list_files_in_dir(folder: Path, extension='*') -> List:\n",
        "    \n",
        "    file_list = [f for f in folder.glob(f'**/*.{extension}') if f.is_file()]\n",
        "    return file_list\n",
        "\n",
        "## Test funcion\n",
        "# list_files_in_dir(DATA_FOLDER, 'dtd')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "065d0df3",
      "metadata": {
        "id": "065d0df3"
      },
      "source": [
        "### Word lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "70954f6b",
      "metadata": {
        "id": "70954f6b"
      },
      "outputs": [],
      "source": [
        "# Load word lists\n",
        "SEX_WL_PATH = PROJECT_ROOT / Path(r'sex_words.txt')\n",
        "with open(SEX_WL_PATH, 'rt') as handle:\n",
        "    sex_word_list = handle.read().split('\\n')\n",
        "\n",
        "MEETING_WL_PATH = SEX_WL_PATH = PROJECT_ROOT / Path(r'meeting_words.txt')\n",
        "with open(MEETING_WL_PATH, 'rt') as handle:\n",
        "    meeting_word_list = handle.read().split('\\n')\n",
        "\n",
        "FAMILY_WL_PATH = SEX_WL_PATH = PROJECT_ROOT / Path(r'family_words.txt')\n",
        "with open(FAMILY_WL_PATH, 'rt') as handle:\n",
        "    family_word_list = handle.read().split('\\n')\n",
        "\n",
        "CHAT_SLANG_PATH = SEX_WL_PATH = PROJECT_ROOT / Path(r'chat_slang.txt')\n",
        "with open(CHAT_SLANG_PATH, mode='rt') as handle:\n",
        "    csv_reader = csv.reader(handle, delimiter='\\t')\n",
        "    chat_slang = {rows[0]:rows[1] for rows in csv_reader}\n",
        "\n",
        "EMOTICONS_PATH = SEX_WL_PATH = PROJECT_ROOT / Path(r'emoticons.txt')\n",
        "with open(EMOTICONS_PATH, mode='rt', encoding=\"utf8\") as handle:\n",
        "    csv_reader = csv.reader(handle, delimiter='\\t')\n",
        "    emoticons = {rows[0]:rows[1] for rows in csv_reader}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0844b40",
      "metadata": {
        "id": "b0844b40",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e182ed0",
      "metadata": {
        "id": "3e182ed0",
        "tags": []
      },
      "source": [
        "### Chat text preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "34d2873c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "34d2873c",
        "outputId": "b23b6c28-f30f-4d69-9d8f-3e7a0e752c33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'yeah well i just want to see you before i go in the apt cause one of my friends got arrested for doing the same thing with a 16 year old it was a set up type thing'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "def remove_stopwords(text: str, words_to_remove: List[str])-> str:\n",
        "    '''\n",
        "    Gets string, returns it without stopwords\n",
        "    '''\n",
        "    return \" \".join([word for word in str(text).split() if word not in words_to_remove])\n",
        "\n",
        "\n",
        "def stem_text(text: str, stemmer: Any)-> str:\n",
        "    '''\n",
        "    stem text string\n",
        "    '''\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "\n",
        "def remove_emoji(text: str) -> str:\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "def remove_emoticons(text: str, emoticons: Dict) -> str:\n",
        "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in emoticons) + u')')\n",
        "    return emoticon_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "def replace_pornsites_with_string(text:str, replacement_string:str='porn')->str:\n",
        "    pornsite_pattern = re.compile(r'\\S+xnxx\\.co\\S+' + r'|\\S+pornhub\\.co\\S+' + r'|\\S+nude\\.co\\S+' + r'|\\S+sex\\.co\\S+')\n",
        "    return pornsite_pattern.sub(replacement_string, text)\n",
        "\n",
        "def remove_urls(text:str)-> str:\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "def remove_special_characters(text:str)-> str:\n",
        "    special_chars_pattern = re.compile(r'[^A-Za-z0-9 ]+')\n",
        "    return special_chars_pattern.sub(r' ', text)\n",
        "\n",
        "\n",
        "def replace_chat_slang(text: str, chat_slang: Dict[str, str])-> str:\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_slang.keys():\n",
        "            new_text.append(chat_slang[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)\n",
        "\n",
        "\n",
        "def correct_spellings(text: str, speller: Callable) -> str:\n",
        "    corrected_text = []\n",
        "    misspelled_words = speller.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(speller.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "    return \" \".join(corrected_text)\n",
        "\n",
        "\n",
        "def preprocess_string_for_bow(text: str, stemmer: Callable=None, speller: Callable=None, words_to_remove:List[str]=None, emoticons: Dict[str, str]=None, chat_slang: Dict[str, str]=None)-> str:\n",
        "    try:\n",
        "        text = remove_emoji(text)\n",
        "        text = remove_emoticons(text, emoticons)\n",
        "        text = replace_chat_slang(text, chat_slang)\n",
        "        text = text.lower()\n",
        "        text = replace_pornsites_with_string(text)\n",
        "        text = remove_urls(text)\n",
        "        text = remove_special_characters(text)\n",
        "        text = correct_spellings(text, speller)\n",
        "        # text = remove_stopwords(text, words_to_remove)\n",
        "        # text = stem_text(text, stemmer)\n",
        "    except(TypeError):\n",
        "        print(f'Problematic string: {text}')\n",
        "        text = ''\n",
        "    return text\n",
        "\n",
        "\n",
        "def preprocess_df_for_bow(df: pd.DataFrame, text_col: str, output_col_name='preprocessed_bow', stemmer=None, speller=None, words_to_remove=None, emoticons=None, chat_slang=None)-> pd.DataFrame:\n",
        "    '''\n",
        "    Gets a PD dataframe and a text column name\n",
        "    returns the same dataframe with additional column called 'posts_preprocessed_bow'\n",
        "    '''\n",
        "    df[output_col_name] = df[text_col]\n",
        "    df[output_col_name] = df[output_col_name].apply(lambda text: preprocess_string_for_bow(text, stemmer=stemmer, speller=speller, words_to_remove=words_to_remove, emoticons=emoticons, chat_slang=chat_slang))\n",
        "    return df\n",
        "\n",
        "\n",
        "# test\n",
        "preprocess_args = {'stemmer': PorterStemmer(),\n",
        "                    'speller': SpellChecker(),\n",
        "                    'words_to_remove': set(stopwords.words('english')),\n",
        "                    'emoticons': emoticons,\n",
        "                    'chat_slang': chat_slang\n",
        "                    }\n",
        "\n",
        "text = 'r u going to www.google.com http://xnxx.com im walking LOL ths is not &amp;right im caming flight now u r right brb and fu :-)'\n",
        "text = 'yeah--well I just want to see you before I go in the apt--cause one of my friends got arrested for doing the same thing with a 16 year old--it was a set-up type thing'\n",
        "\n",
        "preprocess_string_for_bow(text, **preprocess_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d31dd2",
      "metadata": {
        "id": "f4d31dd2",
        "tags": []
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8db35ba",
      "metadata": {},
      "source": [
        "### PJ dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f8fc852-a907-4706-a742-14207e2eccf2",
      "metadata": {
        "id": "0f8fc852-a907-4706-a742-14207e2eccf2"
      },
      "source": [
        "#### PJ Convesation level dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00ea3ef6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "00ea3ef6",
        "outputId": "d17865e4-16d2-4647-eec6-8d3348a5ac1c"
      },
      "outputs": [],
      "source": [
        "def load_one_chat_as_df_pj(file_path: Path) -> Dict[str, pd.DataFrame]:\n",
        "    '''\n",
        "    Gets an path to a PJ XML file\n",
        "    returns a dict with three dataframes:\n",
        "        - victim data\n",
        "        - predator data\n",
        "        - conversation posts\n",
        "    '''\n",
        "    parser = ET.XMLParser(encoding=\"utf-8\")\n",
        "    doc_tree = ET.parse(file_path, parser=parser)\n",
        "    doc_root = doc_tree.getroot()\n",
        "    \n",
        "    posts_df = pd.DataFrame(columns = ['USERNAME', 'DATETIME', 'BODY', 'COMMENT', 'CODING'], dtype=str)\n",
        "    predator_df = pd.DataFrame(columns = ['FIRSTNAME', 'LASTNAME', 'STATEDNAME', 'STATEDAGE', 'GENDER', 'RACE', 'CITY', 'STATE', 'REPEATOFFENDER', 'ADMITGUILT', 'TRUTHFULNAME', 'SCREENNAME'], dtype=str)\n",
        "    victim_df = pd.DataFrame(columns = ['FIRSTNAME', 'LASTNAME', 'STATEDNAME', 'STATEDAGE', 'GENDER', 'RACE', 'CITY', 'STATE', 'PREVIOUSVICTIMIZATION', 'ADMITGUILT', 'SCREENNAME'], dtype=str)\n",
        "\n",
        "    for post in doc_root.findall('POST'):\n",
        "        post_dict = {}\n",
        "        for field in post:\n",
        "            post_dict[field.tag] = field.text\n",
        "\n",
        "        posts_df = posts_df.append(post_dict, ignore_index=True)\n",
        "    posts_df = posts_df.astype('string')\n",
        "\n",
        "\n",
        "    for predator in doc_root.findall('PREDATOR'):\n",
        "        predator_dict = {}\n",
        "        for field in predator:\n",
        "            predator_dict[field.tag] = field.text\n",
        "\n",
        "        predator_df = predator_df.append(predator_dict, ignore_index=True)   \n",
        "    predator_df = predator_df.astype('string')\n",
        "\n",
        "\n",
        "    for victim in doc_root.findall('VICTIM'):\n",
        "        victim_dict = {}\n",
        "        for field in victim:\n",
        "            victim_dict[field.tag] = field.text\n",
        "\n",
        "        victim_df = victim_df.append(victim_dict, ignore_index=True)  \n",
        "    victim_df = victim_df.astype('string')\n",
        "\n",
        "    return {'predator': predator_df, 'victim': victim_df, 'conversation': posts_df}\n",
        "\n",
        "\n",
        "#----------------------------------------------------------\n",
        "# Test XML parse functions:\n",
        "file_path = PJ_DATA_FOLDER / Path('ArmySgt1961.xml')\n",
        "chat_dict = load_one_chat_as_df_pj(file_path)\n",
        "chat_dict['victim'].head()\n",
        "chat_dict['predator'].head()\n",
        "chat_dict['conversation'].head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3818aedd-70b1-4802-b66b-6f8116cb4dbf",
      "metadata": {
        "id": "3818aedd-70b1-4802-b66b-6f8116cb4dbf"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PjDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Wrapper around Torch Dataset.\n",
        "    Prepares an indexed list of PJ conversation in a folder, returns conversations per index (like an array)\n",
        "    Load is lazy - loads conversation from disk on request.\n",
        "    Uses load_one_chat_as_df_pj() for conversation loading\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_folder: Path, df_preprocess_fn=None, df_preprocess_args:Dict=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          data_folder - folder with PJ XML files\n",
        "          df_preprocess_fn - function that gets a dataframe and adds preprocesed text column based on given text column\n",
        "\n",
        "        \"\"\"\n",
        "       \n",
        "        self.file_list = list_files_in_dir(data_folder, extension='xml')\n",
        "        self.df_preprocess_fn = df_preprocess_fn\n",
        "        self.df_preprocess_args = df_preprocess_args\n",
        "        self.TEXT_COLUMN_NAME = 'BODY'\n",
        "\n",
        "        \n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: length of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Gets element of the dataset\n",
        "\n",
        "        Args:\n",
        "            index (int): index of the element in the dataset\n",
        "        Returns:\n",
        "            Single element by index\n",
        "        \"\"\"        \n",
        "        sample = load_one_chat_as_df_pj(self.file_list[idx])['conversation']\n",
        "        if self.df_preprocess_fn is not None:\n",
        "            sample = self.df_preprocess_fn(sample, self.TEXT_COLUMN_NAME, **self.df_preprocess_args)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7562daf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "7562daf7",
        "outputId": "29bd848e-bb88-464c-ad87-1e7ffd617ae3"
      },
      "outputs": [],
      "source": [
        "# Test the dataset\n",
        "preprocess_args = {'stemmer': PorterStemmer(),\n",
        "                    'speller': SpellChecker(),\n",
        "                    'words_to_remove': set(stopwords.words('english')),\n",
        "                    'emoticons': emoticons,\n",
        "                    'chat_slang': chat_slang\n",
        "                    }\n",
        "                    \n",
        "pj_ds = PjDataset(PJ_DATA_FOLDER, df_preprocess_fn=preprocess_df_for_bow, df_preprocess_args=preprocess_args)\n",
        "print(len(pj_ds))\n",
        "print(pj_ds.file_list[1])\n",
        "pj_ds[1].head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ae40be1",
      "metadata": {},
      "source": [
        "### Pan12 dataloader and dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f0a4589",
      "metadata": {
        "id": "6f0a4589"
      },
      "source": [
        "#### Pan12 convesation level dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e001f9d6",
      "metadata": {
        "id": "e001f9d6"
      },
      "outputs": [],
      "source": [
        "class Pan12Dataset(Dataset):\n",
        "    '''\n",
        "    Wrapper around Torch Dataset.\n",
        "    Prepares an indexed list of Pan12 conversation in a folder, returns conversations per index (like an array)\n",
        "    Load is lazy - loads conversation from disk on request.\n",
        "    Uses load_one_chat_as_df_pj() for conversation loading\n",
        "    '''\n",
        "\n",
        "    def __init__(self, chat_data_file: Path, conversation_labels: Path=None, line_labels: Path=None, preprocess_fn=None, preprocess_args=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            chat_data_file: path to chat xml file\n",
        "            conversation_labels:\n",
        "            line_labels:  \n",
        "        \"\"\"\n",
        "       \n",
        "        self.chat_data_file = chat_data_file\n",
        "        self.conversations = self._get_conversation_roots(chat_data_file)\n",
        "        self.preprocess_fn = preprocess_fn\n",
        "        self.preprocess_args = preprocess_args\n",
        "\n",
        "        self.conversation_labels = conversation_labels\n",
        "        self.line_labels = line_labels\n",
        "\n",
        "        self.TEXT_COLUMN_NAME = 'text'\n",
        "\n",
        "                \n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: length of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.conversations)\n",
        "\n",
        "    def __getitem__(self, idx) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Gets element of the dataset\n",
        "\n",
        "        Args:\n",
        "            index (int): index of the element in the dataset\n",
        "        Returns:\n",
        "            Single element by index\n",
        "        \"\"\"        \n",
        "\n",
        "        conversation = self.conversations[idx]\n",
        "        conversation_id = conversation.attrib['id']\n",
        "        conversation_df = pd.DataFrame(columns = ['author', 'line', 'time', 'text'], dtype=str)\n",
        "\n",
        "        for message in conversation.findall('message'):\n",
        "            message_dict = {}\n",
        "            message_dict['line'] = message.attrib['line']\n",
        "            for field in message:\n",
        "                message_dict[field.tag] = field.text\n",
        "\n",
        "            conversation_df = conversation_df.append(message_dict, ignore_index=True)\n",
        "                \n",
        "        if self.preprocess_fn is not None:\n",
        "            conversation_df = self.preprocess_fn(conversation_df, self.TEXT_COLUMN_NAME, **self.preprocess_args)\n",
        "\n",
        "        return {'conversation_id': conversation_id, 'conversation': conversation_df}\n",
        "    \n",
        "    def _get_conversation_roots(self, file_path):\n",
        "        doc_tree = ET.parse(file_path)\n",
        "        conversation_roots = doc_tree.getroot().findall('conversation')\n",
        "        return conversation_roots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa6bbd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eaa6bbd4",
        "outputId": "f0674403-59f1-4453-e668-802ddf728610"
      },
      "outputs": [],
      "source": [
        "preprocess_args = {'stemmer': PorterStemmer(),\n",
        "                    'speller': SpellChecker(),\n",
        "                    'words_to_remove': set(stopwords.words('english')),\n",
        "                    'emoticons': emoticons,\n",
        "                    'chat_slang': chat_slang\n",
        "                    }\n",
        "\n",
        "pan12_ds = Pan12Dataset(PAN12_DATA_FILE, preprocess_fn=preprocess_df_for_bow, preprocess_args=preprocess_args)\n",
        "pan12_ds[34]['conversation']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bab1a7b2",
      "metadata": {
        "id": "bab1a7b2"
      },
      "source": [
        "#### pan12 line level dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64c6027",
      "metadata": {
        "id": "e64c6027"
      },
      "outputs": [],
      "source": [
        "class Pan12LineLevelDataloader():  \n",
        "    \"\"\"\n",
        "    Wrapper around Torch Dataset to perform text classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chat_data_file: Path, user_labels_file: Path=None, line_labels_file: Path=None, preprocess_fn=None, preprocess_args:Dict=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            chat_data_file: path to chat xml file\n",
        "            conversation_labels:\n",
        "            line_labels:  \n",
        "        \"\"\"\n",
        "       \n",
        "        self.chat_data_file = chat_data_file\n",
        "        self.conversations = self._get_conversation_roots(chat_data_file)\n",
        "        self.preprocess_fn = preprocess_fn\n",
        "        self.preprocess_args = preprocess_args\n",
        "\n",
        "        self.user_labels_file = user_labels_file\n",
        "        self.line_labels_file = line_labels_file\n",
        "        self.TEXT_COLUMN_NAME = 'text'\n",
        "\n",
        "        self.length = self._get_ds_length()\n",
        "        self.num_conversations = len(self.conversations)\n",
        "\n",
        "        # Initiate queue\n",
        "        self.message_list = None\n",
        "        self.current_conversation_id = None\n",
        "        self.next_conversation_idx = 0\n",
        "        self.next_message_idx = 0\n",
        "\n",
        "        # Create sets of problematic lines and authors for labels\n",
        "        user_labels = pd.read_csv(user_labels_file, delimiter='\\t', header=None)\n",
        "        self.perverted_authors = set(user_labels[0])\n",
        "\n",
        "        line_labels = pd.read_csv(line_labels_file, delimiter='\\t', header=None)\n",
        "        line_labels['concat'] = line_labels[0] + '_' + line_labels[1].astype(str)\n",
        "        self.pervert_lines = set(line_labels['concat'])\n",
        "\n",
        "        self.load_next_conversation_to_list()\n",
        "                       \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: length of the dataset\n",
        "        \"\"\"\n",
        "        return self.length\n",
        "\n",
        "    def __next__(self) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Gets element of the dataset\n",
        "\n",
        "        Args:\n",
        "            index (int): index of the element in the dataset\n",
        "        Returns:\n",
        "            Single element by index\n",
        "        \"\"\"        \n",
        "        message_dict = {}\n",
        "        try:\n",
        "            message = self.message_list[self.next_message_idx]\n",
        "        except(IndexError):\n",
        "            self.load_next_conversation_to_list()\n",
        "            message = self.message_list[self.next_message_idx]\n",
        "\n",
        "        message_dict['conversation_id'] = self.current_conversation_id\n",
        "        self.next_message_idx += 1\n",
        "        \n",
        "        message_dict['line'] = message.attrib['line']  \n",
        "\n",
        "        for field in message:\n",
        "            message_dict[field.tag] = field.text\n",
        "        \n",
        "        if self.preprocess_fn is not None:\n",
        "            message_dict['text'] = self.preprocess_fn(message_dict['text'], **self.preprocess_args)\n",
        "        \n",
        "        message_dict['author_label'] = 1 if message_dict['author'] in self.perverted_authors else 0\n",
        "        message_dict['line_label'] = 1 if message_dict['conversation_id'] + '_' + message_dict['line'] in self.pervert_lines else 0\n",
        "\n",
        "        return message_dict\n",
        "    \n",
        "    def _get_conversation_roots(self, file_path):\n",
        "        doc_tree = ET.parse(file_path)\n",
        "        conversation_roots = doc_tree.getroot().findall('conversation')\n",
        "        return conversation_roots\n",
        "\n",
        "    def _get_ds_length(self):\n",
        "        number_messages = 0\n",
        "        for conversation in self.conversations:\n",
        "            number_messages += len(conversation.findall('message'))\n",
        "        \n",
        "        return number_messages\n",
        "\n",
        "    def load_next_conversation_to_list(self):\n",
        "        try:\n",
        "            conversation = self.conversations[self.next_conversation_idx] \n",
        "            self.current_conversation_id = conversation.attrib['id']  \n",
        "        except(IndexError):\n",
        "            raise StopIteration()\n",
        "\n",
        "        self.next_conversation_idx += 1\n",
        "        self.message_list = [m for m in conversation.findall('message')]\n",
        "        self.next_message_idx = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dfc77a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dfc77a4",
        "outputId": "1029d1bd-7ff7-4823-c0d8-89f3481c5706"
      },
      "outputs": [],
      "source": [
        "# Test dataset\n",
        "preprocess_args = {'stemmer': PorterStemmer(),\n",
        "                    'speller': SpellChecker(),\n",
        "                    'words_to_remove': set(stopwords.words('english')),\n",
        "                    'emoticons': emoticons,\n",
        "                    'chat_slang': chat_slang\n",
        "                    }\n",
        "\n",
        "pan12_ds = Pan12LineLevelDataloader(PAN12_DATA_FILE, user_labels_file=PAN12_USER_LABELS_FILE, line_labels_file=PAN12_LINE_LABELS_FILE, preprocess_fn=preprocess_string_for_bow, preprocess_args=preprocess_args)\n",
        "print(len(pan12_ds))\n",
        "\n",
        "for i, m in enumerate(pan12_ds):\n",
        "    print(i, m) \n",
        "    if i==50:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3aa278e",
      "metadata": {
        "id": "d3aa278e"
      },
      "source": [
        "### Convert Pan12 to labeled datafreame for use later as Train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2d0e52c1",
      "metadata": {
        "id": "2d0e52c1"
      },
      "outputs": [],
      "source": [
        "class Pan12converterToDF():\n",
        "\n",
        "    # TODO: add labels!\n",
        "    \n",
        "    \"\"\"\n",
        "    Wrapper around Torch Dataset to perform text classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chat_data_file: Path, user_labels_file: Path=None, line_labels_file: Path=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            chat_data_file: path to chat xml file\n",
        "            conversation_labels:\n",
        "            line_labels:\n",
        "            mode:   full - all data \n",
        "                    positive_lines - Only lines labeled as problematic\n",
        "        \"\"\"\n",
        "       \n",
        "        self.chat_data_file = chat_data_file\n",
        "        self.conversations = self._get_conversation_roots(chat_data_file)\n",
        "\n",
        "        self.user_labels_file = user_labels_file\n",
        "        self.line_labels_file = line_labels_file\n",
        "        self.TEXT_COLUMN_NAME = 'text'\n",
        "\n",
        "        self.length = self._get_ds_length()\n",
        "        self.num_conversations = len(self.conversations)\n",
        "\n",
        "        # Initiate queue\n",
        "        self.message_list = None\n",
        "        self.current_conversation_id = None\n",
        "        self.next_conversation_idx = 0\n",
        "        self.next_message_idx = 0\n",
        "\n",
        "        # Create sets of problematic lines and authors for labels\n",
        "        user_labels = pd.read_csv(user_labels_file, delimiter='\\t', header=None)\n",
        "        self.perverted_authors = set(user_labels[0])\n",
        "\n",
        "        line_labels = pd.read_csv(line_labels_file, delimiter='\\t', header=None)\n",
        "        line_labels['concat'] = line_labels[0] + '_' + line_labels[1].astype(str)\n",
        "        self.perverted_conversations = set(line_labels[0].unique())\n",
        "        self.pervert_lines = set(line_labels['concat'])\n",
        "\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: length of the dataset\n",
        "        \"\"\"\n",
        "        return self.length\n",
        "\n",
        "    def convert(self, filename:Path, save_every=2000, mode: str='full') -> pd.DataFrame:\n",
        "        \"\"\"Gets element of the dataset\n",
        "\n",
        "        Args:\n",
        "            index (int): index of the element in the dataset\n",
        "        Returns:\n",
        "            Single element by index\n",
        "        \"\"\"        \n",
        "        pan12_df = pd.DataFrame(columns=['conversation_id', 'line', 'author', 'time', 'text', 'line_label', 'author_label'])\n",
        "\n",
        "        self._load_next_conversation_to_list(mode) \n",
        "\n",
        "        if(mode == 'full'):\n",
        "            iter_len = self.length\n",
        "        elif(mode == 'positive_lines'):\n",
        "            iter_len = len(self.pervert_lines)\n",
        "        \n",
        "        for i in tqdm(range(iter_len)):\n",
        "            message_dict = {}\n",
        "            try:\n",
        "                message = self.message_list[self.next_message_idx]\n",
        "            except(IndexError):\n",
        "                self._load_next_conversation_to_list(mode)\n",
        "                message = self.message_list[self.next_message_idx]\n",
        "            \n",
        "            message_dict['conversation_id'] = self.current_conversation_id\n",
        "            self.next_message_idx += 1\n",
        "            \n",
        "            message_dict['line'] = message.attrib['line']  \n",
        "            for field in message:\n",
        "                message_dict[field.tag] = field.text\n",
        "            \n",
        "            message_dict['author_label'] = 1 if message_dict['author'] in self.perverted_authors else 0\n",
        "            message_dict['line_label'] = 1 if message_dict['conversation_id'] + '_' + message_dict['line'] in self.pervert_lines else 0\n",
        "            \n",
        "            pan12_df = pan12_df.append(message_dict, ignore_index=True)\n",
        "            if i % save_every == 0:\n",
        "                pan12_df.to_csv(filename)\n",
        "                print('.', end='')\n",
        "\n",
        "            # #######\n",
        "            # if i == 1001:\n",
        "            #     print(pan12_df.head(2001))\n",
        "            #     break\n",
        "            # ######\n",
        "        pan12_df.to_csv(filename)\n",
        "        return pan12_df\n",
        "    \n",
        "    def _get_conversation_roots(self, file_path):\n",
        "        doc_tree = ET.parse(file_path)\n",
        "        conversation_roots = doc_tree.getroot().findall('conversation')\n",
        "        return conversation_roots\n",
        "\n",
        "    def _get_ds_length(self):\n",
        "        number_messages = 0\n",
        "        for conversation in self.conversations:\n",
        "            number_messages += len(conversation.findall('message'))\n",
        "        \n",
        "        return number_messages\n",
        "\n",
        "    def _load_next_conversation_to_list(self, mode):\n",
        "        try:\n",
        "            conversation = self.conversations[self.next_conversation_idx] \n",
        "            self.next_conversation_idx += 1\n",
        "            self.current_conversation_id = conversation.attrib['id']  \n",
        "\n",
        "            if mode == 'positive_lines':\n",
        "                while self.current_conversation_id not in self.perverted_conversations:\n",
        "                    conversation = self.conversations[self.next_conversation_idx] \n",
        "                    self.next_conversation_idx += 1\n",
        "                    self.current_conversation_id = conversation.attrib['id']  \n",
        "     \n",
        "        except(IndexError):\n",
        "            raise StopIteration()\n",
        "\n",
        "        if mode == 'positive_lines':\n",
        "            self.message_list = [m for m in conversation.findall('message') if (self.current_conversation_id + '_' + m.attrib['line'] in self.pervert_lines)]\n",
        "        else:\n",
        "            self.message_list = [m for m in conversation.findall('message')]\n",
        "        self.next_message_idx = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "92dd4938",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505,
          "referenced_widgets": [
            "5a30eca9cd274aedba3c3cfee08e986a",
            "e80d4d0d52a54f9ab8ac1f41f281366e",
            "7f1f823c15724c948715c043b9ea89b9",
            "14c4346449c64fa4a695d62f33d10cc1",
            "e032f1f7e816478a96c3c1f9246034c6",
            "bc6c2d7cdac74c079d40c0e1c69aaeec",
            "6aebf996aa9c4960bf0a46ebca04d783",
            "45501c874a53430ea0979ac01e4dcd87",
            "295caedfec664f0bacdab9553c5e674d",
            "3304f532f9c34d59bf10cf3a4b143a8f",
            "cbd617ce94ed4af587dd6dfa9789ac2d"
          ]
        },
        "id": "92dd4938",
        "outputId": "077a296b-5be6-4f27-9be2-c63377c83a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2058781\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32128d3fd5174142a1b65714a57ac981",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6478 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "....6478\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>line</th>\n",
              "      <th>author</th>\n",
              "      <th>time</th>\n",
              "      <th>text</th>\n",
              "      <th>line_label</th>\n",
              "      <th>author_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3763edf61689c00884dba353dba5352e</td>\n",
              "      <td>27</td>\n",
              "      <td>a8e6e3985a82dfde8ee95b5f099ec606</td>\n",
              "      <td>21:20</td>\n",
              "      <td>i wanna work inside with u</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8c5582b1fa2190b69e51e7154d246bbb</td>\n",
              "      <td>8</td>\n",
              "      <td>54b595f1920b5b1988e907ea693303b4</td>\n",
              "      <td>00:02</td>\n",
              "      <td>we could've had sex</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8c5582b1fa2190b69e51e7154d246bbb</td>\n",
              "      <td>9</td>\n",
              "      <td>54b595f1920b5b1988e907ea693303b4</td>\n",
              "      <td>00:02</td>\n",
              "      <td>kidding bout that</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6eab795c5f6a9d822d25a2b153736799</td>\n",
              "      <td>33</td>\n",
              "      <td>2eba3cbb71e6ea5af3ede4d7b898f99d</td>\n",
              "      <td>18:28</td>\n",
              "      <td>what do u ussually say when ur going to be gon...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6eab795c5f6a9d822d25a2b153736799</td>\n",
              "      <td>35</td>\n",
              "      <td>2eba3cbb71e6ea5af3ede4d7b898f99d</td>\n",
              "      <td>18:28</td>\n",
              "      <td>what does he say to that?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>cc5fba01f752fae4846aed8f26731b7b</td>\n",
              "      <td>109</td>\n",
              "      <td>b8931a8b614fb54f6051ffc75f39db29</td>\n",
              "      <td>14:40</td>\n",
              "      <td>i will teach you</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>cc5fba01f752fae4846aed8f26731b7b</td>\n",
              "      <td>111</td>\n",
              "      <td>b8931a8b614fb54f6051ffc75f39db29</td>\n",
              "      <td>14:40</td>\n",
              "      <td>so what would yo udo to me first</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>cc5fba01f752fae4846aed8f26731b7b</td>\n",
              "      <td>114</td>\n",
              "      <td>b8931a8b614fb54f6051ffc75f39db29</td>\n",
              "      <td>14:41</td>\n",
              "      <td>you can stroke my cock or suck on my nipples</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>cc5fba01f752fae4846aed8f26731b7b</td>\n",
              "      <td>116</td>\n",
              "      <td>b8931a8b614fb54f6051ffc75f39db29</td>\n",
              "      <td>14:42</td>\n",
              "      <td>i would love to come to you now honey</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>4406aad767720e999464dea17ff91826</td>\n",
              "      <td>25</td>\n",
              "      <td>8337ec42f09d2dc8798fb9e0c49f4adb</td>\n",
              "      <td>18:31</td>\n",
              "      <td>i just dont wanna get in trouble</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     conversation_id line                            author  \\\n",
              "0   3763edf61689c00884dba353dba5352e   27  a8e6e3985a82dfde8ee95b5f099ec606   \n",
              "1   8c5582b1fa2190b69e51e7154d246bbb    8  54b595f1920b5b1988e907ea693303b4   \n",
              "2   8c5582b1fa2190b69e51e7154d246bbb    9  54b595f1920b5b1988e907ea693303b4   \n",
              "3   6eab795c5f6a9d822d25a2b153736799   33  2eba3cbb71e6ea5af3ede4d7b898f99d   \n",
              "4   6eab795c5f6a9d822d25a2b153736799   35  2eba3cbb71e6ea5af3ede4d7b898f99d   \n",
              "..                               ...  ...                               ...   \n",
              "95  cc5fba01f752fae4846aed8f26731b7b  109  b8931a8b614fb54f6051ffc75f39db29   \n",
              "96  cc5fba01f752fae4846aed8f26731b7b  111  b8931a8b614fb54f6051ffc75f39db29   \n",
              "97  cc5fba01f752fae4846aed8f26731b7b  114  b8931a8b614fb54f6051ffc75f39db29   \n",
              "98  cc5fba01f752fae4846aed8f26731b7b  116  b8931a8b614fb54f6051ffc75f39db29   \n",
              "99  4406aad767720e999464dea17ff91826   25  8337ec42f09d2dc8798fb9e0c49f4adb   \n",
              "\n",
              "     time                                               text line_label  \\\n",
              "0   21:20                         i wanna work inside with u          1   \n",
              "1   00:02                                we could've had sex          1   \n",
              "2   00:02                                  kidding bout that          1   \n",
              "3   18:28  what do u ussually say when ur going to be gon...          1   \n",
              "4   18:28                          what does he say to that?          1   \n",
              "..    ...                                                ...        ...   \n",
              "95  14:40                                   i will teach you          1   \n",
              "96  14:40                   so what would yo udo to me first          1   \n",
              "97  14:41       you can stroke my cock or suck on my nipples          1   \n",
              "98  14:42              i would love to come to you now honey          1   \n",
              "99  18:31                   i just dont wanna get in trouble          1   \n",
              "\n",
              "   author_label  \n",
              "0             1  \n",
              "1             1  \n",
              "2             1  \n",
              "3             1  \n",
              "4             1  \n",
              "..          ...  \n",
              "95            1  \n",
              "96            1  \n",
              "97            1  \n",
              "98            1  \n",
              "99            1  \n",
              "\n",
              "[100 rows x 7 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a dataframe of all pan12 test perverted lines\n",
        "\n",
        "pan12_converter = Pan12converterToDF(PAN12_DATA_FILE, user_labels_file=PAN12_USER_LABELS_FILE, line_labels_file=PAN12_LINE_LABELS_FILE)\n",
        "print(len(pan12_converter))\n",
        "pan12_df = pan12_converter.convert(OUTPUT_FOLDER / Path('pan12_csv.zip'), mode='positive_lines')\n",
        "print(len(pan12_df))\n",
        "pan12_df.head(100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "c5839cab",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>line</th>\n",
              "      <th>author</th>\n",
              "      <th>time</th>\n",
              "      <th>text</th>\n",
              "      <th>line_label</th>\n",
              "      <th>author_label</th>\n",
              "      <th>preprocessed_bow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3763edf61689c00884dba353dba5352e</td>\n",
              "      <td>27</td>\n",
              "      <td>a8e6e3985a82dfde8ee95b5f099ec606</td>\n",
              "      <td>21:20</td>\n",
              "      <td>i wanna work inside with u</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>i want to work inside with you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8c5582b1fa2190b69e51e7154d246bbb</td>\n",
              "      <td>8</td>\n",
              "      <td>54b595f1920b5b1988e907ea693303b4</td>\n",
              "      <td>00:02</td>\n",
              "      <td>we could've had sex</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>we could ve had sex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8c5582b1fa2190b69e51e7154d246bbb</td>\n",
              "      <td>9</td>\n",
              "      <td>54b595f1920b5b1988e907ea693303b4</td>\n",
              "      <td>00:02</td>\n",
              "      <td>kidding bout that</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>kidding about that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6eab795c5f6a9d822d25a2b153736799</td>\n",
              "      <td>33</td>\n",
              "      <td>2eba3cbb71e6ea5af3ede4d7b898f99d</td>\n",
              "      <td>18:28</td>\n",
              "      <td>what do u ussually say when ur going to be gon...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>what do you usually say when you are going to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6eab795c5f6a9d822d25a2b153736799</td>\n",
              "      <td>35</td>\n",
              "      <td>2eba3cbb71e6ea5af3ede4d7b898f99d</td>\n",
              "      <td>18:28</td>\n",
              "      <td>what does he say to that?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>what does he say to that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6473</th>\n",
              "      <td>cf5d918cdd1601c608c62de1c0641dbd</td>\n",
              "      <td>1</td>\n",
              "      <td>b18ae7c450091f1f200e896d765cce6d</td>\n",
              "      <td>14:33</td>\n",
              "      <td>Hey, i go to work most days now, so seeing me ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hey i go to work most days now so seeing me on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6474</th>\n",
              "      <td>ec391a65097a955029afaedc23d5fa81</td>\n",
              "      <td>36</td>\n",
              "      <td>2e0d170f2addfb0048f9424a2daa5a73</td>\n",
              "      <td>18:34</td>\n",
              "      <td>u like older guys?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>you like older guys</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6475</th>\n",
              "      <td>82add2c9da3c267a98b3981375b6c238</td>\n",
              "      <td>55</td>\n",
              "      <td>c5502c7c9bb5e28508a3e19ec869f6d2</td>\n",
              "      <td>09:32</td>\n",
              "      <td>just sitting here naked talking to you</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>just sitting here naked talking to you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6476</th>\n",
              "      <td>82add2c9da3c267a98b3981375b6c238</td>\n",
              "      <td>68</td>\n",
              "      <td>c5502c7c9bb5e28508a3e19ec869f6d2</td>\n",
              "      <td>09:36</td>\n",
              "      <td>see you might be if i was there, and we could ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>see you might be if i was there and we could b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6477</th>\n",
              "      <td>82add2c9da3c267a98b3981375b6c238</td>\n",
              "      <td>88</td>\n",
              "      <td>c5502c7c9bb5e28508a3e19ec869f6d2</td>\n",
              "      <td>09:45</td>\n",
              "      <td>well i guess i need to get ready for work, sin...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>well i guess i need to get ready for work sinc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6478 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       conversation_id line                            author  \\\n",
              "0     3763edf61689c00884dba353dba5352e   27  a8e6e3985a82dfde8ee95b5f099ec606   \n",
              "1     8c5582b1fa2190b69e51e7154d246bbb    8  54b595f1920b5b1988e907ea693303b4   \n",
              "2     8c5582b1fa2190b69e51e7154d246bbb    9  54b595f1920b5b1988e907ea693303b4   \n",
              "3     6eab795c5f6a9d822d25a2b153736799   33  2eba3cbb71e6ea5af3ede4d7b898f99d   \n",
              "4     6eab795c5f6a9d822d25a2b153736799   35  2eba3cbb71e6ea5af3ede4d7b898f99d   \n",
              "...                                ...  ...                               ...   \n",
              "6473  cf5d918cdd1601c608c62de1c0641dbd    1  b18ae7c450091f1f200e896d765cce6d   \n",
              "6474  ec391a65097a955029afaedc23d5fa81   36  2e0d170f2addfb0048f9424a2daa5a73   \n",
              "6475  82add2c9da3c267a98b3981375b6c238   55  c5502c7c9bb5e28508a3e19ec869f6d2   \n",
              "6476  82add2c9da3c267a98b3981375b6c238   68  c5502c7c9bb5e28508a3e19ec869f6d2   \n",
              "6477  82add2c9da3c267a98b3981375b6c238   88  c5502c7c9bb5e28508a3e19ec869f6d2   \n",
              "\n",
              "       time                                               text line_label  \\\n",
              "0     21:20                         i wanna work inside with u          1   \n",
              "1     00:02                                we could've had sex          1   \n",
              "2     00:02                                  kidding bout that          1   \n",
              "3     18:28  what do u ussually say when ur going to be gon...          1   \n",
              "4     18:28                          what does he say to that?          1   \n",
              "...     ...                                                ...        ...   \n",
              "6473  14:33  Hey, i go to work most days now, so seeing me ...          1   \n",
              "6474  18:34                                 u like older guys?          1   \n",
              "6475  09:32             just sitting here naked talking to you          1   \n",
              "6476  09:36  see you might be if i was there, and we could ...          1   \n",
              "6477  09:45  well i guess i need to get ready for work, sin...          1   \n",
              "\n",
              "     author_label                                   preprocessed_bow  \n",
              "0               1                     i want to work inside with you  \n",
              "1               1                                we could ve had sex  \n",
              "2               1                                 kidding about that  \n",
              "3               1  what do you usually say when you are going to ...  \n",
              "4               1                           what does he say to that  \n",
              "...           ...                                                ...  \n",
              "6473            1  hey i go to work most days now so seeing me on...  \n",
              "6474            1                                you like older guys  \n",
              "6475            1             just sitting here naked talking to you  \n",
              "6476            1  see you might be if i was there and we could b...  \n",
              "6477            1  well i guess i need to get ready for work sinc...  \n",
              "\n",
              "[6478 rows x 8 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preprocess pan12 perverted lines \n",
        "\n",
        "preprocess_args = {'stemmer': PorterStemmer(),\n",
        "                    'speller': SpellChecker(),\n",
        "                    'words_to_remove': set(stopwords.words('english')),\n",
        "                    'emoticons': emoticons,\n",
        "                    'chat_slang': chat_slang\n",
        "                    }\n",
        "\n",
        "pan12_df = preprocess_df_for_bow(pan12_df, 'text', **preprocess_args)\n",
        "pan12_df.to_csv(OUTPUT_FOLDER / Path('pan12_perverted_lines_preprocessed.zip'))\n",
        "\n",
        "pan12_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59bd5e29",
      "metadata": {},
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9a594d2",
      "metadata": {},
      "source": [
        "### Word list based classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "8de75393",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>line</th>\n",
              "      <th>author</th>\n",
              "      <th>time</th>\n",
              "      <th>text</th>\n",
              "      <th>line_label</th>\n",
              "      <th>author_label</th>\n",
              "      <th>preprocessed_bow</th>\n",
              "      <th>contains_sex_words</th>\n",
              "      <th>contains_family_words</th>\n",
              "      <th>contains_meeting_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3763edf61689c00884dba353dba5352e</td>\n",
              "      <td>27</td>\n",
              "      <td>a8e6e3985a82dfde8ee95b5f099ec606</td>\n",
              "      <td>21:20</td>\n",
              "      <td>i wanna work inside with u</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>i want to work inside with you</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8c5582b1fa2190b69e51e7154d246bbb</td>\n",
              "      <td>9</td>\n",
              "      <td>54b595f1920b5b1988e907ea693303b4</td>\n",
              "      <td>00:02</td>\n",
              "      <td>kidding bout that</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>kidding bout that</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6eab795c5f6a9d822d25a2b153736799</td>\n",
              "      <td>33</td>\n",
              "      <td>2eba3cbb71e6ea5af3ede4d7b898f99d</td>\n",
              "      <td>18:28</td>\n",
              "      <td>what do u ussually say when ur going to be gon...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>what do you usually say when you are going to ...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6eab795c5f6a9d822d25a2b153736799</td>\n",
              "      <td>35</td>\n",
              "      <td>2eba3cbb71e6ea5af3ede4d7b898f99d</td>\n",
              "      <td>18:28</td>\n",
              "      <td>what does he say to that?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>what does he say to that</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6eab795c5f6a9d822d25a2b153736799</td>\n",
              "      <td>65</td>\n",
              "      <td>2eba3cbb71e6ea5af3ede4d7b898f99d</td>\n",
              "      <td>18:43</td>\n",
              "      <td>how often do u shave ur legs?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>how often do you shave you are legs</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6470</th>\n",
              "      <td>ab42a85c6dd371e3bf98475d5642ac74</td>\n",
              "      <td>67</td>\n",
              "      <td>86acb75ad942a8df784694ad33c83068</td>\n",
              "      <td>03:05</td>\n",
              "      <td>have u ever had a guy lick you b4?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>have you ever had a guy lick you be</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6471</th>\n",
              "      <td>ab42a85c6dd371e3bf98475d5642ac74</td>\n",
              "      <td>69</td>\n",
              "      <td>86acb75ad942a8df784694ad33c83068</td>\n",
              "      <td>03:06</td>\n",
              "      <td>will u wanna lemme try it?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>will you want to lemme try it</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6472</th>\n",
              "      <td>ab42a85c6dd371e3bf98475d5642ac74</td>\n",
              "      <td>75</td>\n",
              "      <td>86acb75ad942a8df784694ad33c83068</td>\n",
              "      <td>03:09</td>\n",
              "      <td>sneak out tonite babe</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>sneak out tonite babe</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6473</th>\n",
              "      <td>cf5d918cdd1601c608c62de1c0641dbd</td>\n",
              "      <td>1</td>\n",
              "      <td>b18ae7c450091f1f200e896d765cce6d</td>\n",
              "      <td>14:33</td>\n",
              "      <td>Hey, i go to work most days now, so seeing me ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hey i go to work most days now so seeing me on...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6474</th>\n",
              "      <td>ec391a65097a955029afaedc23d5fa81</td>\n",
              "      <td>36</td>\n",
              "      <td>2e0d170f2addfb0048f9424a2daa5a73</td>\n",
              "      <td>18:34</td>\n",
              "      <td>u like older guys?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>you like older guys</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4161 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       conversation_id line                            author  \\\n",
              "0     3763edf61689c00884dba353dba5352e   27  a8e6e3985a82dfde8ee95b5f099ec606   \n",
              "2     8c5582b1fa2190b69e51e7154d246bbb    9  54b595f1920b5b1988e907ea693303b4   \n",
              "3     6eab795c5f6a9d822d25a2b153736799   33  2eba3cbb71e6ea5af3ede4d7b898f99d   \n",
              "4     6eab795c5f6a9d822d25a2b153736799   35  2eba3cbb71e6ea5af3ede4d7b898f99d   \n",
              "5     6eab795c5f6a9d822d25a2b153736799   65  2eba3cbb71e6ea5af3ede4d7b898f99d   \n",
              "...                                ...  ...                               ...   \n",
              "6470  ab42a85c6dd371e3bf98475d5642ac74   67  86acb75ad942a8df784694ad33c83068   \n",
              "6471  ab42a85c6dd371e3bf98475d5642ac74   69  86acb75ad942a8df784694ad33c83068   \n",
              "6472  ab42a85c6dd371e3bf98475d5642ac74   75  86acb75ad942a8df784694ad33c83068   \n",
              "6473  cf5d918cdd1601c608c62de1c0641dbd    1  b18ae7c450091f1f200e896d765cce6d   \n",
              "6474  ec391a65097a955029afaedc23d5fa81   36  2e0d170f2addfb0048f9424a2daa5a73   \n",
              "\n",
              "       time                                               text line_label  \\\n",
              "0     21:20                         i wanna work inside with u          1   \n",
              "2     00:02                                  kidding bout that          1   \n",
              "3     18:28  what do u ussually say when ur going to be gon...          1   \n",
              "4     18:28                          what does he say to that?          1   \n",
              "5     18:43                      how often do u shave ur legs?          1   \n",
              "...     ...                                                ...        ...   \n",
              "6470  03:05                 have u ever had a guy lick you b4?          1   \n",
              "6471  03:06                         will u wanna lemme try it?          1   \n",
              "6472  03:09                              sneak out tonite babe          1   \n",
              "6473  14:33  Hey, i go to work most days now, so seeing me ...          1   \n",
              "6474  18:34                                 u like older guys?          1   \n",
              "\n",
              "     author_label                                   preprocessed_bow  \\\n",
              "0               1                     i want to work inside with you   \n",
              "2               1                                  kidding bout that   \n",
              "3               1  what do you usually say when you are going to ...   \n",
              "4               1                           what does he say to that   \n",
              "5               1                how often do you shave you are legs   \n",
              "...           ...                                                ...   \n",
              "6470            1                have you ever had a guy lick you be   \n",
              "6471            1                      will you want to lemme try it   \n",
              "6472            1                              sneak out tonite babe   \n",
              "6473            1  hey i go to work most days now so seeing me on...   \n",
              "6474            1                                you like older guys   \n",
              "\n",
              "      contains_sex_words  contains_family_words  contains_meeting_words  \n",
              "0                  False                  False                   False  \n",
              "2                  False                  False                   False  \n",
              "3                  False                  False                   False  \n",
              "4                  False                  False                   False  \n",
              "5                  False                  False                   False  \n",
              "...                  ...                    ...                     ...  \n",
              "6470               False                  False                   False  \n",
              "6471               False                  False                   False  \n",
              "6472               False                  False                   False  \n",
              "6473               False                  False                   False  \n",
              "6474               False                  False                   False  \n",
              "\n",
              "[4161 rows x 11 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def contains_words_from_list(text: str, word_list: List[str])-> bool:\n",
        "    text_words = re.sub(\"[^\\w]\", \" \",  text).split()\n",
        "    if any(word in word_list for word in text_words):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "pan12_df['contains_sex_words'] = pan12_df['preprocessed_bow'].apply(lambda text: contains_words_from_list(text, sex_word_list))\n",
        "pan12_df['contains_family_words'] = pan12_df['preprocessed_bow'].apply(lambda text: contains_words_from_list(text, family_word_list))\n",
        "pan12_df['contains_meeting_words'] = pan12_df['preprocessed_bow'].apply(lambda text: contains_words_from_list(text, meeting_word_list))\n",
        "\n",
        "pan12_df.to_csv(OUTPUT_FOLDER / Path('pan12_perverted_lines_preprocessed.zip'))\n",
        "\n",
        "# pan12_df[(pan12_df.contains_sex_words == False) & (pan12_df.contains_family_words == False) & (pan12_df.contains_meeting_words == False)]\n",
        "pan12_df[(pan12_df.contains_meeting_words == True)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f319750",
      "metadata": {
        "id": "5f319750",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### TF/IDF - Not started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2d50135b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "2d50135b",
        "outputId": "27ba8462-6da3-4e9c-c93d-09246a684984"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'TfidfVectorizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\docs\\DSML_IDC\\Semester 4\\Cyber\\Tasks\\Task2\\cyber_hw2.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/cyber_hw2.ipynb#ch0000030?line=0'>1</a>\u001b[0m tfIdfVectorizer\u001b[39m=\u001b[39mTfidfVectorizer(use_idf\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/cyber_hw2.ipynb#ch0000030?line=1'>2</a>\u001b[0m tfIdf \u001b[39m=\u001b[39m tfIdfVectorizer\u001b[39m.\u001b[39mfit_transform(dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/cyber_hw2.ipynb#ch0000030?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(tfIdf[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mtodense(), index\u001b[39m=\u001b[39mtfIdfVectorizer\u001b[39m.\u001b[39mget_feature_names(), columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mTF-IDF\u001b[39m\u001b[39m\"\u001b[39m])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
          ]
        }
      ],
      "source": [
        "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
        "tfIdf = tfIdfVectorizer.fit_transform(dataset)\n",
        "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
        "df = df.sort_values('TF-IDF', ascending=False)\n",
        "print (df.head(25))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d684c5",
      "metadata": {
        "id": "72d684c5"
      },
      "source": [
        "## some thoughts\n",
        "Bag of words - sexual words, fear, trust, family, approach (Location, transport) , other categories - DrouinBoydHancockJames2017\n",
        "Good article: file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/Early%20Text%20Classification%20using%20Multi-Resolution%20Concept%20Representations.pdf\n",
        "Ensamble and preprocessing: file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/PredatoryConversationDetection.pdf\n",
        "file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/Analyzing_Chat_Conversations_of_Pedophil.pdf\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "cyber_hw2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1a8e22f9a50968eda7c2b2da6b1cd647c6294c71990fbcb0be47dbd614eb6ed8"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14c4346449c64fa4a695d62f33d10cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3304f532f9c34d59bf10cf3a4b143a8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cbd617ce94ed4af587dd6dfa9789ac2d",
            "value": " 355158/2058781 [3:52:56&lt;35:12:01, 13.44it/s]"
          }
        },
        "295caedfec664f0bacdab9553c5e674d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3304f532f9c34d59bf10cf3a4b143a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45501c874a53430ea0979ac01e4dcd87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a30eca9cd274aedba3c3cfee08e986a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e80d4d0d52a54f9ab8ac1f41f281366e",
              "IPY_MODEL_7f1f823c15724c948715c043b9ea89b9",
              "IPY_MODEL_14c4346449c64fa4a695d62f33d10cc1"
            ],
            "layout": "IPY_MODEL_e032f1f7e816478a96c3c1f9246034c6"
          }
        },
        "6aebf996aa9c4960bf0a46ebca04d783": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f1f823c15724c948715c043b9ea89b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45501c874a53430ea0979ac01e4dcd87",
            "max": 2058781,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_295caedfec664f0bacdab9553c5e674d",
            "value": 355158
          }
        },
        "bc6c2d7cdac74c079d40c0e1c69aaeec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbd617ce94ed4af587dd6dfa9789ac2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e032f1f7e816478a96c3c1f9246034c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e80d4d0d52a54f9ab8ac1f41f281366e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6c2d7cdac74c079d40c0e1c69aaeec",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6aebf996aa9c4960bf0a46ebca04d783",
            "value": " 17%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
