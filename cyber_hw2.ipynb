{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72810151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in d:\\docs\\dsml_idc\\semester 4\\cyber\\venv\\lib\\site-packages (0.6.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086e0e1",
   "metadata": {},
   "source": [
    "## General - imports paths etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683f43e6-ff1c-4c28-af4c-3452553fc476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "d:\\docs\\DSML_IDC\\Semester 4\\Cyber\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import xml.etree.ElementTree as ET \n",
    "import csv\n",
    "\n",
    "from typing import Dict, Callable, List, Dict, Set, Any\n",
    "import logging\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9de114-ddde-43d7-9d6a-69d1b0a913d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders\n",
    "DATA_FOLDER = Path('.\\customer_data')\n",
    "file_path = DATA_FOLDER / Path('ArmySgt1961.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d0df3",
   "metadata": {},
   "source": [
    "### Word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70954f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word lists\n",
    "SEX_WL_PATH = Path(r'.\\sex_words.txt')\n",
    "with open(SEX_WL_PATH, 'rt') as handle:\n",
    "    sex_word_list = handle.read().split('\\n')\n",
    "\n",
    "MEETING_WL_PATH = Path(r'.\\meeting_words.txt')\n",
    "with open(MEETING_WL_PATH, 'rt') as handle:\n",
    "    meeting_word_list = handle.read().split('\\n')\n",
    "\n",
    "FAMILY_WL_PATH = Path(r'.\\family_words.txt')\n",
    "with open(FAMILY_WL_PATH, 'rt') as handle:\n",
    "    family_word_list = handle.read().split('\\n')\n",
    "\n",
    "CHAT_SLANG_PATH = Path(r'.\\chat_slang.txt')\n",
    "with open(CHAT_SLANG_PATH, mode='rt') as handle:\n",
    "    csv_reader = csv.reader(handle, delimiter='\\t')\n",
    "    chat_slang = {rows[0]:rows[1] for rows in csv_reader}\n",
    "\n",
    "EMOTICONS_PATH = Path(r'.\\emoticons.txt')\n",
    "with open(EMOTICONS_PATH, mode='rt', encoding=\"utf8\") as handle:\n",
    "    csv_reader = csv.reader(handle, delimiter='\\t')\n",
    "    emoticons = {rows[0]:rows[1] for rows in csv_reader}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119f4fd",
   "metadata": {},
   "source": [
    "## Data loaders, data parsers, data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ea3ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>BODY</th>\n",
       "      <th>COMMENT</th>\n",
       "      <th>CODING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:02:01 pm)</td>\n",
       "      <td>im dennis us army soldier from cincinnati</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:02:30 pm)</td>\n",
       "      <td>hi im becky from ky</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:02:35 pm)</td>\n",
       "      <td>how old ru</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:02:42 pm)</td>\n",
       "      <td>13 how old ru</td>\n",
       "      <td>(age stated and he didn't bat an eye)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:02:44 pm)</td>\n",
       "      <td>u single</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:02:51 pm)</td>\n",
       "      <td>yeah</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:03:03 pm)</td>\n",
       "      <td>i had a bf but we broke up when i moved here</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:03:11 pm)</td>\n",
       "      <td>ok u have sex at 13</td>\n",
       "      <td>(he obviously knows my age)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>peekaboo1293</td>\n",
       "      <td>(7:03:28 pm)</td>\n",
       "      <td>u mean did i ever</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>armysgt1961</td>\n",
       "      <td>(7:03:32 pm)</td>\n",
       "      <td>yeah</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       USERNAME      DATETIME                                          BODY  \\\n",
       "0   armysgt1961  (7:02:01 pm)     im dennis us army soldier from cincinnati   \n",
       "1  peekaboo1293  (7:02:30 pm)                           hi im becky from ky   \n",
       "2   armysgt1961  (7:02:35 pm)                                    how old ru   \n",
       "3  peekaboo1293  (7:02:42 pm)                                 13 how old ru   \n",
       "4   armysgt1961  (7:02:44 pm)                                      u single   \n",
       "5  peekaboo1293  (7:02:51 pm)                                          yeah   \n",
       "6  peekaboo1293  (7:03:03 pm)  i had a bf but we broke up when i moved here   \n",
       "7   armysgt1961  (7:03:11 pm)                           ok u have sex at 13   \n",
       "8  peekaboo1293  (7:03:28 pm)                             u mean did i ever   \n",
       "9   armysgt1961  (7:03:32 pm)                                          yeah   \n",
       "\n",
       "                                 COMMENT CODING  \n",
       "0                                   <NA>      \n",
       "  \n",
       "1                                   <NA>   <NA>  \n",
       "2                                   <NA>      \n",
       "  \n",
       "3  (age stated and he didn't bat an eye)   <NA>  \n",
       "4                                   <NA>      \n",
       "  \n",
       "5                                   <NA>   <NA>  \n",
       "6                                   <NA>   <NA>  \n",
       "7            (he obviously knows my age)      \n",
       "  \n",
       "8                                   <NA>   <NA>  \n",
       "9                                   <NA>   <NA>  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_chat_file_pj(file_path: Path) -> Dict[str, pd.DataFrame]:\n",
    "    '''\n",
    "    Gets an XML doctree (ET parser)\n",
    "    returns three dataframes:\n",
    "        - victim\n",
    "        - predator\n",
    "        - chat posts\n",
    "    '''\n",
    "    doc_tree = ET.parse(file_path)\n",
    "    doc_root = doc_tree.getroot()\n",
    "    \n",
    "    posts_df = pd.DataFrame(columns = ['USERNAME', 'DATETIME', 'BODY', 'COMMENT', 'CODING'], dtype=str)\n",
    "    predator_df = pd.DataFrame(columns = ['FIRSTNAME', 'LASTNAME', 'STATEDNAME', 'STATEDAGE', 'GENDER', 'RACE', 'CITY', 'STATE', 'REPEATOFFENDER', 'ADMITGUILT', 'TRUTHFULNAME', 'SCREENNAME'], dtype=str)\n",
    "    victim_df = pd.DataFrame(columns = ['FIRSTNAME', 'LASTNAME', 'STATEDNAME', 'STATEDAGE', 'GENDER', 'RACE', 'CITY', 'STATE', 'PREVIOUSVICTIMIZATION', 'ADMITGUILT', 'SCREENNAME'], dtype=str)\n",
    "\n",
    "    for post in doc_root.findall('POST'):\n",
    "        post_dict = {}\n",
    "        for field in post:\n",
    "            post_dict[field.tag] = field.text\n",
    "\n",
    "        posts_df = posts_df.append(post_dict, ignore_index=True)\n",
    "    posts_df = posts_df.astype('string')\n",
    "\n",
    "\n",
    "    for predator in doc_root.findall('PREDATOR'):\n",
    "        predator_dict = {}\n",
    "        for field in predator:\n",
    "            predator_dict[field.tag] = field.text\n",
    "\n",
    "        predator_df = predator_df.append(predator_dict, ignore_index=True)   \n",
    "    predator_df = predator_df.astype('string')\n",
    "\n",
    "\n",
    "    for victim in doc_root.findall('VICTIM'):\n",
    "        victim_dict = {}\n",
    "        for field in victim:\n",
    "            victim_dict[field.tag] = field.text\n",
    "\n",
    "        victim_df = victim_df.append(victim_dict, ignore_index=True)  \n",
    "    victim_df = victim_df.astype('string')\n",
    "\n",
    "    return {'predator': predator_df, 'victim': victim_df, 'posts': posts_df}\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Test XML parse functions:\n",
    "file_path = DATA_FOLDER / Path('ArmySgt1961.xml')\n",
    "chat_dict =  parse_chat_file_pj(file_path)\n",
    "chat_dict['victim'].head()\n",
    "chat_dict['predator'].head()\n",
    "chat_dict['posts'].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0844b40",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e182ed0",
   "metadata": {},
   "source": [
    "### Chat text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34d2873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(text: str, words_to_remove: List[str])-> str:\n",
    "    '''\n",
    "    Gets string, returns it without stopwords\n",
    "    '''\n",
    "    return \" \".join([word for word in str(text).split() if word not in words_to_remove])\n",
    "\n",
    "\n",
    "def stem_text(text: str, stemmer: Any)-> str:\n",
    "    '''\n",
    "    stem text string\n",
    "    '''\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "\n",
    "def remove_emoji(text: str) -> str:\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_emoticons(text: str, emoticons: Dict) -> str:\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in emoticons) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_urls(text:str)-> str:\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def replace_chat_slang(text: str, chat_slang: Dict[str, str])-> str:\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_slang.keys():\n",
    "            new_text.append(chat_slang[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "\n",
    "def correct_spellings(text: str, speller: Callable) -> str:\n",
    "    corrected_text = []\n",
    "    misspelled_words = speller.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(speller.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "\n",
    "def preprocess_text_for_bow(text: str, stemmer: Callable, speller: Callable, words_to_remove:List[str], emoticons: Dict[str, str])-> str:\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_emoticons(text, emoticons)\n",
    "    text = replace_chat_slang(text, chat_slang)\n",
    "    text = text.lower()\n",
    "    text = remove_stopwords(text, words_to_remove)\n",
    "    text = correct_spellings(text, speller)\n",
    "    text = stem_text(text, stemmer)\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_posts_for_bow(df: pd.DataFrame, text_col: str)-> pd.DataFrame:\n",
    "    '''\n",
    "    Gets a PD dataframe and a text column name\n",
    "    returns the same dataframe with additional column called 'posts_preprocessed_bow'\n",
    "    '''\n",
    "    speller = SpellChecker()\n",
    "    words_to_remove = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    df['posts_preprocessed_bow'] = df[text_col]\n",
    "    df['posts_preprocessed_bow'] = df['posts_preprocessed_bow'].apply(lambda text: preprocess_text_for_bow(text, stemmer, speller, words_to_remove, emoticons))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e001f9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'laugh loud the right come right right right back fuck'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    speller = SpellChecker()\n",
    "    words_to_remove = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    text = 'LOL ths is not right im caming right now u r right brb and fu :-)'\n",
    "\n",
    "    preprocess_text_for_bow(text, stemmer, speller, words_to_remove, emoticons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d684c5",
   "metadata": {},
   "source": [
    "## some thoughts\n",
    "Chat Preprocess: https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing/notebook\n",
    "Bag of words - sexual words, fear, trust, family, approach (Location, transport) , other categories - DrouinBoydHancockJames2017\n",
    "Good article: file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/Early%20Text%20Classification%20using%20Multi-Resolution%20Concept%20Representations.pdf\n",
    "Ensamble and preprocessing: file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/PredatoryConversationDetection.pdf\n",
    "file:///D:/docs/DSML_IDC/Semester%204/Cyber/Tasks/Task2/ref%20docs/Analyzing_Chat_Conversations_of_Pedophil.pdf\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a8e22f9a50968eda7c2b2da6b1cd647c6294c71990fbcb0be47dbd614eb6ed8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
